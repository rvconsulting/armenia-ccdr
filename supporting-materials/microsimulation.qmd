---
title: "Armenia CCDR Microsimulation"
author:
  - name: "Renato Vargas"
    id: rv
    email: renovargas@gmail.com
    affiliation: 
      - name: Consultant
  - name: "Julie Rozenberg"
    id: jr
    email: jrozenberg@worldbank.org
    affiliation: 
      - name: The World Bank
  - name: "Colin Lenoble"
    id: cl
    email: clenoble@worldbank.org
    affiliation: 
      - name: The World Bank
  - name: "Natsuko Kiso Nozaki"
    id: nk
    email: nkiso@worldbank.org
    affiliation:
      - name: The World Bank  
  - name: "Thomas Farole"
    id: tf
    email: tfarole@worldbank.org
    affiliation:
      - name: The World Bank  
            
format:
  html:
    toc: true
    number-sections: true
    number-depth: 3
    highlight-style: github
  docx:
    toc: true
    number-sections: true
    highlight-style: github
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
editor: source
editor_options: 
  chunk_output_type: console
bibliography: references.bib
csl: apa-6th-edition.csl
---

## Introduction

In this calculation file, we "age" the household survey according to demographic projections and different macroeconomic scenarios to explore the impact of climate-related risks and policy measures on the consumption expenditure distribution.

As a convention, code is presented in the following format in this guide:

```{r eval=FALSE}
# Some comment that is not evaluated by R
some_variable <- some_function(some_object, some_parameter = TRUE)
```

We assume that the reader has created an Rstudio project and is familiar with basic R functions. Within that project we recommend the following file structure:

``` txt
root/
├── scripts
│   └── my_script.R
├── data/
|   ├── my_data.sav
|   ├── my_data.dta
|   └── my_data.csv
└── output
    ├── my_output1.csv
    └── my_output2.xlsx
```

Using RStudio project makes it possible to not use `setwd()` to establish the root directory and refer to subdirectories in a relative manner, making interoperability easier within teams and not hard coding a particular computer's file structure into the code. If you are not using RStudio, just add `setwd(r'(C:\My\path\to\project\root)')` at the beginning of your coding session.

## Preamble

We start with a clean environment, making sure that any objects from a previous session are not present. We take this opportunity to keep our country ISO code in a variable `iso` in case we need it later.

```{r warning=FALSE, message=FALSE}
# Clean workspace
rm(list = ls())

# Armenia country ISO code
iso <- "ARM"

# Survey year
surveyyear <- 2022

# Exchange rate USD per dram
er <- 0.002310
```

We call the appropriate libraries.

Rather than calling our libraries as we go, we will make sure we have everything we need from the beginning.

```{r output=FALSE}
# Load packages
library(tidyverse) # includes dplyr, ggplot2 and others
library(haven)     # to read SPSS and Stata datasets
library(readxl)    # to read from MS-Excel
library(openxlsx)  # to write to MS-Excel.
library(gt)        # pretty tables
library(car)       # Companion to applied regression
library(modelr)    # regression models
library(ebal)      # Entropy reweighting
library(janitor)   # pretty subtotals
library(purrr)     # map vectors (aggregation)


# Geopackages
library(sf)        # to read and write shapefile maps
library(terra)     # to perform geocalculations
library(tmap)      # for static and interactive maps
```

Stata integration

```{r}
library(RStata)    # stata integration for wentropy function
options("RStata.StataPath" = "\"C:\\Program Files (x86)\\Stata11\\StataMP\"")
options("RStata.StataVersion" = 11)
```


## Datasets

We then load the datasets that we need for this study. The World Bank has processed some of these already for poverty analysis and so we have the original SPSS datasets with all variables for Households `hh` and for Individuals `pp`, as well as a consumption aggregate `ca` and a household income `ic` dataset, which are Stata datasets. This is for the year 2022. These are imported using the `haven` package. These are based on Armenia Integrated Living Conditions Survey 2022 [@armstat_integrated_2023].

```{r output=FALSE}
# Original SPSS datasets
# Households (hh)
hh <- read_sav(
  "data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Households.sav")
# Persons (pp)
pp <- read_sav(
  "data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Persons.sav")

# Processed WB datasets
# Consumption aggregate at household level (ca)
ca  <- read_dta("data/ARM-HH-survey/CONSAGG2022.dta")
# Processed income at household level (ic)
ic  <- read_dta("data/ARM-HH-survey/totinc.dta") 
```

We will work non-destructively, meaning we will not rewrite these data sets and we will only create intermediate data frame objects from them to perform transformations, selections and other data management tasks. For example, we will keep household assignment to poverty status and consumption deciles handy by creating a subset of our `ca` data with only our household identifiers, deciles, and poverty.

```{r warning=FALSE, message=FALSE}
# From the WB processed dataset, we extract deciles and poverty
deciles <- ca |> 
  select( hhid, decile, poor_Avpovln2022, 
          poor_Foodpovln2022, poor_Lpovln2022, poor_Upovln2022)

```

Our population data comes from UN's projections.

```{r warning=FALSE, message=FALSE}
# Population projections UN 2022
pop_proj <- read_dta("data/UN2022_population.dta") |> 
  filter(country == iso)
```

Macro scenario dataset

```{r}
scenario_file <- r"(data\ARM-Microsimulation\ARM_MacroScenarioInformation.xlsx)"
scenario_varlist <- read_xlsx(
  "data/ARM-Microsimulation/ARM_Macro_varlist.xlsx")
```


Economic sectors.

```{r}
sectors <- read_xlsx("data/ARM-HH-survey/economic_activity_codes.xlsx")
```

We also have geographical information for level 1 in Shapefile format, which we import with the `sf` package. We rename the column with the name of the administrative region to match our household survey data set conventions to ease mergers. The `dplyr` package from the `tidyverse` meta package allows us to "pipe" or link processing steps using the `|>` pipe, which can be inserted using **Ctrl + m.** Although there is no geoprocessing in this analysis, this will come in handy for graphical presentations. Let's have a look at it.

```{r warning=FALSE, message=FALSE}
# Geodata
# Armenia marzes or administrative level 1 shapefile
adm1 <- read_sf("data/ARM-Geodata/ARM-ADM1.shp") |> 
  select(NAM_1, COD_HH_SVY, geometry) |> 
    # Make sure that names match the rest of datasets
  mutate(NAM_1 = if_else(NAM_1 == "Gergharkunik", "Gegharkunik", NAM_1))
names(adm1)[2] <- "hh_02"

tm_shape(adm1)+
  tm_polygons("NAM_1", legend.show = FALSE) +
  tm_text("NAM_1", size = 3/4)
```

Marzes names are more accurate in the shapefile than in the survey. We will use them from here on instead of the survey factor labels.

```{r warning=FALSE, message=FALSE}
hh <- hh |> 
  left_join(adm1, join_by(hh_02 == hh_02)) |> 
  select(-geometry)

ic <- ic |> 
  left_join(adm1, join_by(hh_02 == hh_02)) |> 
  select(-geometry)
```

Finally, but not least important, we have our vulnerability information.

```{r warning=FALSE, message=FALSE}
buildings_aal <- 
  read_xlsx("data/ARM-Vulnerability-Analysis/Data_AAL_AAE.xlsx",
            sheet = "Building_AAL") |> 
    # Make sure that names match the rest of datasets
  mutate(NAM_1 = if_else(NAM_1 == "Gergharkunik", "Gegharkunik", NAM_1))
buildings_1in100 <-
  read_xlsx("data/ARM-Vulnerability-Analysis/Data_AAL_AAE.xlsx",
            sheet = "Building_1in100")
crops_productivity <- 
  read.csv("data/ARM-Vulnerability-Analysis/ARM_crops_combined_REF_shock_admin1.csv") |> 
  rename(NAM_1 = Province)
crops_aal <- 
  read_xlsx("data/ARM-Vulnerability-Analysis/Data_AAL_AAE.xlsx",
            sheet = "Agriculture_AAL")
crops_1in100 <-
  read_xlsx("data/ARM-Vulnerability-Analysis/Data_AAL_AAE.xlsx",
            sheet = "Agriculture_1in100")
```

## Data preparation income outliers and missings

### Household consumption aggregates and characteristics

Initial necessary variables.

```{r}
consumption_aggregates <- ca |> 
  mutate(rural = ifelse(urb_rur == 2, 1, 0),  # Create rural indicator
         yhh = totc,              # Total household expenditure
         wgt_adj = pweight) |>        # Make a copy of the weight variable 
  select(hhid, rural, hhsize,hhsize_R, marz, aepc, yhh, wgt_adj, weight, 
         Foodpovln2022, Lpovln2022, Upovln2022, Avpovln2022, 
         poor_Foodpovln2022, poor_Lpovln2022, poor_Upovln2022, 
         poor_Avpovln2022, decile )  # Keep only necessary columns
```

### Demographic characteristics, education, Labor Force

Here the original code calls for Zone data, which is not present in our dataset, due to the different administrative structure of Armenia. However, we use `hh_01_code` (settlement) for this purpose.

```{r}
# Zone data
zone_data <- hh |> 
  select(interview__key, hh_01_code, hh_02, hh_03) |> 
  mutate(
    hhid = interview__key, # Household id
    zone = hh_01_code,     # Settlement
    marz = hh_02,          # Marz
    urb_rur = hh_03        # Urban / rural
  )
```

Demographic data, merge with zone data Note that ed_03 (educy) below is not years of education, but education level (primary, general, secondary, etc.) However, it is ordered in a way that higher levels imply more years of education. We perform several steps within the first pipe call.

```{r}
demographics <- pp |>
  rename(hhid = interview__key) |> 
  left_join(zone_data, join_by( hhid == hhid))  |>  
  mutate(# Demographic characteristics
         pid = paste0(interview__key, "-", 
                      str_pad(mem_001__id, 2, pad = "0")), # Unique person id
         gender = mem_02,
         age = mem_05,
         head = ifelse(mem_03 == 1, 1, 0),
         # Education level
         educy = ifelse(is.na(ed_03) | ed_03 == 8, 0, ed_03),
         # Labor Force Status
         lstatus = case_when(
           est_03 == 1 | est_04 == 1 | est_05 == 1 | est_06 == 1 | est_09 < 7 ~ 1L,
           est_10 == 1 ~ 2L,
           est_10 == 2 ~ 3L,
           .default = 4L # Default to OLF
         ),
         employed = (lstatus == 1),
         # Salaried status (1. paid employee; 2 self-employed)
         salaried = ifelse(!is.na(emp_11a), 1L, 
                           ifelse(is.na(emp_11a) & employed == TRUE, 0L, NA_integer_))
         ) |>
  rename(rel = mem_03) # |> 
  # select(hhid, pid, gender, age, head, rel, zone, marz, urb_rur, educy,
  #        lstatus, employed, salaried, )  
```

Later, when we conduct the reweighting of the dataset, we need to summarize into three levels of education.

```{r}
demographics <- demographics %>%
  mutate(calif = case_when(
    educy >= 0 & educy <= 2 ~ "None - General",
    educy > 3 & educy <= 7 ~ "Secondary - Vocational",
    educy > 7 & educy <= 11 ~ "Higher +",
    TRUE ~ NA_character_  # This handles any values outside the specified ranges
  ))

# View the first few rows to confirm the recoding
head(demographics[,c("calif")])

```



Count the number of employed persons by household.

```{r}
demographics <- demographics |> 
  mutate(employed = (lstatus == 1)) |> 
  group_by(hhid) |> 
  mutate(employed_hh = sum(employed, na.rm = TRUE)) |>  # Count within each household 
  ungroup() 
```

Here the original Stata code calculates income variables and aggregates them by household. We skip that because the dataset "ic" already has these elements calculated by the WB poverty team. We'll add them later.

**Primary and Secondary Job income**

-   **emp_11** 11.How much was %rostertitle%'s payment for wages/salary/income for last month?
-   **emp_12** 12.What period of time was the wage/income for?
-   **emp_25** 25.How much was %rostertitle%'s payment for wages/salary/income for last month?
-   **emp_26** 26.What period of time was the wage/income for?

Bonus, In-Kind, and food from job was not asked in Armenia, If it were, you should add a mutate() statement like the ones below for each subcategory.

```{r}
demographics <- demographics |> 
  # Labor income primary job
  mutate(annual_labor_income_primary = case_when(
    emp_12 == 1 ~ emp_11 * 365,
    emp_12 == 2 ~ (emp_11/7) * 365,  # Assuming weekly rate 
    emp_12 == 3 ~ (emp_11/14) * 365,
    emp_12 == 4 ~ emp_11 * 12,
    emp_12 == 5 ~ emp_11 * 2,
    emp_12 == 6 ~ emp_11,
    emp_12 == 7 ~ NA
  ))   |> 
  # Labor income secondary job
  mutate(annual_labor_income_secondary = case_when(
    emp_26 == 1 ~ emp_25 * 365,
    emp_26 == 2 ~ (emp_25/7) * 365,  # Assuming weekly rate 
    emp_26 == 3 ~ (emp_25/14) * 365,
    emp_26 == 4 ~ emp_25 * 12,
    emp_26 == 5 ~ emp_25 * 2,
    emp_26 == 6 ~ emp_25,
    emp_26 == 7 ~ NA
  )) |> 
  # Annual labor total in thousands of dram
  mutate(annual_labor_total = (coalesce(annual_labor_income_primary, 0) + 
           coalesce(annual_labor_income_secondary, 0))/1000) 
```

26.23% employed with no labor income reported. We calculate this way:

```{r}
total_employed_no_income <- demographics |>
  filter(employed == 1 & annual_labor_total == 0) |> 
  nrow()

total_employed <- demographics |>
  filter(employed == 1) |>
  nrow()

percent_employed_no_income <- (total_employed_no_income / total_employed) * 100

print(percent_employed_no_income)

```

Let's flag outliers now

```{r}
demographics <- demographics  |> 
  # Filter for employed and positive income 
  filter(employed == 1 & annual_labor_total > 0) |> 
  mutate(
    sd = sd(annual_labor_total, na.rm = TRUE),   # Calculate standard deviation
    d = annual_labor_total / sd,                
    # Combined outlier condition
    outlier = (d > 5) | (employed == 1 & annual_labor_total == 0), 
    # Mark potential missings
    missings = (employed == 1 & annual_labor_total == 0)           
  ) 
```

Economic sector

```{r}
demographics <- demographics |>
  mutate(emp_04 = as.integer(emp_04)) |> 
  left_join(sectors, join_by("emp_04" == "economic_activity_code") ) |> 
  rename(sector = ea_shortcode)
```

Impute sector for those with missing employed by hh head sector.

Step 1: Impute sector for missing employed by the hh head sector. Adjusting the code to impute 'sector' based on the household head's 'sector'.

```{r}
demographics <- demographics |>
  group_by(hhid) |>
  mutate(
    # Convert 'head_sector' to numeric; 'sector' remains numeric
    head_sector = if_else(head == 1, sector, NA_real_)
  ) |>
  fill(head_sector, .direction = "downup") |>
  mutate(
    # Impute missing 'sector' values based on the household head's 'sector'
    # Ensure 'sector' is treated as numeric throughout
    sector = if_else(is.na(sector) & employed == 1, head_sector, sector)
  ) |>
  select(-head_sector) |>
  ungroup()
```

Step 2: Assign a specific value for missing sectors for those employed.

```{r}
demographics <- demographics |>
  mutate(sector = if_else(is.na(sector) & employed == 1, 2, sector))
```

Step 3: Replace sector with NA based on lstatus,

```{r}
demographics <- demographics |>
  mutate(sector = if_else(lstatus == 2 | lstatus == 3, NA_real_, sector))
```

Step 4: Label the sector variable. In R, factors are used to handle categorical variables with labels.

```{r}
demographics <- demographics |>
  mutate(sector = factor(sector, levels = c(0, 1, 2, 3),
                         labels = c("Unemployed", "Agriculture", 
                                    "Manufacturing", "Services"))) |> 
  mutate(sector_code = as.integer(sector))
```

Step 5: No sector for OLF and clonevar industry=sector.

```{r}
demographics <- demographics |>
  mutate(lstatus = as.numeric(lstatus),
         sector = if_else(lstatus == 4, as.character(NA), as.character(sector)),
         industry = as.factor(sector))
```

### The regression

Prepare the data.

```{r}
demographics <- demographics |>
  mutate(
    educy2 = educy^2,
    age2 = age^2,
    male = case_when(
      gender == 1 ~ 1,
      gender == 2 ~ 0
    ),
    lnlab = log(annual_labor_total),
    simuli = NA_real_ # Initialize simuli
  )
```

Filter the data for regression conditions.

```{r}
regression_data <- demographics |>
  filter(employed == 1 & outlier == 0 & missings == 0)
```

Regression model.

```{r}
model <- lm(lnlab ~ age + gender + educy + age2 + marz + emp_11a + sector, 
            data = regression_data)
```

Predict for specific conditions

```{r}
demographics <- demographics |>
  mutate(
    condition = employed == 1 & (outlier == 1 | missings == 1)
  )
```

Applying predictions.

Note: The 'predict' function in R does not directly support conditions within the function call, so we handle this by filtering or subsetting the data as needed.

temp2 equivalent - Note: 'type = "response"' might be needed depending on model type.

```{r}
demographics$simuli[demographics$condition] <- exp(
  predict(model, demographics[demographics$condition, ], type = "response"))
```

Handling negative values in 'simuli'.

```{r}
demographics <- demographics |>
  mutate(
    simuli = if_else(simuli < 0, 0, simuli)
  )
```

There were 8 observations that met the criteria:

`(employed==1 & (outlier==1 | missings == 1)).`

We will replace `annual_labor_total` with this value for those observations.

```{r}
demographics <- demographics |>
  mutate(annual_labor_total = if_else(
    employed == 1 & (outlier == 1 | missings == 1),
    simuli, annual_labor_total))
```

Merging datasets.

```{r}
demographics <- demographics |>
  left_join(consumption_aggregates, by = "hhid")
```

### Total income and shares

Total labor income at HH level.

```{r}
demographics <- demographics |>
  group_by(hhid) |>
  mutate(lab_hh = sum(annual_labor_total, na.rm = TRUE)) |>
  ungroup()
```

Monthly incomes come from the `ic` data set.

```{r}
incomes <- ic |> 
  select(interview__key, inc1, inc2, inc3, inc4, inc5, inc6, inc7, inc8)
```

Total income at HH level (the commented out portion was a less efficient way of accomplishing the same result of coalescing NAs to 0 so that the sum can be performed). Note that here we need to use the magittr pipe `%>%` instead of the newer Native Pipe `|>` , because we need to reference the correct scope with the dot `.`.

```{r}
demographics <- demographics %>%
  left_join(incomes, by = c("hhid" = "interview__key")) %>%
  mutate(across(inc5:inc8, ~replace_na(., 0))) %>%
  mutate(nli_hh = 12 * rowSums(select(., inc5:inc8), na.rm = TRUE)) %>%
  mutate(income_hh = lab_hh + nli_hh)

# demographics <- demographics |>
#   left_join(incomes, join_by(hhid == interview__key)) |> 
#   mutate(nli_hh = (  coalesce(inc5) + 
#                      coalesce(inc6) +
#                      coalesce(inc7) +
#                      coalesce(inc8)) * 12) |> 
#   mutate(income_hh = lab_hh + nli_hh)
```

Calculating shares:

```{r}
demographics <- demographics |>
  mutate(
    s_lab = lab_hh / income_hh,
    s_nli = nli_hh / income_hh,
    lny = log(income_hh),
    lnc = log(yhh), # comes from consumption aggregates
    mpc = yhh / income_hh
  )
```

Shares of labor and non-labor income, and additional calculations.

```{r}
demographics <- demographics |>
  mutate(
    share = if_else(employed == 1, annual_labor_total / lab_hh, NA_real_),
    ylb = yhh * s_lab,
    ynl = yhh * (1 - s_lab),
    ylbi = if_else(employed == 1, ylb * share, NA_real_)
  )
```

Final subset of data.

```{r}
demographics <- demographics |>
  select(hhid, pid, industry, yhh, ylb, ynl, ylbi, salaried,
         rural, hhsize,hhsize_R, marz.x, aepc, yhh, wgt_adj, weight, 
         Foodpovln2022, Lpovln2022, Upovln2022, Avpovln2022, 
         poor_Foodpovln2022, poor_Lpovln2022, poor_Upovln2022, 
         poor_Avpovln2022, decile, zone, urb_rur,
         gender, age, head, rel, zone, educy, calif, sector, sector_code) |> 
  rename(marz = marz.x)

# Exporting to Stata
write_dta(demographics, path = "outputs/MAG_assigned.dta", version = 10)
```

Exporting to Stata is necessary because we will use a custom Stata function.

## UN Population Projections and Macroeconomic Model

Now we are ready to move to our demographic projections and macroeconomic model information.

First, filtering based on country (our `iso` variable).

```{r}
pop_proj_processed <- pop_proj  |>  
  filter(country == iso)
```

Collapsing data by summing up variables starting with "yf" and "ym" and reshaping data to long format.

```{r}
pop_proj_processed <- pop_proj_processed %>%
  group_by(Variant, country) %>%
  summarise(across(starts_with(c("yf", "ym")), sum)) %>%
  ungroup()

pop_proj_processed <- pivot_longer(pop_proj_processed,
                              cols = starts_with(c("yf", "ym")),
                              names_to = c(".value", "year"),
                              names_pattern = "(yf|ym)(.*)")
```

Creating new variable `pop` as the sum of `yf` and `ym`. Dropping `yf`, `ym` and `country` variables.

```{r}
pop_proj_processed <- pop_proj_processed %>%
  mutate(pop = yf + ym) %>%
  select(-yf, -ym, -country)
```

Summarizing the year to find the range.

```{r}
summary_years <- pop_proj_processed %>%
  summarize(minyear = min(year, na.rm = TRUE), maxyear = max(year, na.rm = TRUE))

minyear <- surveyyear # Make sure `surveyyear` is correctly defined
maxyear <- as.numeric(summary_years$maxyear)

# Print the year range as a check
print(paste("Min Year:", minyear, "- Max Year:", maxyear))
```

```{r}
# With minyear and maxyear defined above
# Initialize a list to store growth data
pop_growth <- list()

# Loop over variants
variants <- unique(pop_proj_processed$Variant)
for (variant in variants) {
  for (t in minyear:maxyear) {
    
    # Calculate population for year t
    pop_t <- pop_proj_processed %>%
      filter(year == t, Variant == variant) %>%
      summarise(sum_pop = sum(pop)) %>%
      pull(sum_pop)
    
    # Calculate population for base year
    pop_base <- pop_proj_processed %>%
      filter(year == minyear, Variant == variant) %>%
      summarise(sum_pop = sum(pop)) %>%
      pull(sum_pop)
    
    # Calculate growth rate and store in list with dynamic naming
    growth_rate <- pop_t / pop_base
    pop_growth[[paste0(t, "_", variant)]] <- list(
      growth_rate = growth_rate, pop_t = pop_t
      )
  }
}

# Convert list to dataframe
pop_growth_df <- do.call(rbind, lapply(names(pop_growth), function(x) {
  # Extract year and variant from the name
  parts <- unlist(strsplit(x, "_"))
  year <- as.integer(parts[1])
  variant <- parts[2]
  
  # Create a tibble for each entry
  tibble(year = year, 
         variant = variant, 
         total_population = pop_growth[[x]]$pop_t,
         pop_growth_rate = pop_growth[[x]]$growth_rate)
}))

# Arrange the dataframe for better readability
pop_growth_df <- arrange(pop_growth_df, variant, year)

# Display the first few rows of the dataframe
head(pop_growth_df)

```

We load elasticities.

```{r}
elasticities <- c(0.82, 0.9, 0.79) # Agr, Manuf, Services
yearsto <- c(2022, 2026, 2030)
```

The following code accomplishes the following:

-   Import data from Excel sheets corresponding to each scenario and combine them into one data frame.
-   Rename columns, create a 'scenid' to identify scenarios, and merge with population projections.
-   Calculate real wages and consumption per capita.


```{r}
# Macro Scenario File imported in "Datasets" section (scenario_file) 
sheets <- excel_sheets(scenario_file)

# Define the names of the scenarios and the variants 
scenarios <- sheets[c(1)] # modify list with the tab numbers or names with scenarios
variants

# Create an empty list to store data frames for each scenario
scen_data_list <- list()

# Import data for each scenario and store it in the list
for (i in seq_along(scenarios)) {
  sheet_data <- read_excel(scenario_file, 
                           sheet = scenarios[i], 
                           range = "B3:AT41",
                           col_names = FALSE)
  sheet_data$scenario_id <- scenarios[i]
  colnames(sheet_data) <- scenario_varlist$var_short_name
  scen_data_list[[i]] <- sheet_data
  
}

# Combine all data frames into one
combined_data <- bind_rows(scen_data_list)

# Remove observations with missing year
combined_data <- combined_data %>% 
  filter(!is.na(year))

# Remove population_m from the data set because we will use 
# UN pop projections from the other data set.
combined_data <- combined_data |> 
  rename(population_m_macrodata = population_m)

# Calculate real wages
combined_data <- combined_data %>%
  mutate(rwage_agr_m_amd = wage_agr_m_amd / cpi,
         rwage_man_m_amd = wage_man_m_amd / cpi,
         rwage_ser_m_amd = wage_ser_m_amd / cpi)

# # Assign variants to each scenid
# combined_data <- combined_data %>%
#   mutate(Variant = variants[scenario_id])

# Fix pop_proj_processed type
pop_proj_processed <- pop_proj_processed |> 
  mutate(year = as.numeric(year))

# Filter population data to macro model years
pop_growth_df <- pop_growth_df |> 
  filter(year <= max(combined_data$year))
# Merge the combined data with population projections
final_data <- pop_growth_df %>%
  full_join(combined_data, by = c("year"))

# Calculate consumption per capita and other totals
final_data <- final_data %>%
  mutate(
    consumption_pc = consumption_b_amd / (total_population),
    total_employment = lab_agr_1000p + lab_man_1000p + lab_ser_1000p,
    employment_rate = working_age_pop_m / total_population
    )

# Function to add growth rate columns directly in the dataframe
calculate_growth <- function(data, value_column) {
  growth_col_name <- paste0(value_column, "_growth") # dynamic name for growth column
  data %>%
    arrange(year) %>%
    group_by(variant, scenario_id) %>%
    mutate(
      base_value = first(!!sym(value_column)),
      !!sym(growth_col_name) := !!sym(value_column) / base_value
    ) %>%
    select(-base_value) |> # optionally remove base_value column if not needed
    ungroup()
}

# Columns to calculate growth for
value_columns <- c(
  "gdp_b_amd",           # GDP
  "consumption_b_amd",   # Consumption
  "consumption_pc",      # Consumption PC
  "remittances_b_amd",   # Remittances
  "total_employment",    # Employment
  "employment_rate",     # Employment rate
  "working_age_pop_m",   # Working age population
  "va_agr_b_amd",        # Value added agriculture
  "va_man_b_amd",        # Value added manufacturing
  "va_ser_b_amd",        # Value added services
  "wage_agr_m_amd",      # Nominal wage agriculture
  "wage_man_m_amd",      # Nominal wage manufacturing
  "wage_ser_m_amd",      # Nominal wage services
  "rwage_agr_m_amd",     # Real wage agriculture
  "rwage_man_m_amd",     # Real wage manufacturing
  "rwage_ser_m_amd"      # Real wage services
  )

# Applying the growth calculation to the final_data for each column
for (col in value_columns) {
  final_data <- calculate_growth(final_data, col)
}

# Now `final_data` will have growth rate columns for each of the variables listed
# We rearrange the dataset for clarity
final_data <- final_data |> 
  relocate(scenario_id, variant, .before = year) |> 
  arrange(scenario_id, variant, year)

```

## Reweighting of the dataset

### Aggregation of population data

This is based on a custom command to reweight the survey according to macroeconomic data for every possible combination of variant, year, and country. In the macro data we know they only used the "medium" variant and we only need to reweight for a specific year (2030) for Armenia (ARM), so we will conduct the reweighting directly with these parameters.


```{r}
pop_data <- pop_proj %>%
  filter(country == "ARM", Variant == "Medium") %>%
  # Recoding cohorts into ordered factors
  mutate(cohort = factor(case_when(
    cohort %in% c("P0004", "P0509") ~ "P0009",
    cohort %in% c("P1014", "P1519") ~ "P1019",
    cohort %in% c("P2024", "P2529") ~ "P2029",
    cohort %in% c("P3034", "P3539") ~ "P3039",
    cohort %in% c("P4044", "P4549") ~ "P4049",
    cohort %in% c("P5054", "P5559") ~ "P5059",
    cohort %in% c("P6064", "P6569") ~ "P6069",
    cohort %in% c("P7074", "P7579", "P8084", "P8589", "P9094", "P9599", "P100up") ~ "P70up"
  ), levels = c("P0009", "P1019", "P2029", "P3039", "P4049", "P5059", "P6069", "P70up"))) %>%
  # Convert factor 'cohort' to numeric codes
  mutate(cohort_code = as.integer(cohort)) %>%
  # Pivoting longer to turn year columns into rows
  pivot_longer(
    cols = starts_with("y"),
    names_to = "year_gender",
    values_to = "population"
  ) %>%
  # Extracting year and gender from the combined column
  mutate(
    year = readr::parse_number(year_gender),
    gender = if_else(str_detect(year_gender, "ym"), "male", "female"),
    year_gender = NULL  # Removing the combined column
  ) %>%
  # Grouping by cohort, year, and gender to summarize
  group_by(cohort, year, gender) %>%
  summarise(
    total_population = sum(population, na.rm = TRUE),
    .groups = 'drop'
  ) %>%
  # Spreading gender to create separate columns for males and females
  pivot_wider(
    names_from = gender,
    values_from = total_population
  ) %>%
  # Calculate the total population as the sum of male and female
  mutate(
    total = male + female
  )

# Checking the resulting dataset
print(pop_data)

```

The guidance Stata code creates a popdatatot file, but we already created `pop_proj_processed` with that information before in this code, so we will use that and just filter by variant when it's time to use it. 

Then some checks are performed.

```{r}
# Filter out missing education data
demographics <- demographics %>%
  filter(!is.na(calif))  # Keeps only rows where 'calif' is not NA

# Check if the target year is within the specified range
target_year <- 2030  # Example target year
if(target_year < 1991 || target_year > 2100) {
  stop("Target year is out of range.")
}

```


Let's now create cohorts in our `demographics` data to match our population projection data.

```{r}
# Convert 'age' into 'cohort' factor with levels ordered as specified
demographics <- demographics %>%
  mutate(cohort = factor(case_when(
    age >= 0 & age <= 9 ~ "P0009",
    age >= 10 & age <= 19 ~ "P1019",
    age >= 20 & age <= 29 ~ "P2029",
    age >= 30 & age <= 39 ~ "P3039",
    age >= 40 & age <= 49 ~ "P4049",
    age >= 50 & age <= 59 ~ "P5059",
    age >= 60 & age <= 69 ~ "P6069",
    age >= 70 ~ "P70up"
  ), levels = c("P0009", "P1019", "P2029", "P3039", "P4049", "P5059", "P6069", "P70up")))

# Convert the 'cohort' factor to numeric codes
demographics <- demographics %>%
  mutate(cohort_code = as.integer(cohort))
```

We also need demographic targets for 2030

```{r}
# Ensure pop_targets_2030 is correctly prepared
pop_targets_2030 <- pop_data %>%
  filter(year == 2030) %>%
  select(cohort, male, female)

# Join demographic targets with demographics
demographics <- demographics %>%
  left_join(pop_targets_2030, by = "cohort")
```

And economic targets from our macroeconomic scenario data.

```{r}
economic_targets_2030 <- final_data %>%
  filter(year == 2030, variant == "Medium", scenario_id == "baseline") %>%
  summarise(
    target_lab_agr = sum(lab_agr_1000p * 1000),
    target_lab_man = sum(lab_man_1000p * 1000),
    target_lab_ser = sum(lab_ser_1000p * 1000)
  )
```


We create our demographic targets

```{r}
# Adjust weights for demographic targets
demographics <- demographics %>%
  mutate(
    sector = as.character(sector),  # Convert sector to character for direct comparison
    adj_ratio_male = ifelse(gender == 1, male / sum(weight * (gender == 1)), 1),
    adj_ratio_female = ifelse(gender == 2, female / sum(weight * (gender == 2)), 1)
  ) %>%
  mutate(
    adjusted_weight = weight * case_when(
      gender == 1 ~ adj_ratio_male,
      gender == 2 ~ adj_ratio_female,
      TRUE ~ 1  # Default case if gender isn't 1 or 2
    )
  )

# Add economic targets and adjust weights for sector
demographics <- demographics %>%
  mutate(
    target_lab_agr = economic_targets_2030$target_lab_agr,
    target_lab_man = economic_targets_2030$target_lab_man,
    target_lab_ser = economic_targets_2030$target_lab_ser
  ) %>%
  group_by(sector) %>%
  mutate(
    total_lab_force = sum(adjusted_weight),
    adjusted_weight = case_when(
      sector == "Agriculture" ~ adjusted_weight * (target_lab_agr / total_lab_force),
      sector == "Manufacturing" ~ adjusted_weight * (target_lab_man / total_lab_force),
      sector == "Services" ~ adjusted_weight * (target_lab_ser / total_lab_force),
      TRUE ~ adjusted_weight  # Keep weights for non-labor force sectors unchanged
    )
  ) %>%
  ungroup()
```


### Wentropy in Stata

We need to prepare our dataset for wentropy in Stata. First we check our weights

```{r}
# Verify adjusted totals by sector
check_totals <- demographics %>%
  group_by(sector) %>%
  summarise(
    total_weight = sum(adjusted_weight),
    .groups = 'drop'
  )

# Print out the check totals to see if they match with economic_targets_2030
print(check_totals)

```

And save as Stata dataset.

```{r}
# Save the adjusted demographics to a .dta file
write_dta(demographics, path = "outputs/demographics_2030.dta", version = 10)
```

Now we create the constraints matrix.

```{r}
# Assuming 'demographics' has been properly prepared with 'cohort_code', 'sector_code', 'gender' as numeric and 'adjusted_weight'
# Calculate the total adjusted weights for each combination of cohort, sector, and gender
constraints_matrix <- demographics %>%
  group_by(cohort_code, sector_code, gender) %>%
  summarise(
    total_weight = sum(adjusted_weight),
    .groups = 'drop'
  ) %>%
  pivot_longer(
    cols = total_weight,
    names_to = "constraint",
    values_to = "weight"
  ) %>%
  # Ensure the matrix is a single column of weights
  select(weight)

# Print the constraints matrix to check it
print(constraints_matrix)

# Save the constraints matrix to a .dta file for use in Stata
write_dta(constraints_matrix, path = "outputs/constraints_matrix_2030.dta", version = 10)

# This single-column format should now be directly usable in Stata's wentropy command


# Assuming demographics data has been prepared with adjusted weights
# and contains 'cohort_code', 'sector_code', 'gender', and 'adjusted_weight'

# Calculate the total adjusted weights for each combination
constraints_matrix <- demographics %>%
  group_by(cohort_code, sector_code, gender) %>%
  summarise(
    total_weight = sum(adjusted_weight),
    .groups = 'drop'
  ) %>%
  arrange(cohort_code, sector_code, gender) %>%
  # Ensure it's a column vector for Stata
  transmute(constraint_value = total_weight)

# Print the constraints matrix to check it
print(constraints_matrix)

# Save the constraints matrix to a .dta file for use in Stata
write_dta(constraints_matrix, path = "outputs/constraints_matrix_2030.dta", version = 10)


```

Let's use raking to recalculate weights

```{r}

library(anesrake)
library(dplyr)

# Calculate target proportions -----------------------

# Cohort proportions (male and female within cohorts)
cohort_targets_prop <- pop_targets_2030 %>% 
  mutate(across(where(is.numeric), proportions)) %>%
  rename(cohort_code = cohort)

# Sector proportions (single value for all cohorts)
sector_targets_prop <- economic_targets_2030 %>% 
  mutate(across(where(is.numeric), proportions)) %>%
  summarise(across(where(is.numeric), mean)) %>%  # Calculate mean across sectors
  mutate(sector_code = mean(c(2, 3, 4))) 

# Function for iterative raking within cohorts ---------
rake_within_cohort <- function(df_cohort, cohort_prop, sector_mean) {
  # Get the matching cohort proportions 
  cohort_row <- cohort_prop[cohort_prop$cohort_code == df_cohort$cohort[1], ] 

  # Create the 'targets' list (renamed for clarity)
  raking_targets <- list(gender = cohort_row[["male"]], 
                  sector_code = sector_mean) 

  raked_weights <- anesrake(targets = raking_targets, # Pass the renamed list
                          dat = df_cohort, 
                          caseid = "hhid", 
                          weightvec = df_cohort$weight, 
                          verbose = FALSE, 
                          cap = 5, 
                          choosemethod = "total", 
                          type = "pctlim", 
                          pctlim = 0.05, 
                          iterate = TRUE) 
  df_cohort$raked_weights <- raked_weights$weightvec
  return(df_cohort)
}

# Apply raking to each cohort --------------------------
demographics <- demographics %>% 
  group_by(cohort) %>%  # Using 'cohort' here (matches pop_targets_2030)
  do(rake_within_cohort(., cohort_targets_prop, mean(sector_targets_prop$sector_code)))

# Reminder: Validate the raked weights (demographics$raked_weights) to ensure they match expectations!
 
```








