---
title: "Armenia CCDR Microsimulation"
author:
  - name: "Renato Vargas"
    id: rv
    email: renovargas@gmail.com
    affiliation: 
      - name: Consultant for The World Bank
            
format:
  html:
    toc: true
    number-sections: true
    number-depth: 3
    highlight-style: github
  docx:
    toc: true
    number-sections: true
    highlight-style: arrow
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
editor: source
editor_options: 
  chunk_output_type: console
bibliography: references.bib
csl: apa-6th-edition.csl
---


## Introduction

In this calculation file, we "age" the household survey according to demographic projections and different macroeconomic scenarios to explore the impact of climate-related risks and policy measures on the consumption expenditure distribution. It is part of a larger project with all contributions to Armenia's CCDR, which can be [downloaded from GitHub](https://github.com/rvconsulting/armenia-ccdr) in the form of an [Rstudio project](https://support.posit.co/hc/en-us/articles/200526207-Using-RStudio-Projects).

As a convention, code is presented in the following format in this guide:


```{r}
#| eval: false

# Some comment that is not evaluated by R
some_variable <- some_function(some_object, some_parameter = TRUE)
```


We assume that the reader has created an Rstudio project and is familiar with basic R functions. Within that project we recommend the following file structure:

``` txt
root/
├── scripts
│   └── my_script.R
├── data/
|   ├── my_data.sav
|   ├── my_data.dta
|   └── my_data.csv
└── output
    ├── my_output1.csv
    └── my_output2.xlsx
```

Using RStudio project makes it possible to not use `setwd()` to establish the root directory and refer to subdirectories in a relative manner, making interoperability easier within teams and not hard coding a particular computer's file structure into the code. If you are not using RStudio, just add `setwd(r'(C:\My\path\to\project\root)')` at the beginning of your coding session.

## Preamble

We start with a clean environment, making sure that any objects from a previous session are not present. We take this opportunity to keep our country ISO code in a variable `iso` in case we need it later.


```{r}
#| warning: false
#| message: false

# Clean workspace
rm(list = ls())

# Armenia country ISO code
iso <- "ARM"

# Survey year
survey_year <- 2022

# Exchange rate USD per dram
er <- 0.002310

# Years of interest for our macroeconomic scenario analysis
analysis_years <- c(2030)
```


We call the appropriate libraries.

Rather than calling our libraries as we go, we will make sure we have everything we need from the beginning.


```{r}
#| output: false
#| lst-label: lst-load-packages

library(tidyverse) # includes dplyr, ggplot2, purr...
library(haven)     # to read SPSS and Stata datasets
library(readxl)    # to read from MS-Excel
library(openxlsx)  # to write to MS-Excel.
library(gt)        # pretty tables
library(car)       # companion to applied regression
library(modelr)    # regression models
#library(anesrake)  
# Raking reweighting but we don't load it, because 
# it changes the meaning of summarize from dplyr, 
# so we use the form anesrake::anesrake() when using it.
#library(ebal)      # Entropy reweighting (not used)
library(janitor)   # pretty subtotals
library(broom)     # More regressions
library(zoo)       # Calculate moving window average and max value
# library(ineq) # Inequality measures
# library(acid)

# Geopackages
library(sf)        # to read and write shapefile maps
library(terra)     # to perform geocalculations
library(tmap)      # for static and interactive maps
```


## Datasets

We then load the datasets that we need for this study. The World Bank has processed some of these already for poverty analysis and so we have the original SPSS datasets with all variables for Households `hh` and for Individuals `pp`, as well as a consumption aggregate `ca` and a household income `ic` dataset, which are Stata datasets. This is for the year 2022. These are imported using the `haven` package. These are based on Armenia Integrated Living Conditions Survey 2022 [@armstat_integrated_2023]. We take this oportunity to standardize the household identification variable to `household_id`.


```{r}
#| warning: false
#| message: false
#| output: false
#| lst-label: original-datasets

# Households (hh)
hh <- read_sav(
  "data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Households.sav") %>% 
  rename(household_id = interview__key)
# Persons (pp)
pp <- read_sav(
  "data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Persons.sav") %>% 
  rename(household_id = interview__key)
# Consumption aggregate at household level (ca)
ca  <- read_dta("data/ARM-HH-survey/CONSAGG2022.dta") %>% 
  rename(household_id = hhid)
# Processed income at household level (ic)
ic  <- read_dta("data/ARM-HH-survey/totinc.dta") %>% 
  rename(household_id = interview__key)
# Food diary
food_with_prices <- read_dta("data/ARM-HH-survey/FOOD_with_prices_short.dta")%>% 
  rename(household_id = hhid)
```


We will work non-destructively, meaning we will not rewrite these data sets and we will only create intermediate data frame objects from them to perform transformations, selections and other data management tasks. For example, we will keep household assignment to poverty status and consumption deciles handy by creating a subset of our `ca` data with only our household identifiers, deciles, and poverty.


```{r}
#| lst-label: lst-deciles
#| warning: FALSE
#| message: FALSE

# From the WB processed dataset, we extract deciles and poverty
deciles <- ca %>% 
  select( household_id, decile, poor_Avpovln2022, 
          poor_Foodpovln2022, poor_Lpovln2022, poor_Upovln2022)
```


Our population data comes from UN's projections.


```{r}
#| warning: FALSE
#| message: FALSE 
#| lst-label: lst-population-projections

population_projections <- read_dta("data/UN2022_population.dta") %>% 
  filter(country == iso) # we filter for Armenia
```


The macro scenario dataset is an input provided by the Macroeconomic CGE simulation team, with yearly information on GDP, working age population, employment by economic activity (for an aggregation of three sectors: agriculture, manufacturing, and services), wages by economic activity, value added by economic activity, remittances, consumer price index, food price index and energy price index (for a bundle of gas, oil, coal, electricity) by decile (10 representative households in the macro model), and carbon tax revenue transfers to household deciles.


```{r}
#| warning: false
#| message: false
#| output: false
#| lst-label: lst-import-macro-scenarios


scenario_file <- "data/ARM-Microsimulation/ARM_MacroScenarioInformation.xlsx"
scenario_varlist <- read_xlsx(
  "data/ARM-Microsimulation/ARM_Macro_varlist.xlsx")
prices_2030 <- 
  read.csv("data/ARM-Microsimulation/prices2030.csv")
```


Economic Activities in the Survey is in Armenian. The following dataset is a lookup table with the English names.


```{r}
#| lst-label: lst-import-economic-activity-codes

sectors <- read_xlsx("data/ARM-HH-survey/economic_activity_codes.xlsx")
```


We also have geographical information for level 1 in Shapefile format, which we import with the `sf` package. We rename the column with the name of the administrative region to match our household survey data set conventions to ease mergers. The `dplyr` package from the `tidyverse` meta package allows us to "pipe" or link processing steps using the `%>%` pipe. Although there is no geoprocessing in this analysis, this will come in handy for graphical presentations.


```{r}
#| warning: false 
#| message: false
#| lst-label: lst-import-geodata

# Armenia marzes or administrative level 1 shapefile
adm1 <- read_sf("data/ARM-Geodata/ARM-ADM1.shp") %>% 
  select(COD_HH_SVY, NAM_1, geometry) %>% 
  # Make sure that names match the rest of datasets
  mutate(NAM_1 = if_else(NAM_1 == "Gergharkunik", "Gegharkunik", NAM_1)) %>% 
  # Sort by number
  arrange(COD_HH_SVY)
# We rename with the survey designation
names(adm1) <- c("marz_no","marz", "geometry") 

```


And we plot it for reference (see @fig-map-example). This is done with the tmap R package and the code shown in @lst-map-example.


```{r}
#| lst-label: lst-map-example
#| lst-cap: "Plotting a map with with the tmap package"
#| label: fig-map-example
#| fig-cap: "Map of Armenia at administrative level 1 (ADM1)"

tm_shape(adm1)+
  tm_polygons("marz", legend.show = FALSE) +
  tm_text("marz", size = 3/4)
```


Marzes names are more accurate in the shapefile than in the survey. We will use them from here on instead of the survey factor labels.


```{r}
#| warning: FALSE
#| message: FALSE 
#| lst-label: lst-marz-name-from-geodata
#| lst-cap: "Marz name from geodata"

adm1_names <- adm1 %>% 
  select(-geometry)

hh <- hh %>% 
  left_join(adm1_names, join_by(hh_02 == marz_no))

ic <- ic %>% 
  left_join(adm1_names, join_by(hh_02 == marz_no))

rm(adm1_names)
```


We also have an Excel file with changes to labor productivity due to climate variability. We bind together the datasets found in each Excel sheet.


```{r}
#| lst-label: lst-import-labor-productivity-data
#| lst-cap: "Import labor productivity data"

file <- "data/ARM-Microsimulation/LaborProductivityChanges.xlsx"
sheets <- excel_sheets(file)

# Use lapply to read and process each sheet
labor_productivity <- lapply(sheets, function(sheet) {
  info <- read_excel(
    file,
    sheet = sheet,
    col_names = TRUE,
    col_types = c("text", "text", "numeric", "text", "numeric")
  )
  info$sector <- sheet
  return(info)
})

# Bind all data frames in the list into a single data frame
labor_productivity <- bind_rows(labor_productivity)
```


Finally, we have our climate vulnerability information. For this analysis we only use the `crops_productivity` and `livestock_productivity` that comes from *Estimating the Economic Impacts of Climate Change in Armenia* [@strzepek_estimating_2024].


```{r}
#| warning: false 
#| message: false
#| lst-label: lst-import-vulnerability-data
#| lst-cap: "Import crops and livestock yield loss data"

crops_productivity <- 
  read.csv("data/ARM-Vulnerability-Analysis/ARM_crops_combined_REF_shock_admin1.csv") %>% 
  rename(marz = Province)
livestock_productivity <-
  read.csv(
    "data/ARM-Vulnerability-Analysis/ARM_livestock_REF_shock_admin1.csv"
    ) %>% 
  rename(marz = Province)
```


## Data preparation income outliers and missings

We start with various renames for standardization. Naming conventions in the guidance code use traditional abbreviations like `nli` for non-lablor income. We are opting for more descriptive variable names like `non_labor_income`, `labor_income`, etc. to have more easily readable code. We make an exception for total consumption, because it's a variable that we use in every scenario and it supersedes lenght limits when adding scenario identifiers.


```{r}
ca <- ca %>% 
  rename(urban_rural = urb_rur,
         tc = totc)
```



### Household consumption aggregates and characteristics

Initial necessary variables. 


```{r}
#| lst-label: lst-consumption-aggregates

poverty_designations <- ca %>%
  mutate(rural_dummy = ifelse(urban_rural == 2, 1, 0)) %>%
  select(household_id, rural_dummy, hhsize,hhsize_R, tc, marz, aepc, weight, 
         Foodpovln2022, Lpovln2022, Upovln2022, Avpovln2022, 
         poor_Foodpovln2022, poor_Lpovln2022, poor_Upovln2022, 
         poor_Avpovln2022, decile )  # Keep only necessary columns
```


### Demographic characteristics, education, labor force

Here the original code calls for Zone data, which is not present in our dataset, due to the different administrative structure of Armenia. However, we use `hh_01_code` (settlement) for this purpose. In the end, this variable was never used.


```{r}
#| label: lst-zone-data

zone_data <- hh %>% 
  select(household_id, hh_01_code, hh_02, hh_03, marz) %>% 
  rename(
    household_id  = household_id, # Household id
    settlement    = hh_01_code,   # Settlement
    marz_no       = hh_02,        # Marz
    urban_rural   = hh_03         # 1 = urban, 2 = rural
  )
```


Demographic data, merge with zone data Note that ed_03 (educy) below is not years of education, but education level (primary, general, secondary, etc.) However, it is ordered in a way that higher levels imply more years of education. We perform several steps within the first pipe call. The variable `lstatus` (Labor Force Status) here is very important for the reweigthing of the dataset later on. Note that from here onwards we will be creating `_microsim` versions of our datasets with the transformations needed for calculations. That way we avoid changing our original data and can refer to it later without fearing we've left things behind.


```{r}
#| label: lst-demographic-characteristics

pp_microsim <- pp %>%
  rename(household_id = household_id) %>%
  left_join(zone_data, join_by(household_id))  %>%
  mutate(
    # Demographic characteristics
    # Unique person id
    person_id = paste0(household_id, "-", str_pad(mem_001__id, 2, pad = "0")),
    head = ifelse(mem_03 == 1, 1, 0),
    # Education level
    educy = ifelse(is.na(ed_03) | ed_03 == 8, 0, ed_03),
    # Labor Force Status
    lstatus = case_when(
      # 1. Employed
      est_03 == 1 | est_04 == 1 | est_05 == 1 |
        est_06 == 1 | est_08 == 1 ~ 1L,
      # 2. Unemployed (available, and searching)
      est_10 == 1 ~ 2L,
      # 3. Inactive (available, not searching)
      est_10 == 2 ~ 3L,
      # Out of the labor force
      .default = 4L # Default to OLF
    ),
    employed = (lstatus == 1),
    # Salaried status (1. paid employee; 2 self-employed)
    salaried = ifelse(
      !is.na(emp_11a),
      1L,
      ifelse(is.na(emp_11a) &
               employed == TRUE, 0L, NA_integer_)
    )
  ) %>%
  rename(rel = mem_03, # relationship to HH head
         gender = mem_02,
         age = mem_05)
```


Later, when we conduct the reweighting of the dataset, we need to summarize into three levels of education.


```{r}
#| label: lst-education-information

pp_microsim <- pp_microsim %>%
  mutate(calif = case_when(
    educy >= 0 & educy <= 2 ~ "None - General",
    educy > 3 & educy <= 7 ~ "Secondary - Vocational",
    educy > 7 & educy <= 11 ~ "Higher +",
    TRUE ~ NA_character_  # Values outside the specified ranges
  ))
```


Count the number of employed persons by household. Note that it is necessary to explicitly tell R to ignore missing values(`NA`). This is different from Stata where `1 + .= 1` (where `.` is "missing"). In R 1 + `NA` = `NA` (where `NA` means "not available"). Not adding `na.rm = TRUE` to aggregation functions such as `sum()` in @lst-employed-hh below will not throw an error and only provide a column with `NA` for households where at least one individidual has an employed status of `NA`.


```{r}
#| lst-label: lst-employed-hh
#| lst-cap: "Employed in household"

pp_microsim <- pp_microsim %>% 
  mutate(employed = (lstatus == 1)) %>% 
  group_by(household_id) %>% 
  # Count within each household
  mutate(employed_hh = sum(employed, na.rm = TRUE)) %>%   
  ungroup() 
```


Here the original Stata code calculates income variables and aggregates them by household. We skip that because the dataset `ic` already has these elements calculated by the WB poverty team. We'll add them later as we need them.

However, as we'll see later labor income information is heavily non-reported in the dataset. Labor income is a crucial step in merging the dataset with macroeconomic information and so we will predict income for those that do not report it below. These variables are related to labor income, amount and frequency, which we have to standardized to a monthly or yearly value.

**Primary and Secondary Job income:**

-   **emp_11** How much was %rostertitle%'s payment for wages/salary/income for last month?
-   **emp_12** What period of time was the wage/income for?
-   **emp_25** How much was %rostertitle%'s payment for wages/salary/income for last month?
-   **emp_26** What period of time was the wage/income for?

Bonus, In-Kind, and food from job was not asked in Armenia, If it were, you should add a `mutate()` statement like the ones below for each subcategory in @lst-annualized-labor-income. We use `coalesce(colname, 0)` when adding the `annual_labor_total` again to prevent sums of `NA`'s. This function replaces a value with 0 within the calculation if it's missing, but doesn't change its value permanently.


```{r}
#| lst-label: lst-annualized-labor-income
#| lst-cap: "Annualized labor income"

pp_microsim <- pp_microsim %>% 
  # Labor income primary job
  mutate(annual_labor_income_primary = case_when(
    emp_12 == 1 ~ emp_11 * 365,
    emp_12 == 2 ~ (emp_11/7) * 365,  # Assuming weekly rate 
    emp_12 == 3 ~ (emp_11/14) * 365,
    emp_12 == 4 ~ emp_11 * 12,
    emp_12 == 5 ~ emp_11 * 2,
    emp_12 == 6 ~ emp_11,
    emp_12 == 7 ~ NA
  ))   %>% 
  # Labor income secondary job
  mutate(annual_labor_income_secondary = case_when(
    emp_26 == 1 ~ emp_25 * 365,
    emp_26 == 2 ~ (emp_25/7) * 365,  # Assuming weekly rate 
    emp_26 == 3 ~ (emp_25/14) * 365,
    emp_26 == 4 ~ emp_25 * 12,
    emp_26 == 5 ~ emp_25 * 2,
    emp_26 == 6 ~ emp_25,
    emp_26 == 7 ~ NA
  )) %>% 
  # Annual labor total in thousands of dram
  mutate(annual_labor_total = 
           (coalesce(annual_labor_income_primary, 0) + 
           coalesce(annual_labor_income_secondary, 0))/1000)

# Restore annual_labor_total to NA if both NA
pp_microsim <- pp_microsim %>% 
  mutate(annual_labor_total =
           if_else(
             is.na(annual_labor_income_primary)
             & is.na(annual_labor_income_secondary),
         NA, 
         annual_labor_total))
```


Now we need to check the share of individuals that are employed, but did not report income. This is done in @lst-employed-no-income below.


```{r}
#| lst-label: lst-employed-no-income
#| lst-cap: "Employed with no income reported"

total_employed_no_income <- pp_microsim %>%
  filter(employed == TRUE & is.na(annual_labor_total)) %>% 
  nrow()

total_employed <- pp_microsim %>%
  filter(employed == TRUE) %>%
  nrow()

percent_employed_no_income <- 
  (total_employed_no_income / total_employed) * 100

print(
  paste0(
    "There is ",
    format(
      percent_employed_no_income,digits = 2, nsmall=2
      ),
    "% of the employed population that reports no income.")
  )
```


We also need to mark income outliers as those with incomes outside 5 standard deviations.


```{r}
#| label: lst-employed-outliers

pp_microsim <- pp_microsim  %>% 
  mutate(
    # Calculate standard deviation
    sd = sd(annual_labor_total, na.rm = TRUE), 
    d = annual_labor_total / sd,                
    # Combined outlier condition
    outlier = (d > 5) | (employed == TRUE & annual_labor_total == 0), 
    # Mark potential missings
    missings = if_else(employed == TRUE, is.na(annual_labor_total), NA) 
  ) 
```


Economic sector. The economic sectors dataset contains a lookup table for sector aggregation which we add to the `pp_microsim` database in @lst-sector-aggregation.


```{r}
#| lst-label: lst-sector-aggregation
#| lst-cap: "Sector aggregation"

pp_microsim <- pp_microsim %>%
  mutate(emp_04 = as.integer(emp_04)) %>% 
  left_join(sectors, join_by("emp_04" == "economic_activity_code") ) %>% 
  rename(sector = ea_shortcode)
```


Some individuals report no sector for either their primary or secondary job. In @lst-assign-sector we find out the sector of other family members in their home and assign the sector of whoever is closest using `fill( other_sector, .direction = "downup")`.


```{r}
#| lst-label: lst-assign-sector
#| lst-cap: "Assign sector to those who don't report one"

pp_microsim <- pp_microsim %>%
  group_by(household_id) %>%
  mutate(
    # Create a temporary variable 'other_sector'
    # which captures the sector of any employed 
    # individual in the household
    other_sector = 
      if_else(employed == TRUE & !is.na(sector), sector, NA_real_)
  ) %>%
  # Use 'fill' to propagate 'other_sector' values within the household
  fill(other_sector, .direction = "downup") %>%
  mutate(
    # Impute missing 'sector' values based on the 'other_sector'
    sector = 
      if_else(is.na(sector) & employed == TRUE, other_sector, sector)
  ) %>%
  # Drop the temporary 'other_sector' variable
  select(-other_sector) %>%
  ungroup()
```


We then assign a specific value for missing sectors for those employed with no one else in the hh to assign value. We select services as it's the heaviest sector in the dataset (we do it like this, instead of say, any matching technique, because it's only 2 observations).


```{r}
#| lst-label: lst-sector-no-alternatives

pp_microsim <- pp_microsim %>%
  mutate(sector = if_else(is.na(sector) & employed == TRUE, 3, sector))
```


We provide value labels for sector factors.


```{r}
#| lst-label: lst-sector-labels

pp_microsim <- pp_microsim %>%
  mutate(sector_name = factor(sector, levels = c(1, 2, 3),
                         labels = c("Agriculture", 
                                    "Manufacturing", 
                                    "Services")))
```


We make sure that those outside the labor force (OLF) do not report a sector, which we replace with `NA` for those who meet the condition.


```{r}
#| lst-label: lst-no-sector-olf
#| lst-cap: "No sector for OLF"

pp_microsim <- pp_microsim %>%
  mutate(lstatus = as.numeric(lstatus),
         sector = 
           if_else(lstatus == 4, 
                   as.character(NA), 
                   as.character(sector)),
         industry = as.factor(sector)) %>%
  # We need this for reweighting and 
  # not messing up the regression below.
  mutate(sector_w = sector)
```


### The regression

Since labor income was a key variable, which we needed to match with the future wage bill by economic activity, we first checked for missing values among employed individuals. We found that almost a third of respondents (28.6%) did not report income for either their primary or secondary job. To overcome this limitation, we used the available information from the remaining respondents to estimate an extended Mincer equation, as shown in @eq-labor-income-regression, and implemented in @lst-regression-model. For the respondents with available information, we also identified outliers as those outside of five standard deviations from the mean labor income.

$$
\ln(lab_i) = \beta_0 + \beta_1 \text{age}_i + \beta_2 \text{gender}_i + \beta_3 \text{educy}_i + \beta_4 \text{age}^2_i + \beta_5 \text{marz}_i + \beta_6 \text{sector}_i + \epsilon_i
$$ {#eq-labor-income-regression}

Where:

-   $\ln(lab_i)$ is the natural logarithm of labor income for individual $i$.
-   $\beta_0$ is the intercept term.
-   $\beta_1, \beta_2, \beta_3, \beta_4, \beta_5, \beta_6$ are the coefficients for the respective independent variables.
-   $\text{age}_i$ is the age of individual $i$.
-   $\text{gender}_i$ is a binary variable indicating the gender of individual $i$ (1 for male, 2 for female).
-   $\text{educy}_i$ represents the level of education for individual $i$ (ordered: 1) None to General, 2) Secondary to Vocational, 3) Higher education).
-   $\text{age}^2_i$ is the square of the age of individual $i$, included to capture non-linear effects of age on labor income.
-   $\text{marz}_i$ represents the region where individual $i$ resides.
-   $\text{sector}_i$ represents the sector of employment for individual $i$ (i.e., agriculture, manufacturing or services).
-   $\epsilon_i$ is the error term for individual $i$.

We first prepare our variables for the regression.


```{r}
pp_microsim <- pp_microsim %>%
  mutate(
    educy2 = educy^2,
    age2 = age^2,
    male = case_when(
      gender == 1 ~ 1,
      gender == 2 ~ 0
    ),
    lnlab = log(annual_labor_total),
    simuli = NA_real_ # Initialize simuli
  )
```


Filter the data for regression conditions.


```{r}
regression_data <- pp_microsim %>%
  filter(employed == TRUE & outlier == FALSE & missings == FALSE)
```


Regression model.


```{r}
#| lst-label: lst-regression-model
#| lst-cap: "Income regression model"

model <- lm(lnlab ~ age + gender + educy + age2 + marz + sector, 
            data = regression_data)
```


Predict for specific conditions


```{r}
pp_microsim <- pp_microsim %>%
  mutate(
    condition = (lstatus == 1 & (outlier == TRUE | missings == TRUE))
  )
```


Applying predictions.

Note: The 'predict' function in R does not directly support conditions within the function call, so we handle this by filtering or subsetting the data as needed.

temp2 equivalent - Note: 'type = "response"' might be needed depending on model type.


```{r}
pp_microsim$simuli[pp_microsim$condition==TRUE] <- exp(
  predict(model, pp_microsim[pp_microsim$condition==TRUE, ], type = "response"))
```


Handling negative values in 'simuli'.


```{r}
pp_microsim <- pp_microsim %>%
  mutate(
    simuli = if_else(simuli < 0, 0, simuli)
  )
```


There were 8 observations that met the criteria:

We will replace `annual_labor_total` with this value for those observations.


```{r}
pp_microsim <- pp_microsim %>%
  mutate(annual_labor_total = if_else(
    employed == TRUE & (outlier == TRUE | missings == TRUE),
    simuli, annual_labor_total))

# And get monthly incomes for everyone
pp_microsim <- pp_microsim %>% 
  mutate(monthly_labor_income = annual_labor_total / 12)

```


Merging datasets.


```{r}
pp_microsim <- pp_microsim %>%
  left_join(poverty_designations, by = "household_id")
```


### Total income and shares

Total labor income at HH level.


```{r}
pp_microsim <- pp_microsim %>%
  group_by(household_id) %>%
  mutate(lab_hh = sum(annual_labor_total, na.rm = TRUE)) %>%
  ungroup()
```


Monthly incomes come from the `ic` data set.


```{r}
incomes <- ic %>% 
  select(household_id, inc1, inc2, inc3, inc4, inc5, inc6, inc7, inc8)
```


Total income at HH level (the commented out portion was a less efficient way of accomplishing the same result of coalescing NAs to 0 so that the sum can be performed). Note that here we need to use the magittr pipe `%>%` instead of the newer Native Pipe `%>%` , because we need to reference the correct scope with the dot `.`.


```{r}
pp_microsim <- pp_microsim %>%
  left_join(incomes, by = c("household_id" = "household_id")) %>%
  mutate(across(inc5:inc8, ~replace_na(., 0))) %>%
  mutate(nli_hh = 12 * rowSums(select(., inc5:inc8), na.rm = TRUE)) %>%
  mutate(income_hh = lab_hh + nli_hh)

# pp_microsim <- pp_microsim %>%
#   left_join(incomes, join_by(household_id == household_id)) %>% 
#   mutate(nli_hh = (  coalesce(inc5) + 
#                      coalesce(inc6) +
#                      coalesce(inc7) +
#                      coalesce(inc8)) * 12) %>% 
#   mutate(income_hh = lab_hh + nli_hh)
```



Final subset of data.


```{r}
pp_microsim <- pp_microsim %>%
  select(household_id, person_id, industry, salaried,
         rural_dummy, hhsize,hhsize_R, marz_no, aepc, weight, 
         Foodpovln2022, Lpovln2022, Upovln2022, Avpovln2022, 
         poor_Foodpovln2022, poor_Lpovln2022, poor_Upovln2022, 
         poor_Avpovln2022, decile, settlement, urban_rural,
         gender, age, head, rel, educy, calif, sector, sector_name,
         annual_labor_total,annual_labor_income_primary,
         annual_labor_income_secondary,monthly_labor_income,
         lstatus, sector_w, marz.x ) %>%
  rename(marz = marz.x)

# Exporting to Stata (might be necessary for reweigthing with wentropy)
# write_dta(pp_microsim, path = "outputs/pp_microsim.dta", version = 10)
```


## UN Population Projections

Now we are ready to move to our demographic projections and macroeconomic model information.

First, filtering based on country (our `iso` variable).


```{r}
population_projections <- population_projections  %>%  
  filter(country == iso)
```


Collapsing data by summing up variables starting with "yf" and "ym" and reshaping data to long format.


```{r}
#| warning: false
#| message: false

population_projections <- population_projections %>%
  group_by(Variant, country, cohort) %>%
  summarize(across(starts_with(c("yf", "ym")), sum)) %>%
  ungroup()

population_projections <- pivot_longer(population_projections,
                              cols = starts_with(c("yf", "ym")),
                              names_to = c(".value", "year"),
                              names_pattern = "(yf|ym)(.*)")
```


Creating new variable `total_population` as the sum of `yf` and `ym`. Dropping `country` variables.


```{r}
population_projections <- population_projections %>%
  mutate(total_population = yf + ym) %>%
  select( -country) %>% 
  mutate(year = as.numeric(year))
```


Summarizing the year to find the range.


```{r}
minyear <- survey_year # Make sure `survey_year` is correctly defined
maxyear <- max(as.numeric(population_projections$year))
```


We have that the "Min Year" is `r .QuartoInlineRender(minyear)` and the "Max Year" is `r .QuartoInlineRender(maxyear)`. Now we create a population growth rate by demographic variant dataset. We initialize an empty list to store our data by variant and we loop over variants to create this list.


```{r}
# With minyear and maxyear defined above
# Initialize a list to store growth data
pop_growth <- list()

# Loop over variants
variants <- unique(population_projections$Variant)
for (variant in variants) {
  for (t in minyear:maxyear) {
    
    # Calculate population for year t
    pop_t <- population_projections %>%
      filter(year == t, Variant == variant) %>%
      summarize(sum_pop = sum(total_population)) %>%
      pull(sum_pop)
    
    # Calculate population for base year
    pop_base <- population_projections %>%
      filter(year == minyear, Variant == variant) %>%
      summarize(sum_pop = sum(total_population)) %>%
      pull(sum_pop)
    
    # Calculate growth rate and store in list with dynamic naming
    growth_rate <- pop_t / pop_base
    pop_growth[[paste0(t, "_", variant)]] <- list(
      growth_rate = growth_rate, pop_t = pop_t
      )
  }
}
```


With the list ready, we convert back to dataframe by stitching the list elements one on top of the other.


```{r}
# Convert list to dataframe
pop_growth <- do.call(rbind, lapply(names(pop_growth), function(x) {
  # Extract year and variant from the name
  parts <- unlist(strsplit(x, "_"))
  year <- as.integer(parts[1])
  variant <- parts[2]
  
  # Create a tibble for each entry
  tibble(year = year, 
         variant = variant, 
         total_population = pop_growth[[x]]$pop_t,
         pop_growth_rate = pop_growth[[x]]$growth_rate)
}))

# Arrange the dataframe for better readability
pop_growth <- arrange(pop_growth, variant, year)

# Display the first few rows of the dataframe
pop_growth[c(1:09),]
```


## Macro Scenarios

Here we use the Excel tab names to create the names of the scenarios going forward, with a previous cleaning in which we convert names to lower case, replace spaces and special characters with underscores, we remove the word scenario from the name, and remove leading or trailing spaces or underscores.


```{r}
#| output: false
#| warning: false
#| message: false

# Macro Scenario File imported in "Datasets" section (scenario_file) 
sheets <- excel_sheets(scenario_file)
scenario_sheets <- sheets[c(1,2,3)]

# Define the names of the scenarios and the variants
# modify list with the tab numbers in the Excel file
scenarios <- scenario_sheets %>%
  # Convert all text to lowercase
  str_to_lower() %>%  
  # Replace all spaces and hyphens with underscores
  str_replace_all("[ -]", "_") %>%
  # Remove the word 'scenario' or 'scenarios'
  str_remove_all("scenario?s?") %>%
  # Remove leading and trailing underscores
  str_replace_all("^_+|_+$", "")  

```


Our scenarios are: `r .QuartoInlineRender(glue::glue_collapse(scenarios, sep = ', ', last = ', and '))`. We now import data from Excel sheets corresponding to each scenario and combine them into one data frame.


```{r}
#| output: false
#| warning: false
#| message: false

# Create an empty list to store data frames for each scenario
scen_data_list <- list()

# Import data for each scenario and store it in the list.
# Note the trick where we use the index `i` from `scenarios`
# but access the scenario_sheets name to fetch the Excel
# tab.
for (i in seq_along(scenarios)) {
  sheet_data <- read_excel(scenario_file, 
                           sheet = scenario_sheets[i], 
                           range = "B3:AT31",
                           col_names = FALSE)
  sheet_data$scenario_id <- scenarios[i]
  colnames(sheet_data) <- scenario_varlist$var_short_name
  scen_data_list[[i]] <- sheet_data
}

# Combine all data frames into one
macro_data <- bind_rows(scen_data_list)
# Remove unnecessary list
rm(scen_data_list)
```


We then rename columns, create a 'scenid' to identify scenarios, and merge with population projections. Calculate real wages


```{r}
# Rename population_m from the data set because we will use 
# UN pop projections from the other data set.
macro_data <- macro_data %>% 
  rename(population_m_macrodata = population_m)

```


We prepare our population data to combine it with the macro data.


```{r}
pop_data <- population_projections %>% 
  group_by(Variant, year) %>% 
  summarize(female = sum(yf),
            male = sum(ym),
            total_population = sum(total_population) ) %>% 
  ungroup()

# Filter population data to macro model years
pop_data <- pop_data %>% 
  filter(year <= max(macro_data$year),
         Variant == variants[7])
# Merge the combined data with population projections
macro_data <- macro_data %>%
  left_join(pop_data, by = c("year"))
```


There are some calculated variables that we need to estimate.


```{r}
# Calculate real wages
macro_data <- macro_data %>%
  # These result in billion AMD because employment in 1000s
  # and wages in million AMD p/person p/year.
  mutate(rwage_agr_m_amd = 
           (wage_agr_m_amd * lab_agr_1000p) / cpi, 
         rwage_man_m_amd = 
           (wage_man_m_amd * lab_man_1000p) / cpi,
         rwage_ser_m_amd = 
           (wage_ser_m_amd* lab_ser_1000p) / cpi,
         # We also rescale jobs and tot pop to millions
         total_population = total_population / 1000,
         lmarket_1 = lab_agr_1000p/1000, 
         lmarket_2 = lab_man_1000p/1000,  
         lmarket_3 = lab_ser_1000p/1000)
```


We calculate columns for the totals by labor market group so we can derive our shares.


```{r}
macro_data <- macro_data %>%
  mutate(
    lmarket_4 = 
      working_age_pop_m - (lmarket_1 + lmarket_2 + lmarket_3),
    lmarket_5 = 
      (total_population) - working_age_pop_m
  )

# And we label these variables
attr(macro_data$total_population, 
     "label") <- "Total population (million)"
attr(macro_data$lmarket_1, 
     "label") <- "Employed in agriculture (million)"
attr(macro_data$lmarket_2, 
     "label") <- "Employed in manufacturing (million)"
attr(macro_data$lmarket_3, 
     "label") <- "Employed in services (million)"
attr(macro_data$lmarket_4, 
     "label") <- "Unemployed and inactive (million)"
attr(macro_data$lmarket_5, 
     "label") <- "Outside the labor force (million)"
```




With our demographic data added to our macroeconomic data, we need to estimate relative growth of some of the variables. For this we create a function to estimate growth per column to a named list of column.


```{r}
# Function to add growth rate columns directly in the dataframe
calculate_growth <- function(data, value_column) {
  growth_col_name <- paste0(value_column, "_growth") # dynamic name for growth column
  data %>%
    arrange(year) %>%
    group_by(Variant, scenario_id) %>%
    mutate(
      base_value = first(!!sym(value_column)),
      !!sym(growth_col_name) := !!sym(value_column) / base_value
    ) %>%
    select(-base_value) %>% # optionally remove base_value column if not needed
    ungroup()
}

# Columns to calculate growth for
value_columns <- c(
  "rwage_agr_m_amd",     # Real wage agriculture
  "rwage_man_m_amd",     # Real wage manufacturing
  "rwage_ser_m_amd",     # Real wage services
  "lmarket_1",
  "lmarket_2",
  "lmarket_3",
  "lmarket_4",
  "lmarket_5"
  )

```


We create the list and pass it to the function.


```{r}
# Using purrr to apply the function column-wise, without a for loop.
macro_data <- reduce(value_columns, calculate_growth, .init = macro_data)

# We relocate some variables for clarity.
macro_data <- macro_data %>% 
  relocate(scenario_id, Variant, .before = year) %>% 
  arrange(scenario_id, Variant, year)

```


Now that `macro_data` has growth rate columns for each of the variables. We can check, for example, the employment and wage growth rates for our three scenarios in the year 2030 (see ).



```{r}
#| label: tbl-lmarket-growth
#| tbl-cap: "Labor market growth by category in the year 2030"

macro_data[macro_data$year==2030,c(
  c("scenario_id",
    "lmarket_1_growth",
    "lmarket_2_growth",
    "lmarket_3_growth",
    "lmarket_4_growth", 
    "lmarket_5_growth")
)] %>% 
  gt(rowname_col = "scenario_id") %>%
  cols_label(
    lmarket_1_growth = md("Agriculture"),
    lmarket_2_growth = md("Manufacturing"),
    lmarket_3_growth = md("Services"),
    lmarket_4_growth = md("Unemployed"),
    lmarket_5_growth = md("OLF")
  ) %>%
  fmt_number(columns = everything(),
             decimals = 2)
```

```{r}
#| label: tbl-wage-growth
#| tbl-cap: "Wage bill growth by sector in the year 2030"

macro_data[macro_data$year==2030,c(
  c("scenario_id",
    "rwage_agr_m_amd_growth", 
    "rwage_man_m_amd_growth",
    "rwage_ser_m_amd_growth")
)] %>% 
  gt(rowname_col = "scenario_id") %>%
  cols_label(
    rwage_agr_m_amd_growth = md("Agriculture"),
    rwage_man_m_amd_growth = md("Manufacturing"),
    rwage_ser_m_amd_growth = md("Services")
  ) %>%
  fmt_number(columns = everything(),
             decimals = 2)
```



## Reweighting of the dataset

### Aggregation of population data

This is based on a custom command to reweight the survey according to macroeconomic data for every possible combination of variant, year, and country. In the macro data we know they only used the "medium" variant and we only need to reweight for a specific year (2030) for Armenia (ARM), so we will conduct the reweighting directly with these parameters.

We join several cohorts from 0 to 29 years old and from 60 onwards, because the reweighting procedure works best if each category is at least 5% of the population. The solution here works best for Armenia.


```{r}
population_projections <- population_projections %>%
  # filter(Variant == "Medium") %>%
  # Recoding cohorts into ordered factors
    mutate(
      cohort_short = factor(
        case_when(
          cohort %in% 
            c("P0004", "P0509","P1014",
              "P1519","P2024", "P2529") ~ "P0029",
          cohort %in% 
            c("P3034", "P3539") ~ "P3039",
          cohort %in% 
            c("P4044", "P4549") ~ "P4049",
          cohort %in% 
            c("P5054", "P5559") ~ "P5059",
          cohort %in% 
            c("P6064", "P6569","P7074", "P7579",
              "P8084", "P8589", "P9094", "P9599",
              "P100up") ~ "P60up"), 
        levels = 
          c("P0029", "P3039", "P4049",
            "P5059", "P60up"))) %>%
  # Get also factor 'cohort' to numeric codes
  mutate(cohort_code = as.integer(cohort_short))

```


Let's now create cohorts in our `pp_microsim` data to match our population projection data.


```{r}
# Convert 'age' into 'cohort' factor with levels ordered as specified
pp_microsim <- pp_microsim %>%
    mutate(cohort = factor(case_when(
    age >= 0  & age <= 29 ~ "P0029",
    age >= 30 & age <= 39 ~ "P3039",
    age >= 40 & age <= 49 ~ "P4049",
    age >= 50 & age <= 59 ~ "P5059",
    age >= 60  ~ "P60up"
  ), levels = c("P0029", "P3039", "P4049", "P5059", "P60up")))

# Convert the 'cohort' and 'gender' factor to numeric codes
pp_microsim <- pp_microsim %>%
  mutate(cohort_code = as.integer(cohort)) %>% 
  mutate(gender_code = as.integer(gender))

```


We also need demographic targets for 2030


```{r}
#| warning: false
#| message: false

# Ensure pop_targets_2030 is correctly prepared
# We use the "Medium" variant = variants[7]
pop_targets_2030 <- population_projections  %>% 
  filter(year == 2030, Variant == variants[7])  %>% 
  group_by(cohort_code, cohort_short) %>% 
    summarize(female = sum(yf),
              male   = sum(ym), 
              total = sum(total_population),
              ) %>%
  ungroup()

pop_total <- sum(pop_targets_2030$total)

pop_targets_2030 <- pop_targets_2030 %>% 
  mutate(pct_total = total / pop_total)

#writeClipboard(pop_targets_2030)
# write.table(pop_targets_2030, "clipboard", sep="\t", row.names=FALSE)
  
```


And economic targets from our macroeconomic scenario data. We deal with this later. Should come back to fix this so we can automate.


```{r}
# economic_targets_2030 <- macro_data %>%
#   filter(year == 2030, Variant == "Medium", scenario_id == "baseline") %>%
#   summarize(
#     target_lab_agr = sum(lab_agr_1000p * 1000),
#     target_lab_man = sum(lab_man_1000p * 1000),
#     target_lab_ser = sum(lab_ser_1000p * 1000)
#  )
```


For a better representation of the labor market, we will take into account the combination between labor status and economic sector of the employed and adjust that combination according to the macrodata so that we can accurately model changes in total employment, sector distribution of the employed and overall population changes.


```{r}
pp_microsim <- pp_microsim %>% 
  mutate(lmarket = case_when(
    lstatus == 1 & sector_w  == 1  ~ 1,   # Agriculture
    lstatus == 1 & sector_w  == 2  ~ 2,   # Manufactures
    lstatus == 1 & sector_w  == 3  ~ 3,   # Services
    lstatus == 2 & is.na(sector_w) ~ 4,   # Unemployed
    lstatus == 3 & is.na(sector_w) ~ 4,   # Unemployed
    lstatus == 4 & is.na(sector_w) ~ 5,   # OLF
    
  ))
```


Note that the differences between the totals of the survey and the macro file for the base year are very much different. We'll adjust the survey only with relative growth instead of total numbers so that labor income doesn't change completely.

### Reweigting

We use anesrake to calculate targets from known future proportions of sex, age, economic sector. We first create a target list.


```{r}
# Target for each variable

gender_code <- c(
  sum(pop_targets_2030$male)   / 
    (sum(pop_targets_2030$male)+ sum(pop_targets_2030$female)), 
  sum(pop_targets_2030$female) / 
    (sum(pop_targets_2030$male)+ sum(pop_targets_2030$female)))

cohort_code <- pop_targets_2030$pct_total

# Four digits are better than two in this case, raking is quite accurate.
lmarket_baseline <- c(0.1325, 0.0495, 0.2598, 0.2451, 0.3132)
lmarket_dry_hot  <- c(0.1348, 0.0490, 0.2582, 0.2459, 0.3120)
lmarket_nzs      <- c(0.1237, 0.0510, 0.2594, 0.2488, 0.3171)
# Note how similar the scenarios are

# Target list baseline
targets_baseline <- list(gender_code
                , cohort_code
                , lmarket_baseline
                )

names(targets_baseline) <- c("gender_code", 
                    "cohort_code", 
                    "lmarket"
                    )

# Target list Dry/Hot
targets_dry_hot <- list(gender_code
                , cohort_code
                , lmarket_dry_hot
                )

names(targets_dry_hot) <- c("gender_code", 
                    "cohort_code", 
                    "lmarket"
                    )

# Target list NZS
targets_nzs <- list(gender_code
                , cohort_code
                , lmarket_nzs
                )

names(targets_nzs) <- c("gender_code", 
                    "cohort_code", 
                    "lmarket"
                    )

```


And now we perform the reweighting, using the original weights. Initially we had used the default option type = "pctlim" combined with pctlim=0.05, because the method recommends that if reweighting changes for one variable according to its target are not of at least 5%, then it's not worth burdening the procedure with it. It then ignored sex as a reweighting variable, leaving a small percentage difference between the target and the final population. However, we then tried removing this limitation and the procedure reached convergence in 33 iterations very efficiently.


```{r}
# Since this uses base R, we need to turn the data frame into base R object
rakedata <- as.data.frame(pp_microsim)

anesrake::anesrakefinder(targets_baseline, rakedata, choosemethod = "total")

outsave <- anesrake::anesrake(targets_baseline, 
                    rakedata, 
                    caseid = rakedata$person_id, 
                    #verbose = FALSE,
                    choosemethod = "total",
                    #type = "pctlim",
                    type = "nolim",
                    #cap = 100,
                    #pctlim = 0.05,
                    nlim = 3,
                    iterate = TRUE,
                    force1 = TRUE,
                    verbose = TRUE,
                    weightvec = rakedata$weight)

#summary(outsave)

# add weights to the dataset

rakedata$weight_2030_baseline  <- unlist(outsave[1])
n  <- length(rakedata$sector)

# Calculate the sum of original weights
original_weight_sum <- sum(rakedata$weight)

# # Target scaling for original weights

original_weight_scaling_factor <-
  pop_data$total_population[pop_data$year == 2030] /
  pop_data$total_population[pop_data$year == 2022]

# Scaled original weights
original_weight_sum <- (original_weight_sum 
                        * original_weight_scaling_factor)

# Calculate the sum of the new weights
new_weight_sum <- sum(rakedata$weight_2030_baseline)

# Scale the new weights to match the sum of the original weights
scaling_factor <- original_weight_sum / new_weight_sum
rakedata$weight_2030_baseline <- rakedata$weight_2030_baseline * scaling_factor

# Verify the adjustment
head(rakedata[, c("weight", "weight_2030_baseline")])
summary(rakedata$weight_2030_baseline)
summary(rakedata$weight)

hh_size <- rakedata %>% 
  select(household_id, hhsize) %>% 
  mutate(ones = 1,
         hhsize_old = hhsize) %>% 
  group_by(household_id) %>% 
  summarize(hhsize = sum(ones, na.rm = TRUE)) %>% 
  ungroup()

rakedata <- rakedata %>%
  rename(hhsize_old = hhsize) %>% 
  left_join(hh_size, join_by(household_id)) %>% 
  relocate(weight, .before = weight_2030_baseline) %>% 
  mutate(hh_weight_2030_baseline = weight_2030_baseline / hhsize)

pp_microsim <- tibble(rakedata)
rm(rakedata)

```


We now do the Dry/Hot Scenario. The efficient way of doing this is through a loop or sapply, but as we're strapped for time we will just repeat the code. (Needs rework.)


```{r}
# Since this uses base R, we need to turn the data frame into base R object
rakedata <- as.data.frame(pp_microsim)

anesrake::anesrakefinder(targets_dry_hot, rakedata, choosemethod = "total")

outsave <- anesrake::anesrake(targets_dry_hot, 
                    rakedata, 
                    caseid = rakedata$person_id, 
                    #verbose = FALSE,
                    choosemethod = "total",
                    #type = "pctlim",
                    type = "nolim",
                    #cap = 100,
                    #pctlim = 0.05,
                    nlim = 3,
                    iterate = TRUE,
                    force1 = TRUE,
                    verbose = TRUE,
                    weightvec = rakedata$weight)

#summary(outsave)

# add weights to the dataset

rakedata$weight_2030_dry_hot  <- unlist(outsave[1])

# Calculate the sum of original weights
original_weight_sum <- sum(rakedata$weight)

# Target scaling for original weights

original_weight_scaling_factor <-
  pop_data$total_population[pop_data$year == 2030] /
  pop_data$total_population[pop_data$year == 2022]

# Scaled original weights
original_weight_sum <- (original_weight_sum 
                        * original_weight_scaling_factor)

# Calculate the sum of the new weights
new_weight_sum <- sum(rakedata$weight_2030_dry_hot)

# Scale the new weights to match the sum of the original weights
scaling_factor <- original_weight_sum / new_weight_sum
rakedata$weight_2030_dry_hot <- rakedata$weight_2030_dry_hot * scaling_factor

# Verify the adjustment
head(rakedata[, c("weight", "weight_2030_dry_hot")])
summary(rakedata$weight_2030_dry_hot)
summary(rakedata$weight)

rakedata <- rakedata %>% 
  mutate(hh_weight_2030_dry_hot = weight_2030_dry_hot / hhsize)

pp_microsim <- tibble(rakedata)
rm(rakedata)

```


Let's add the NZS scenario


```{r}
# Since this uses base R, we need to turn the data frame into base R object
rakedata <- as.data.frame(pp_microsim)

anesrake::anesrakefinder(targets_nzs, rakedata, choosemethod = "total")

outsave <- anesrake::anesrake(targets_nzs, 
                    rakedata, 
                    caseid = rakedata$person_id, 
                    #verbose = FALSE,
                    choosemethod = "total",
                    #type = "pctlim",
                    type = "nolim",
                    #cap = 100,
                    #pctlim = 0.05,
                    nlim = 3,
                    iterate = TRUE,
                    force1 = TRUE,
                    verbose = TRUE,
                    weightvec = rakedata$weight)

#summary(outsave)

# add weights to the dataset

rakedata$weight_2030_nzs  <- unlist(outsave[1])

# Calculate the sum of original weights
original_weight_sum <- sum(rakedata$weight)

# Target scaling for original weights

original_weight_scaling_factor <-
  pop_data$total_population[pop_data$year == 2030] /
  pop_data$total_population[pop_data$year == 2022]

# Scaled original weights
original_weight_sum <- (original_weight_sum 
                        * original_weight_scaling_factor)

# Calculate the sum of the new weights
new_weight_sum <- sum(rakedata$weight_2030_nzs)

# Scale the new weights to match the sum of the original weights
scaling_factor <- original_weight_sum / new_weight_sum
rakedata$weight_2030_nzs <- rakedata$weight_2030_nzs * scaling_factor

# Verify the adjustment
head(rakedata[, c("weight", "weight_2030_nzs")])
summary(rakedata$weight_2030_nzs)
summary(rakedata$weight)

rakedata <- rakedata %>% 
  mutate(hh_weight_2030_nzs = weight_2030_nzs / hhsize)

```


Weights for the household database


```{r}
# We calculate new weights for households in the hh database
weights_scenarios <- rakedata %>% 
  group_by(household_id) %>%
  summarize(
    hh_weight_2030_baseline = 
      sum(hh_weight_2030_baseline, na.rm = TRUE),
    hh_weight_2030_dry_hot = 
      sum(hh_weight_2030_dry_hot, na.rm = TRUE),
    hh_weight_2030_nzs = 
      sum(hh_weight_2030_nzs, na.rm = TRUE)
    )

# We return rakedata to data frame pp_microsim and get rid of rakedata
pp_microsim <- tibble(rakedata)
rm(rakedata)

```


### Rescaling labor income according to changes to the wage bill

As a last step, we rescale labor income according to changes to the wage bill in the macro scenario.


```{r}
# Wage rescale factor by sector from macro (Agriculture, Manufacturing, Services)
wrf_2030_baseline  <- c(1.22786496, 1.32301655, 1.34032297)
wrf_2030_dry_hot   <- c(1.24850624, 1.27740284, 1.30020020)
wrf_2030_nzs       <- c(1.05423642, 1.30685398, 1.27521304)

# We check the wage bill by sector
wages_by_sector <- pp_microsim %>%
  filter(!is.na(sector_w)) %>% 
  group_by(sector_w, .drop = TRUE) %>% 
  summarize(
    wages_2022 = sum(annual_labor_total * weight, na.rm = TRUE),
    wages_2030_baseline = 
      sum(annual_labor_total * weight_2030_baseline, na.rm = TRUE),
    wages2030_dry_hot   = 
      sum(annual_labor_total * weight_2030_dry_hot, na.rm = TRUE),
    wages2030_nzs   = 
      sum(annual_labor_total * weight_2030_nzs, na.rm = TRUE)
  )


# Compare how much it changed with reweighting with how it should have changed
# Derive coefficients (wtc_2030) from that
wages_by_sector <- wages_by_sector %>% 
  mutate(
    wages_target_2030_baseline = case_when(
      sector_w == 1 ~ wages_2022 * wrf_2030_baseline[1],
      sector_w == 2 ~ wages_2022 * wrf_2030_baseline[2],
      sector_w == 3 ~ wages_2022 * wrf_2030_baseline[3],
      .default = NA
    ),
    wages_target2030_dry_hot = case_when(
      sector_w == 1 ~ wages_2022 * wrf_2030_dry_hot[1],
      sector_w == 2 ~ wages_2022 * wrf_2030_dry_hot[2],
      sector_w == 3 ~ wages_2022 * wrf_2030_dry_hot[3],
      .default = NA
    ),
    wages_target2030_nzs = case_when(
      sector_w == 1 ~ wages_2022 * wrf_2030_nzs[1],
      sector_w == 2 ~ wages_2022 * wrf_2030_nzs[2],
      sector_w == 3 ~ wages_2022 * wrf_2030_nzs[3],
      .default = NA
    ),
    wtc_2030_baseline = wages_target_2030_baseline / wages_2030_baseline,
    wtc_2030_dry_hot = wages_target2030_dry_hot / wages2030_dry_hot,
    wtc_2030_nzs = wages_target2030_nzs / wages2030_nzs
    ) 

# wages_by_sector %>%
#   gt()
# write.table(wages_by_sector, "clipboard", sep="\t", row.names=FALSE)
```


We then add the coefficient to rescale each wage by sector


```{r}
# Assign rescale the annual and monthly wage depending on the sector
# Quick way, but needs to be put in a sapply statement or loop
pp_microsim <- pp_microsim %>% 
  rename(monthly_labor_income_2022 = monthly_labor_income,
         annual_labor_total_2022 = annual_labor_total) %>% 
  mutate(
    monthly_labor_income_2030_baseline = case_when(
      sector_w == 1 ~ monthly_labor_income_2022 * wages_by_sector$wtc_2030_baseline[1],
      sector_w == 2 ~ monthly_labor_income_2022 * wages_by_sector$wtc_2030_baseline[2],
      sector_w == 3 ~ monthly_labor_income_2022 * wages_by_sector$wtc_2030_baseline[3],
      TRUE ~ NA
    ),
    annual_labor_total_2030_baseline = case_when(
      sector_w == 1 ~ annual_labor_total_2022 * wages_by_sector$wtc_2030_baseline[1],
      sector_w == 2 ~ annual_labor_total_2022 * wages_by_sector$wtc_2030_baseline[2],
      sector_w == 3 ~ annual_labor_total_2022 * wages_by_sector$wtc_2030_baseline[3],
      TRUE ~ NA
    ),
    monthly_labor_income_2030_dry_hot = case_when(
      sector_w == 1 ~ monthly_labor_income_2022 * wages_by_sector$wtc_2030_dry_hot[1],
      sector_w == 2 ~ monthly_labor_income_2022 * wages_by_sector$wtc_2030_dry_hot[2],
      sector_w == 3 ~ monthly_labor_income_2022 * wages_by_sector$wtc_2030_dry_hot[3],
      TRUE ~ NA
    ),
    annual_labor_total_2030_dry_hot = case_when(
      sector_w == 1 ~ annual_labor_total_2022 * wages_by_sector$wtc_2030_dry_hot[1],
      sector_w == 2 ~ annual_labor_total_2022 * wages_by_sector$wtc_2030_dry_hot[2],
      sector_w == 3 ~ annual_labor_total_2022 * wages_by_sector$wtc_2030_dry_hot[3],
      TRUE ~ NA
    ),
    monthly_labor_income_2030_nzs = case_when(
      sector_w == 1 ~ monthly_labor_income_2022 * wages_by_sector$wtc_2030_nzs[1],
      sector_w == 2 ~ monthly_labor_income_2022 * wages_by_sector$wtc_2030_nzs[2],
      sector_w == 3 ~ monthly_labor_income_2022 * wages_by_sector$wtc_2030_nzs[3],
      TRUE ~ NA
    ),
    annual_labor_total_2030_nzs = case_when(
      sector_w == 1 ~ annual_labor_total_2022 * wages_by_sector$wtc_2030_nzs[1],
      sector_w == 2 ~ annual_labor_total_2022 * wages_by_sector$wtc_2030_nzs[2],
      sector_w == 3 ~ annual_labor_total_2022 * wages_by_sector$wtc_2030_nzs[3],
      TRUE ~ NA
    )
    )

# This takes care of different household members coming from different sectors
hh_li <- pp_microsim %>% 
  group_by(household_id) %>% 
  summarize(mli_2022 = sum(monthly_labor_income_2022, na.rm = TRUE),
            mli_2030_baseline = sum(monthly_labor_income_2030_baseline, na.rm = TRUE),
            mli_2030_dry_hot = sum(monthly_labor_income_2030_dry_hot, na.rm = TRUE),
            mli_2030_nzs = sum(monthly_labor_income_2030_nzs, na.rm = TRUE),
            mli_coef_2030_baseline = if_else(mli_2022 == 0, 1, mli_2030_baseline / mli_2022),
            mli_coef_2030_dry_hot = if_else(mli_2022 == 0, 1, mli_2030_dry_hot / mli_2022),
            mli_coef_2030_nzs = if_else(mli_2022 == 0, 1, mli_2030_nzs / mli_2022)
            )%>% 
  select(household_id,
         mli_2022,
         mli_2030_baseline,
         mli_2030_dry_hot,
         mli_2030_nzs,
         mli_coef_2030_baseline, 
         mli_coef_2030_dry_hot,
         mli_coef_2030_nzs)
  
ic_microsim <- ic %>% 
  left_join(hh_li, join_by(household_id == household_id)) %>%
  left_join(weights_scenarios, join_by(household_id == household_id)) %>% 
  rename(inc2_2022 = inc2,
         inc3_2022 = inc3,
         totalinc_2022 = totalinc) %>% 
  mutate(
    mli_coef_2030_baseline = 
      if_else(
        is.na(mli_coef_2030_baseline), 1,mli_coef_2030_baseline),
    mli_coef_2030_dry_hot = 
      if_else(
        is.na(mli_coef_2030_dry_hot), 1,mli_coef_2030_dry_hot),
    mli_coef_2030_nzs = 
      if_else(
        is.na(mli_coef_2030_nzs), 1,mli_coef_2030_nzs)
    ) %>% 
  mutate(
    inc2_2030_baseline = inc2_2022 * mli_coef_2030_baseline,
    inc3_2030_baseline = inc3_2022 * mli_coef_2030_baseline,
    inc2_2030_dry_hot  = inc2_2022 * mli_coef_2030_dry_hot,
    inc3_2030_dry_hot  = inc3_2022 * mli_coef_2030_dry_hot,
    inc2_2030_nzs  = inc2_2022 * mli_coef_2030_nzs,
    inc3_2030_nzs  = inc3_2022 * mli_coef_2030_nzs
    ) %>% 
  mutate(
    totalinc_2030_baseline = 
      totalinc_2022 - coalesce(inc2_2022,0) - coalesce(inc3_2022,0) + 
      coalesce(inc2_2030_baseline,0) + coalesce(inc3_2030_baseline,0),
    totalinc_2030_dry_hot = 
      totalinc_2022 - coalesce(inc2_2022,0) - coalesce(inc3_2022,0) + 
      coalesce(inc2_2030_dry_hot,0) + coalesce(inc3_2030_dry_hot,0),
    totalinc_2030_nzs_noctr = 
      totalinc_2022 - coalesce(inc2_2022,0) - coalesce(inc3_2022,0) + 
      coalesce(inc2_2030_nzs,0) + coalesce(inc3_2030_nzs,0)
    ) 

# Calculate quantiles and create 'breaks'
breaks <- Hmisc::wtd.quantile(ic_microsim$totalinc_2030_nzs_noctr, 
                             weights = ic_microsim$hh_weight_2030_nzs, 
                             probs = seq(0.1, 0.9, 0.1))

# Assign decile groups directly without creating an intermediate income_decile column
ic_microsim <- ic_microsim %>%
  mutate(totalinc_2030_nzs_noctr =
           if_else(is.na(totalinc_2030_nzs_noctr), 0,totalinc_2030_nzs_noctr)) %>% 
  mutate(income_decile_group = cut(totalinc_2030_nzs_noctr, 
                                   breaks = c(-Inf, breaks, Inf),
                                   labels = 1:10, 
                                   include.lowest = TRUE))

income_decile_group <- ic_microsim %>% 
  select(household_id, income_decile_group)


```

```{r}
ic_microsim <- ic_microsim %>% 
  mutate(
    totinc_coef_2030_baseline = 
      if_else(
        totalinc_2022 == 0, 
        1, 
        totalinc_2030_baseline / totalinc_2022),
    totinc_coef_2030_dry_hot = 
      if_else(
        totalinc_2022 == 0, 
        1, 
        totalinc_2030_dry_hot / totalinc_2022),
    totinc_coef_2030_nzs_noctr = 
      if_else(
        totalinc_2022 == 0, 
        1, 
        totalinc_2030_nzs_noctr / totalinc_2022)
    ) %>% 
  mutate(
    totinc_coef_2030_baseline = 
      if_else(
        is.na(totinc_coef_2030_baseline), 
        1, 
        totinc_coef_2030_baseline),
    totinc_coef_2030_dry_hot = 
      if_else(
        is.na(totinc_coef_2030_dry_hot), 
        1, 
        totinc_coef_2030_dry_hot),
    totinc_coef_2030_nzs_noctr = 
      if_else(
        is.na(totinc_coef_2030_nzs_noctr), 
        1, 
        totinc_coef_2030_nzs_noctr)
    )


ic_coef_scenarios <- ic_microsim %>%
  select(
    household_id, 
    totinc_coef_2030_baseline, 
    totinc_coef_2030_dry_hot,
    totinc_coef_2030_nzs_noctr
    )
```


We check that our reweighting was successful


```{r}
# table <- pp_microsim %>%
#   group_by(cohort) %>%
# #  group_by(lmarket) %>%
# #  group_by(gender) %>%
#   summarize(no_weight = sum(n(), na.rm = TRUE),
#             total_pp = sum(weight, na.rm = TRUE)) %>%
#   ungroup()
# 
# table %>%
#   gt() %>%
#   fmt_number(columns = total_pp, decimals = 0)
# 
# write.table(
#   table,
#   "clipboard", sep="\t", row.names=FALSE
#   )

```


## Microsimulation

We now implement different shocks according to various scenarios.

### Macro scenarios without additional impacts

For the baseline we only adjust labor income according to the reweighting procedure and rescaling of the wage bill.


```{r}
ca_microsim <- ca %>% 
  left_join(weights_scenarios, join_by(household_id == household_id)) %>% 
  left_join(ic_coef_scenarios, join_by(household_id == household_id)) %>% 
  # We adjust total consumption by the income coefficient
  rename(
    tc_2022 = tc,
    poor_Avpovln2022_2022 = poor_Avpovln2022
    ) %>% 
  mutate(
    tc_2030_baseline   = tc_2022 * totinc_coef_2030_baseline,
    tc_2030_dry_hot    = tc_2022 * totinc_coef_2030_dry_hot,
    tc_2030_nzs_noctr  = tc_2022 * totinc_coef_2030_nzs_noctr
    )
```


Here we add back the tax revenue

Add back carbon tax revenue. We estimated weighted income deciles above and mapped number of households by decile. We divided the revenue by that number and we add that amount by the first four income deciles in this manner. Again, another one calculated in Excel because of time constraints. Needs fixing to make automatic.


```{r}
ca_microsim <- ca_microsim %>%
  left_join(income_decile_group, join_by(household_id == household_id)) %>%
  mutate(
    tc_2030_nzs =
      # Urban 25% and Rural 75%
      case_when(
        # Urban
        income_decile_group == 1 & urban_rural == 1 ~
          tc_2030_nzs_noctr + (1546.29 * hhsize),
        income_decile_group == 2 & urban_rural == 1 ~
          tc_2030_nzs_noctr + (1610.65 * hhsize),
        income_decile_group == 3 & urban_rural == 1 ~
          tc_2030_nzs_noctr + (1251.14 * hhsize),
        income_decile_group == 4 & urban_rural == 1 ~
          tc_2030_nzs_noctr + (1134.21 * hhsize),
        # Rural
        income_decile_group == 1 & urban_rural == 2 ~
          tc_2030_nzs_noctr + (6323.09 * hhsize),
        income_decile_group == 2 & urban_rural == 2 ~
          tc_2030_nzs_noctr + (6109.07 * hhsize),
        income_decile_group == 3 & urban_rural == 2 ~
          tc_2030_nzs_noctr + (5599.16 * hhsize),
        income_decile_group == 4 & urban_rural == 2 ~
          tc_2030_nzs_noctr + (4420.53 * hhsize),
        .default = tc_2030_nzs_noctr
      )
  )
```


This is the 50/50 version


```{r}
# ca_microsim <- ca_microsim %>% 
#   left_join(income_decile_group, join_by(household_id == household_id)) %>% 
#   mutate(
#     tc_2030_nzs = 
#       # Urban 25% and Rural 75%
#       case_when(
#         # Urban
#         income_decile_group == 1 ~ 
#           tc_2030_nzs_noctr + (3567.74 * hhsize),
#         income_decile_group == 2 ~ 
#           tc_2030_nzs_noctr + (3597.32 * hhsize),
#         income_decile_group == 3 ~ 
#           tc_2030_nzs_noctr + (2996.11 * hhsize),
#         income_decile_group == 4  ~ 
#           tc_2030_nzs_noctr + (2563.57 * hhsize),
#         .default = tc_2030_nzs_noctr
#       )
#   )
```



And recalculate poverty.


```{r}
ca_microsim <- ca_microsim %>% 
  rename(
    aec_r_2022 = aec_r,
    weight_2022 = weight,
    weight_2030_baseline = hh_weight_2030_baseline,
    weight_2030_dry_hot = hh_weight_2030_dry_hot,
    weight_2030_nzs = hh_weight_2030_nzs
    ) %>% 
  mutate(
    aec_r_2030_baseline = 
      tc_2030_baseline / ae_r / PI,
    aec_r_2030_dry_hot = 
      tc_2030_dry_hot  / ae_r / PI,
    aec_r_2030_nzs = 
      tc_2030_nzs  / ae_r / PI
    ) %>% 
  # Official poverty line
  mutate(
    poor_Avpovln2022_2030_baseline = 
      if_else(aec_r_2030_baseline < 52883, 1, 0),
    poor_Avpovln2022_2030_dry_hot  = 
      if_else(aec_r_2030_dry_hot  < 52883, 1, 0),
    poor_Avpovln2022_2030_nzs      = 
      if_else(aec_r_2030_nzs      < 52883, 1, 0)
    )
```


Test


```{r}
test_baseline <- ca_microsim %>%
  rename(
    poor_original = poor_Avpovln2022_2022,
    poor_2030_baseline = poor_Avpovln2022_2030_baseline,
    poor_2030_dry_hot = poor_Avpovln2022_2030_dry_hot,
    poor_2030_nzs = poor_Avpovln2022_2030_nzs
    ) %>%
  group_by(poor_2030_nzs) %>% 
  summarize(
    # no_hh_2022 = sum(weight_2022, na.rm = TRUE),
    # no_pp_2022 = sum(weight_2022 * hhsize, na.rm = TRUE),
    # no_hh_baseline = sum(weight_2030_baseline, na.rm = TRUE),
    # no_pp_baseline = sum(weight_2030_baseline * hhsize, na.rm = TRUE),
    # no_hh_dry_hot = sum(weight_2030_dry_hot, na.rm = TRUE),
    # no_pp_dry_hot = sum(weight_2030_dry_hot * hhsize, na.rm = TRUE),
    no_hh_nzs = sum(weight_2030_nzs, na.rm = TRUE),
    no_pp_nzs = sum(weight_2030_nzs * hhsize, na.rm = TRUE)
    ) %>% 
  ungroup()

test_baseline %>% 
  gt()

write.table(test_baseline, "clipboard", sep="\t", row.names=FALSE)

```


We plot the distributions in @fig-scenario-distribution-plots.


```{r}
#| warning: false
#| message: false
#| lst-label: lst-scenario-distribution-plots
#| lst-cap: "Plotting equivalized consumption per capita distribution by scenario"
#| label: fig-scenario-distribution-plots
#| fig-cap: "Equivalized consumption per capita distribution by scenario"

# Basic density plot comparing equivalized consumption per capita
ggplot(ca_microsim) +
  geom_density(
    data = ca_microsim,
    aes(x = aec_r_2022, fill = 'Baseline 2022'),
    alpha = 0.4) +
  geom_density(
    data = ca_microsim,
    aes(x = aec_r_2030_nzs, fill = 'NZS 2030'),
    alpha = 0.4) +
  geom_density(
    data = ca_microsim,
    aes(x = aec_r_2030_dry_hot, fill = 'Dry/Hot 2030'),
    alpha = 0.4) +
  geom_density(
    data = ca_microsim,
    aes(x = aec_r_2030_baseline, fill = 'Baseline 2030'),
    alpha = 0.4) +
  labs(
    fill = "Scenario Variant",
    # title = "Comparison of Consumption Distributions",
    x = "Equivalized consumption (Dram)",
    y = "Probability") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 500000),
          #        ylim = c(0.000005,0.0000160)
                  ) + # Zoom in without removing data
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma)+
  geom_vline(xintercept = 55883,
             color = "red",
             linetype = "dotted",
             linewidth =0.8) +
  annotate("text",
           x = 55883,
           y = 0.0000025,
           #label = "Poverty line\nAMD 55,883",
           label = "Poverty line",
           color = "black",
           hjust = -0.1,
           # vjust = -3.5,
           #angle = 90,
           size = 3)
```


And we also plot the cumulative distributions to make the distinctions more evident in @fig-scenario-cumulative-distribution-plots.


```{r}
#| warning: false
#| message: false
#| lst-label: lst-scenario-cumulative-distribution-plots
#| lst-cap: "Plotting equivalized consumption per capita cumulative distribution by scenario"
#| label: fig-scenario-cumulative-distribution-plots
#| fig-cap: "Equivalized consumption per capita cumulative distribution by scenario"

# Plot the cumulative distribution with left-facing arrows
ggplot(ca_microsim)+
  stat_ecdf(data = ca_microsim,
            aes(x = aec_r_2030_nzs, color = 'NZS 2030')) +
  stat_ecdf(data = ca_microsim,
            aes(x = aec_r_2030_dry_hot, color = 'Dry/Hot 2030')) +
  stat_ecdf(data = ca_microsim,
            aes(x = aec_r_2030_baseline, color = 'Baseline 2030')) +
  stat_ecdf(data = ca_microsim,
            aes(x = aec_r_2022, color = 'Baseline 2022')) +
  labs(
    color = "Scenario Variant",
    # title = "Comparison of Cumulative Consumption Distributions",
    x = "Equivalized consumption (Dram)",
    y = "Cumulative Probability") +
  theme_minimal() +
  coord_cartesian(xlim = c(40000, 110000)) +
  scale_x_continuous(labels = scales::comma)
  # annotate("segment", 
  #          x = 70000, 
  #          xend = 65000, 
  #          y = 0.2, 
  #          yend = 0.2,
  #          arrow = arrow(length = unit(0.3, "cm")), 
  #          color = "black") +
  # annotate("text", 
  #          x = 72500, 
  #          y = 0.2,
  #          label = "Shift due to scenario conditions", 
  #          hjust = 0)

```


### Climate change

In these sections we use Administrative Level 1 data on yield losses and labor productivity losses due to climate change that are provided in the study commissioned for Armenia's CCDR *Estimating the Economic Impacts of Climate Change in Armenia* [@strzepek_estimating_2024].

In the climate change scenario, we ask ourselves, what would happen if agriculture revenues from crops and livestock are reduced due to losses in productivity due to heat? For this, we use crops data.

We add a moving window average and max value for our labor productivity data.


```{r}
# First calculate moving window average
labor_productivity <- labor_productivity %>%
  group_by(ADM1_EN, 
           clim_scenario) %>%
  arrange(year) %>%
  # Moving window average 5 years before, 5 after
  mutate(
    moving_avg = rollapply(
      pct_change_productivity,
      width = 11,
      FUN = mean,
      partial = TRUE,
      align = "center",
      fill = NA,
      na.rm = TRUE
    ),
    # Moving window max value 5 years before, 5 after
    # Since it's expressed in negative values (min) is the maximum
    moving_max = rollapply(
      pct_change_productivity,
      width = 11,
      FUN = min,
      partial = TRUE,
      align = "center",
      fill = NA,
      na.rm = TRUE
    )
  ) %>%
  ungroup()

# Clim scenarios to select
cs <- unique(labor_productivity$clim_scenario)

# Moving average for year of interest
lab_loss_avg <- labor_productivity %>%
  filter(clim_scenario == cs[1], year == analysis_years[1]) %>%
  select(-pct_change_productivity,
         -ADM1_PCODE,
         -year,
         -clim_scenario,
         -moving_max) %>%
  pivot_wider(names_from = sector, values_from = moving_avg) %>%
  rename(agr_avg = Agriculture,
         man_avg = Manufacturing,
         ser_avg = Services)

# Max value for year of interest
lab_loss_max <- labor_productivity %>%
  filter(clim_scenario == cs[1], year == analysis_years[1]) %>%
  select(-pct_change_productivity,
         -ADM1_PCODE,
         -year,
         -clim_scenario,
         -moving_avg) %>%
  pivot_wider(names_from = sector, values_from = moving_max) %>%
  rename(agr_max = Agriculture,
         man_max = Manufacturing,
         ser_max = Services)
```


We add a moving window average and max value for our crops and livestock productivity data.


```{r}
# First calculate moving window average
crops_productivity <- crops_productivity %>%
  group_by(marz, climate_scenario) %>%
  arrange(year) %>%
  # Moving window average
  mutate(
    moving_avg = rollapply(
      pct_change_prod,
      width = 11,
      # 5 years before, 5 after + reference year = 11
      FUN = mean,
      partial = TRUE,
      align = "center",
      fill = NA,
      na.rm = TRUE
    ),
    # Moving window max value 5 years before, 5 after
    # Since it's expressed in negative values (min) is the maximum
    moving_max = rollapply(
      pct_change_prod,
      width = 11,
      FUN = min,
      partial = TRUE,
      align = "center",
      fill = NA,
      na.rm = TRUE
    )
  ) %>%
  ungroup()

# Clim scenarios to select
cs <- unique(crops_productivity$climate_scenario)

# Moving average for year of interest
crops_pdcvty_loss <- crops_productivity %>%
  filter(climate_scenario == cs[1], 
         year == analysis_years[1]) %>%
  select(-pct_change_prod, 
         -GID_1, 
         -year, 
         -climate_scenario) %>%
  rename(crops_avg_loss = moving_avg, 
         crops_max_loss = moving_max)
```


And we do the same for livestock productivity.In this case, there is also disaggregation by Marz.


```{r}
# First calculate moving window average
livestock_productivity <- livestock_productivity %>%
  group_by(marz, climate.scenario) %>%
  arrange(year) %>%
  # Moving window average
  mutate(
    moving_avg = rollapply(
      pct_change_prod,
      width = 11,
      # 5 years before, 5 after + reference year = 11
      FUN = mean,
      partial = TRUE,
      align = "center",
      fill = NA,
      na.rm = TRUE
    ),
    # Moving window max value 5 years before, 5 after
    # Since it's expressed in negative values (min) is the maximum
    moving_max = rollapply(
      pct_change_prod,
      width = 11,
      FUN = min,
      partial = TRUE,
      align = "center",
      fill = NA,
      na.rm = TRUE
    )
  ) %>%
  ungroup()

# Clim scenarios to select
cs <- unique(livestock_productivity$climate.scenario)

# Moving average for year of interest
lvstk_pdcvty_loss <- livestock_productivity %>%
  filter(climate.scenario == cs[1], 
         year == analysis_years[1]) %>%
  select(-pct_change_prod, 
         -year, 
         -climate.scenario) %>%
  rename(lvstk_avg_loss = moving_avg, 
         lvstk_max_loss = moving_max)
```


And then we introduce these values in our ag income and labor income data. First, we attach the percentage losses to the appropriate data set.


```{r}
# Persons processed dataset
pp_microsim_cc <- pp_microsim %>%
  left_join(lab_loss_avg, 
            join_by(marz == ADM1_EN)) %>%
  left_join(lab_loss_max, 
            join_by(marz == ADM1_EN))

# Household income processed dataset
ic_microsim_cc <- ic_microsim %>%
  left_join(crops_pdcvty_loss, 
            join_by(marz == marz)) %>% 
  left_join(lvstk_pdcvty_loss,
            join_by(marz))

##write.table(lab_loss_avg, "clipboard", sep="\t", row.names=FALSE)
```


And we first shock labor income.


```{r}
# Labor income according to sector
pp_microsim_cc <- pp_microsim_cc %>%
  mutate(sector = as.numeric(sector)) %>%
  mutate(
    mli_2030_baseline_lab_avg =
      case_when(
        sector == 1 ~
          monthly_labor_income_2030_baseline * 
          (1 + agr_avg),
        sector == 2 ~
          monthly_labor_income_2030_baseline * 
          (1 + man_avg),
        sector == 3 ~
          monthly_labor_income_2030_baseline * 
          (1 + ser_avg),
        TRUE ~ NA
      )
  ) %>%
  mutate(
    mli_2030_baseline_lab_max =
      case_when(
        # * 1000 because its thousands of Dram
        sector == 1 ~
          monthly_labor_income_2030_baseline * 
          (1 + agr_max),
        sector == 2 ~
          monthly_labor_income_2030_baseline * 
          (1 + man_max),
        sector == 3 ~
          monthly_labor_income_2030_baseline * 
          (1 + ser_max),
        TRUE ~ NA
      )
  )
```


We aggregate at household level and take note of the percent difference between the two labor incomes, so that we can impact labor income by that amount. We don't do it with absolute numbers because we don't know the assumptions made by the poverty team to construct the income variable.


```{r}
ic_new_incomes <- pp_microsim_cc %>%
  group_by(household_id) %>%
  summarize(
    mli_2030_baseline_lab_avg = 
      sum(mli_2030_baseline_lab_avg, na.rm = TRUE),
    mli_2030_baseline_lab_max = 
      sum(mli_2030_baseline_lab_max, na.rm = TRUE),
    mli_original = 
      sum(monthly_labor_income_2030_baseline, na.rm = TRUE)
  ) %>%
  mutate(
    mli_2030_baseline_lab_avg_coef =
      if_else(
        mli_original == 0 | is.na(mli_original),
        1,
        mli_2030_baseline_lab_avg / mli_original
      ),
    mli_2030_baseline_lab_max_coef =
      if_else(
        mli_original == 0 | is.na(mli_original),
        1,
        mli_2030_baseline_lab_max / mli_original
      )
  ) %>%
  ungroup()

ic_microsim_cc <- ic_microsim_cc %>%
  left_join(ic_new_incomes, 
            join_by(household_id == household_id)) %>%
  mutate(
    inc2_2030_baseline_lab_avg = 
      inc2_2030_baseline * mli_2030_baseline_lab_avg_coef,
    inc2_2030_baseline_lab_max = 
      inc2_2030_baseline * mli_2030_baseline_lab_max_coef,
    inc3_2030_baseline_lab_avg = 
      inc3_2030_baseline * mli_2030_baseline_lab_avg_coef,
    inc3_2030_baseline_lab_max = 
      inc3_2030_baseline * mli_2030_baseline_lab_max_coef
  )
```


And now we impact agricultural income `cropinc` and livestock income`lvstk`.


```{r}
ic_microsim_cc <- ic_microsim_cc %>% 
  mutate(
    cropinc_2030_baseline_cc_avg = 
      cropinc * (1 + crops_avg_loss),
    cropinc_2030_baseline_cc_max = 
      cropinc * (1 + crops_max_loss),
    lvstk_2030_baseline_cc_avg = 
      lvstk * (1 + lvstk_avg_loss),
    lvstk_2030_baseline_cc_max = 
      lvstk * (1 + lvstk_max_loss)
    )
```


And recalculate total income.


```{r}
ic_microsim_cc <- ic_microsim_cc %>%
  mutate(
    totalinc_2030_baseline_lab_avg =
      totalinc_2030_baseline -
      rowSums(select(., c(inc2_2030_baseline, 
                          inc3_2030_baseline)), na.rm = TRUE) +
      rowSums(select(
        ., c(inc2_2030_baseline_lab_avg, 
             inc3_2030_baseline_lab_avg)), na.rm = TRUE),
    totalinc_2030_baseline_lab_max =
      totalinc_2030_baseline -
      rowSums(select(., c(inc2_2030_baseline, 
                          inc3_2030_baseline)), na.rm = TRUE) +
      rowSums(select(
        ., c(inc2_2030_baseline_lab_max, 
             inc3_2030_baseline_lab_max)), na.rm = TRUE)
  ) %>%
  mutate(
    totalinc_2030_baseline_lab_avg_coef =
      if_else(totalinc_2030_baseline == 0, 
              1, totalinc_2030_baseline_lab_avg /
                totalinc_2030_baseline),
    totalinc_2030_baseline_lab_max_coef =
      if_else(totalinc_2030_baseline == 0, 
              1, totalinc_2030_baseline_lab_max /
                totalinc_2030_baseline)
  ) %>%
  mutate(
    totalinc_2030_baseline_lab_avg_coef =
      if_else(is.na(totalinc_2030_baseline_lab_avg_coef), 
              1, totalinc_2030_baseline_lab_avg_coef),
    totalinc_2030_baseline_lab_max_coef =
      if_else(is.na(totalinc_2030_baseline_lab_max_coef), 
              1, totalinc_2030_baseline_lab_max_coef)
  )
```


We do the same for agriculture and livestock income alone


```{r}
ic_microsim_cc <- ic_microsim_cc %>%
  mutate(
    totalinc_2030_baseline_cc_avg =
      totalinc_2030_baseline -
      rowSums(select(., c(cropinc,
                          lvstk)), na.rm = TRUE) +
      rowSums(select(
        ., c(cropinc_2030_baseline_cc_avg,
             lvstk_2030_baseline_cc_avg)), na.rm = TRUE),
    totalinc_2030_baseline_cc_max =
      totalinc_2030_baseline -
      rowSums(select(., c(cropinc,
                          lvstk)), na.rm = TRUE) +
      rowSums(select(
        ., c(cropinc_2030_baseline_cc_max,
             lvstk_2030_baseline_cc_max)), na.rm = TRUE)
  ) %>%
  mutate(
    totalinc_2030_baseline_cc_avg_coef =
      if_else(totalinc_2030_baseline == 0, 
              1, totalinc_2030_baseline_cc_avg 
              / totalinc_2030_baseline),
    totalinc_2030_baseline_cc_max_coef =
      if_else(totalinc_2030_baseline == 0, 
              1, totalinc_2030_baseline_cc_max 
              / totalinc_2030_baseline)
  ) %>%
  mutate(
    totalinc_2030_baseline_cc_avg_coef =
      if_else(is.na(totalinc_2030_baseline_cc_avg_coef), 
              1, totalinc_2030_baseline_cc_avg_coef),
    totalinc_2030_baseline_cc_max_coef =
      if_else(is.na(totalinc_2030_baseline_cc_max_coef), 
              1, totalinc_2030_baseline_cc_max_coef)
  )
```


And yet again for the combined impacts


```{r}
ic_microsim_cc <- ic_microsim_cc %>%
  mutate(
    totalinc_2030_baseline_lab_cc_avg =
      totalinc_2030_baseline -
      rowSums(select(., c(inc2_2030_baseline, 
                          inc3_2030_baseline,
                          cropinc,
                          lvstk)), na.rm = TRUE) +
      rowSums(select(
        ., c(inc2_2030_baseline_lab_avg, 
             inc3_2030_baseline_lab_avg,
             cropinc_2030_baseline_cc_avg,
             lvstk_2030_baseline_cc_avg)), na.rm = TRUE),
    totalinc_2030_baseline_lab_cc_max =
      totalinc_2030_baseline -
      rowSums(select(., c(inc2_2030_baseline, 
                          inc3_2030_baseline,
                          cropinc,
                          lvstk)), na.rm = TRUE) +
      rowSums(select(
        ., c(inc2_2030_baseline_lab_max, 
             inc3_2030_baseline_lab_max,
             cropinc_2030_baseline_cc_max,
             lvstk_2030_baseline_cc_max)), na.rm = TRUE)
  ) %>%
  mutate(
    totalinc_2030_baseline_lab_cc_avg_coef =
      if_else(totalinc_2030_baseline == 0, 
              1, totalinc_2030_baseline_lab_cc_avg /
                totalinc_2030_baseline),
    totalinc_2030_baseline_lab_cc_max_coef =
      if_else(totalinc_2030_baseline == 0, 
              1, totalinc_2030_baseline_lab_cc_max /
                totalinc_2030_baseline)
  ) %>%
  mutate(
    totalinc_2030_baseline_lab_cc_avg_coef =
      if_else(is.na(totalinc_2030_baseline_lab_cc_avg_coef), 
              1, totalinc_2030_baseline_lab_cc_avg_coef),
    totalinc_2030_baseline_lab_cc_max_coef =
      if_else(is.na(totalinc_2030_baseline_lab_cc_max_coef), 
              1, totalinc_2030_baseline_lab_cc_max_coef)
    )
```


We assume that the loss in income translates into a loss of expenditure.


```{r}
#| warning: false
#| message: false

income_losses <- ic_microsim_cc %>% 
  select(household_id,
         totalinc_2030_baseline_lab_avg_coef, 
         totalinc_2030_baseline_lab_max_coef,
         totalinc_2030_baseline_cc_avg_coef,
         totalinc_2030_baseline_cc_max_coef,
         totalinc_2030_baseline_lab_cc_avg_coef,
         totalinc_2030_baseline_lab_cc_max_coef)


ca_microsim_cc <- ca_microsim %>% 
  left_join(income_losses, join_by(household_id == household_id))

# And now reduce total consumption

ca_microsim_cc <- ca_microsim_cc %>% 
  mutate(tc_2030_baseline_lab_avg = tc_2030_baseline *
           totalinc_2030_baseline_lab_avg_coef,
         tc_2030_baseline_lab_max = tc_2030_baseline * 
           totalinc_2030_baseline_lab_max_coef,
         tc_2030_baseline_cc_avg = tc_2030_baseline *
           totalinc_2030_baseline_cc_avg_coef,
         tc_2030_baseline_cc_max = tc_2030_baseline * 
           totalinc_2030_baseline_cc_max_coef,
         tc_2030_baseline_lab_cc_avg = tc_2030_baseline *
           totalinc_2030_baseline_lab_cc_avg_coef,
         tc_2030_baseline_lab_cc_max = tc_2030_baseline * 
           totalinc_2030_baseline_lab_cc_max_coef
         ) %>% 
  mutate(aec_r_2030_baseline_lab_avg = 
           tc_2030_baseline_lab_avg / ae_r / PI,
         aec_r_2030_baseline_lab_max = 
           tc_2030_baseline_lab_max / ae_r / PI,
         aec_r_2030_baseline_cc_avg = 
           tc_2030_baseline_cc_avg / ae_r / PI,
         aec_r_2030_baseline_cc_max = 
           tc_2030_baseline_cc_max / ae_r / PI,
         aec_r_2030_baseline_lab_cc_avg = 
           tc_2030_baseline_lab_cc_avg / ae_r / PI,
         aec_r_2030_baseline_lab_cc_max = 
           tc_2030_baseline_lab_cc_max / ae_r / PI) %>% 
  mutate(poor_2030_baseline_lab_avg = 
           if_else(aec_r_2030_baseline_lab_avg < 52883, 1, 0),
         poor_2030_baseline_lab_max = 
           if_else(aec_r_2030_baseline_lab_max < 52883, 1, 0),
         poor_2030_baseline_cc_avg = 
           if_else(aec_r_2030_baseline_cc_avg < 52883, 1, 0),
         poor_2030_baseline_cc_max = 
           if_else(aec_r_2030_baseline_cc_max < 52883, 1, 0),
         poor_2030_baseline_lab_cc_avg = 
           if_else(aec_r_2030_baseline_lab_cc_avg < 52883, 1, 0),
         poor_2030_baseline_lab_cc_max = 
           if_else(aec_r_2030_baseline_lab_cc_max < 52883, 1, 0)
         )

# We make a table to see who became poor. 

test <- ca_microsim_cc %>%
  rename(poor_original = poor_Avpovln2022_2030_baseline,
         poor_cc = poor_2030_baseline_lab_avg) %>%
  group_by(income_decile_group, urban_rural) %>% 
  summarize(no_hh = round(sum(weight_2030_nzs, na.rm = TRUE)),
            no_pp = round(sum(weight_2030_nzs * hhsize, na.rm = TRUE))) %>% 
  ungroup()

test %>% 
  gt()

##write.table(test, "clipboard", sep="\t", row.names=FALSE)

```


### Food prices

We start by looking at the differences of food prices between scenarios.


```{r}
#| warning: false
#| message: false

# We extract and reformat the price data
price_data <- macro_data %>% 
  select(year, scenario_id, starts_with( c("fpi" , "epi") )) %>% 
  rename(scenario = scenario_id) %>% 
  pivot_longer(starts_with( c("fpi" , "epi") ), 
               names_to = "type_decile", 
               values_to = "index") %>%
  mutate(decile = parse_number(type_decile)) %>% 
  mutate(commodity_group = 
           case_when(
             str_starts(type_decile, "fpi") ~ "food",
             str_starts(type_decile, "epi") ~ "energy",
             TRUE ~ NA_character_
           )) %>% 
  select(-type_decile) %>% 
  relocate(index, .after = commodity_group)

# We take a look at price information in 2030
price_data %>% 
  filter(year == 2030) %>% 
  group_by(commodity_group, scenario) %>% 
  summarize(index = mean(index, na.rm = TRUE)) %>% 
  gt()
  
```


So, we will assign a price index depending on which decile the household belonged to in the base year 2022. We will have a column for each scenario. So we manipulate our price data according to our years of interest (in this case, only 2030).


```{r}
# Filter `price_data` for the years of interest
price_data_analysis_years <- price_data %>%
  filter(year %in% analysis_years)

# Create a named vector for scenario indices
scenario_indices <- setNames(seq_along(scenarios), scenarios)

# Create the composite string column
price_data_analysis_years <- price_data_analysis_years %>%
  mutate(
    scenario_index = scenario_indices[scenario],
    composite_column = paste( scenario,year,commodity_group, sep = "_")
  ) %>% 
  select(decile,index,composite_column)

composite_column_names <- unique(price_data_analysis_years$composite_column)

price_data_analysis_years <- price_data_analysis_years %>% 
  pivot_wider(names_from="composite_column", values_from = index)

```


So in this particular case, we don't want to use the price index from the `dry_hot` scenario, but we want to use the difference between the baseline and that scenario, so we are going to do those columns by hand, but we actually have to find a way to do it programmatically against the baseline.


```{r}
price_data_analysis_years <- price_data_analysis_years %>% 
  mutate(food_PI = dry_hot_2030_food - baseline_2030_food +1,
         energy_PI = nzs_2030_energy - baseline_2030_energy + 1)
```


And we join with our household's dataset.


```{r}
# PP microsim already has decile information from previous join
ca_microsim_cc <- ca_microsim_cc %>% 
  left_join(price_data_analysis_years, join_by(decile==decile))
```


Since we don't have quantities for the aggregate food expenditure category or for the aggregate energy bundle, we assume a price of 1 in the survey year.

We will estimate price elasticities for a single "food" commodity from the consumption aggregate `FOOD_with_prices` dataset. We add decile data to the original.


```{r}
food_summary <- food_with_prices %>% 
  left_join(deciles, join_by(household_id))

# Step 1: Summarize the data at the household level
food_summary <- food_summary %>%
  group_by(household_id, decile) %>%
  summarize(
    total_quantity = sum(q, na.rm = TRUE),
    weighted_price = sum(avrpr_mean * q, na.rm = TRUE) / sum(q, na.rm = TRUE),
    .groups = 'drop'
  )

# Define a function to fit the model and extract the elasticity
fit_model <- function(data) {
  model <- lm(log(total_quantity) ~ log(weighted_price), data = data)
  coef(model)["log(weighted_price)"]
}

# Apply the model fitting function by decile
decile_models <- food_summary %>%
  group_by(decile) %>%
  nest() %>%
  mutate(price_elasticity = map_dbl(data, fit_model)) %>%
  select(decile, price_elasticity) %>% 
  mutate(price_elasticity = if_else(price_elasticity >0,
                                    price_elasticity *(-1),
                                    price_elasticity))

decile_models

```


Let's add back the elasticity data to the analysis dataset.


```{r}
ca_microsim_cc <- ca_microsim_cc %>%
  left_join(decile_models, by = "decile")
```


Let's apply the elasticities to the new data.


```{r}
# Calculate the implicit price
# Assuming implicit_price can be calculated from the expenditure (food1)
# If we assume baseline quantity consumed is proportional to expenditure/price
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(implicit_price = food1 / food1,  # This is 1 as we don't have baseline price
         food_quantity = food1 / implicit_price)

# Calculate the percentage change in prices for each decile
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(food_1_dprice  = (baseline_2030_food - 1),
         food_2_dprice  = (dry_hot_2030_food - 1),
         food_PI_dprice = (food_PI - 1))

# Estimate the new food consumption levels
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(
    food_q1_sim = food_quantity * 
      (1 + food_1_dprice * price_elasticity),
    food_q2_sim = food_quantity * 
      (1 + food_2_dprice * price_elasticity),
    food_qPI_sim = food_quantity *
      (1 + food_PI_dprice * price_elasticity))

# Calculate the new expenditure levels
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(food_exp1_sim = food_q1_sim * baseline_2030_food,
         food_exp2_sim = food_q2_sim * dry_hot_2030_food,
         food_exp3_sim = food_qPI_sim * food_PI)

# View the results
print(ca_microsim_cc %>% select(decile, food1, baseline_2030_food, food_1_dprice, food_q1_sim, food_exp1_sim, food_2_dprice, food_q2_sim, food_exp2_sim,food_exp2_sim, food_PI_dprice))


```


Let's plot the distributions to see changes:


```{r}

# Basic density plot comparing food1 and food_exp_sim
ggplot(ca_microsim_cc, aes(x = food1, fill = 'Initial Food Expenditure')) + 
  geom_density(alpha = 0.3) + 
  geom_density(
    data = ca_microsim_cc, 
    aes(x = food_exp3_sim, fill = 'Baseline + Dry-Hot prices'), 
    alpha = 0.3) +
  labs(
    fill = "Consumption Type", 
    title = "Comparison of Food Expenditure Distributions", 
    x = "Food Expenditure", 
    y = "Density") +
  theme_minimal() +
  coord_cartesian(xlim = c(0, 300000)) + # Adjust the xlim for zoom
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma)


```


Calculate losses in consumer surplus and purchasing power loss.


```{r}

# Calculate Consumer Surplus loss for food1 and food2 scenarios
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(
    across(
      c(food1,
        food_exp1_sim,
        food_exp2_sim,
        food_exp3_sim,
        tc_2030_baseline_lab_cc_avg), ~replace_na(., 0))) %>%
  mutate(food1_CSloss = ((food_quantity * implicit_price) / 
                           tc_2030_baseline) * food_1_dprice * (
                             1 + (price_elasticity / 2) * food_1_dprice),
         food2_CSloss = ((food_quantity * implicit_price) /
                           tc_2030_dry_hot) * food_2_dprice * (
                             1 + (price_elasticity / 2) * food_2_dprice),
         foodPI_CSloss = ((food_quantity * implicit_price) /
                           tc_2030_baseline_lab_cc_avg) * food_PI_dprice * (
                             1 + (price_elasticity / 2) * food_PI_dprice),
         ttl_CSloss_1 = food1_CSloss,
         ttl_CSloss_2 = food2_CSloss,
         ttl_CSloss_PI = foodPI_CSloss)

# Calculate Purchasing Power loss for food1 and food2 and PI scenarios
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(food1_PPloss = (food1 / 
                           tc_2030_baseline) * food_1_dprice,
         food2_PPloss = (food1 / 
                           tc_2030_dry_hot) * food_2_dprice,
         foodPI_PPloss = (food1 / 
                            tc_2030_baseline_lab_cc_avg) * food_PI_dprice,
         ttl_PPloss_1 = food1_PPloss,
         ttl_PPloss_2 = food2_PPloss,
         ttl_PPloss_PI = foodPI_PPloss
         )

# Adjust total expenditure (tc) based on the purchasing power loss
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(tc_2030_baseline_food1 = tc_2030_baseline * (1 - ttl_PPloss_1),
         tc_2030_dry_hot_food2 = tc_2030_dry_hot * (1 - ttl_PPloss_2),
         tc_2030_baseline_lab_cc_foodPI2 = tc_2030_baseline_lab_cc_avg * (1 - ttl_PPloss_PI),
         tc_2030_baseline_lab_cc_foodPI = tc_2030_baseline_lab_cc_avg - (food_exp3_sim - food1)
         )

# View the results
print(ca_microsim_cc %>% select(decile, tc_2030_baseline, tc_2030_baseline_food1, tc_2030_dry_hot_food2, tc_2030_baseline_lab_cc_foodPI))

```


Okay so now we estimate new welfare and poverty.


```{r}
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(aec_r_2030_baseline_food1 = tc_2030_baseline_food1 / ae_r / PI,
         aec_r_2030_dry_hot_food2 = tc_2030_dry_hot_food2 / ae_r / PI,
         aec_r_2030_baseline_foodPI = tc_2030_baseline_lab_cc_foodPI / ae_r / PI) %>%
  mutate(poor_2030_baseline_food1 =
           if_else(aec_r_2030_baseline_food1 < 52883, 1, 0),
         poor_2030_dry_hot_food2 =
           if_else(aec_r_2030_dry_hot_food2 < 52883, 1, 0),
         poor_2030_baseline_lab_cc_foodPI =
           if_else(aec_r_2030_baseline_foodPI < 52883, 1, 0))

```


And now we see who became poor


```{r}
# We make a table to see who became poor. 
test <- ca_microsim_cc

test <- test%>%
  rename(poor_original = poor_Avpovln2022_2030_baseline,
         poor_cc = poor_2030_baseline_lab_cc_avg,
         poor_food1 = poor_2030_baseline_food1,
         poor_food2 = poor_2030_dry_hot_food2,
         poor_foodPI =  poor_2030_baseline_lab_cc_foodPI) %>%
  group_by(poor_original) %>% 
  summarize(no_hh = round(sum(weight_2030_baseline, na.rm = TRUE)),
            no_pp = round(sum(weight_2030_baseline*hhsize, na.rm = TRUE)))

test %>% 
  gt()

##write.table(test, "clipboard", sep="\t", row.names=FALSE)

```


And we map these results.


```{r}
# foodpoor <- ca_microsim_cc %>%
#   mutate(new_poor_food_base = if_else(
#     poor_cc_avg_food2 == 1 & poor_cc_avg == 0, 1, 0),
#          new_poor_food_dryhot = if_else(
#            poor_cc_avg_food1 == 1 & poor_cc_avg == 0, 1, 0),
#     marz = as_factor(marz)) %>% 
#   mutate(marz = if_else(marz == "VayotsDzor", "Vayots Dzor", marz)) %>% 
#   mutate(marz = if_else(marz == "Sjunik", "Syunik", marz)) %>% 
#   select(marz, poor_Avpovln2022, poor_cc_avg, poor_cc_max,
#          poor_cc_avg_food1, poor_cc_avg_food2, new_poor_food_base,
#          new_poor_food_dryhot, weight, hhsize)
# 
# fp <-foodpoor %>% 
#   group_by(marz) %>% 
#   summarize(new_poor = round(sum(new_poor_food_dryhot * weight*hhsize, na.rm = TRUE))) %>% 
#   mutate(label = paste0(marz," (", new_poor, ")"))
# 
# 
# ##write.table(fp, "clipboard", sep="\t", row.names=FALSE)
# fp_map <- adm1 |> 
#   left_join(fp, join_by(marz == marz))
# 
# fp_map <-tm_shape(fp_map)+
#   tm_polygons("new_poor", legend.show = FALSE) +
#   tm_text("label", size = .7, col = "black")+
#   tm_layout(legend.position = c("right", "top"), 
#             title= "Additional Poor Dry-Hot Scenario", 
#             title.position = c('left', 'bottom'),
#             title.size = 0.9)
# 
# fp_map

```


Let's plot how the distribution moves with all these measures.


```{r}
# Basic density plot comparing equivalized consumption per capita
ggplot(ca_microsim_cc, 
       aes(x = aec_r_2030_baseline_foodPI, fill = 'Direct CC + Food Price')) +
  geom_density(alpha = 0.5) +
  # geom_density(
  #   data = ca_microsim_cc,
  #   aes(x = aec_r_2030_dry_hot, fill = 'Dry/Hot'),
  #   alpha = 0.5) +
  # geom_density(
  #   data = ca_microsim_cc,
  #   aes(x = aec_r_2030_dry_hot_food2, fill = 'Dry/Hot + Food Price'),
  #   alpha = 0.5) +
  geom_density(
    data = ca_microsim_cc,
    aes(x = aec_r_2030_baseline_lab_cc_avg, fill = 'Direct CC'),
    alpha = 0.5) +
  geom_density(
    data = ca_microsim_cc,
    aes(x = aec_r_2030_baseline, fill = 'Baseline'),
    alpha = 0.5) +
  labs(
    fill = "Scenario Variant", 
    # title = "Comparison of Consumption Distributions", 
    x = "Equivalized consumption (Dram)", 
    y = "Probability") +
  theme_minimal()+
  coord_cartesian(xlim = c(20000, 150000),
                  ylim = c(0.000005,0.0000160)) + # Zoom in without removing data
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma)+
  geom_vline(xintercept = 55883, 
             color = "red", 
             linetype = "dotted", 
             linewidth =0.8) +
  annotate("text", 
           x = 55883, 
           y = 0.0000110, 
           #label = "Poverty line\nAMD 55,883", 
           label = "Poverty line", 
           color = "black", 
           hjust = -0.1, 
           # vjust = -3.5,
           #angle = 90, 
           size = 3)
```


And we also plot the cumulative distributions.


```{r}
# Plot the cumulative distribution with left-facing arrows
ggplot(ca_microsim_cc, 
       aes(x = aec_r_2030_baseline_foodPI, color = 'Direct CC + Food Price')) +
  stat_ecdf(geom = "step") +
  # stat_ecdf(data = ca_microsim_cc, 
  #           aes(x = aec_r_2030_baseline_lab_avg, color = 'Baseline + Labor Productivity')) +
  stat_ecdf(data = ca_microsim_cc, 
            aes(x = aec_r_2030_baseline_lab_cc_avg, color = 'Direct CC')) +
  stat_ecdf(data = ca_microsim_cc, 
            aes(x = aec_r_2030_baseline, color = 'Baseline')) +
  labs(
    color = "Scenario Variant", 
    # title = "Comparison of Cumulative Consumption Distributions", 
    x = "Equivalized consumption (Dram)", 
    y = "Cumulative Probability") +
  theme_minimal() +
  coord_cartesian(xlim = c(40000, 110000)) + 
  scale_x_continuous(labels = scales::comma) +
  # geom_vline(xintercept = 55883, 
  #            color = "red", 
  #            linetype = "dotted", 
  #            linewidth = 0.8) +
  # annotate("text", 
  #          x = 55883, 
  #          y = 0.5, 
  #          label = "Poverty line", 
  #          color = "black", 
  #          hjust = -0.1, 
  #          size = 3) +
  annotate("segment", x = 70000, xend = 65000, y = 0.2, yend = 0.2, 
           arrow = arrow(length = unit(0.3, "cm")), color = "black") +
  annotate("text", x = 72500, y = 0.2, label = "Shift due to shocks", hjust = 0) 
  # annotate("segment", x = 80000, xend = 75000, y = 0.4, yend = 0.4, 
  #          arrow = arrow(length = unit(0.3, "cm")), color = "black") +
  # annotate("text", x = 82500, y = 0.4, label = "Shift due to shocks", hjust = 0)



```


### Energy prices

We first establish energy elasticities. We only have quantities for liquefied gas `hous_29_a` and their purchase value `hous_29_b` with which we can compute price. Unfortunately there is no quantity for electricity, so we will use the same elasticity. We do not compute an elasticity by decile, because there are too few observations per decile, so we estimate an overall elasticity for all the distribution.


```{r}
# We extract the liquefied gas (hous_29), natural gas (hous_38) 
# and electricity (hous_23) information
energy_summary_all <- hh %>% 
  mutate(l_gas_price = 
           if_else(hous_29_a == 0, 0, hous_29_b/hous_29_a),
         n_gas_price = 
           if_else(hous_36_a == 0, 0, hous_36_b/hous_36_a)) %>%
  select(household_id, weight, hous_29_a, hous_29_b,hous_23,
         hous_36_a, hous_36_b, l_gas_price, n_gas_price)

# We estimate the weighted mean of liquefied gas prices
avg_l_gas_price <- weighted.mean(energy_summary_all$l_gas_price,
                               energy_summary_all$weight,
                               na.rm=TRUE)

# And do the same for natural gas
avg_n_gas_price <- weighted.mean(energy_summary_all$n_gas_price,
                               energy_summary_all$weight,
                               na.rm=TRUE)

# We replace missing 0 values with average gas price
energy_summary_all <- energy_summary_all %>% 
  mutate(l_gas_price = if_else(l_gas_price==0.0,
                             avg_l_gas_price,
                             l_gas_price),
         n_gas_price = if_else(n_gas_price==0.0,
                             avg_n_gas_price,
                             n_gas_price))

# We subset to compute a single elasticity value for the entire distribution
# Summarize the data at the household level
l_energy_summary <- energy_summary_all %>%
  filter(!is.na(l_gas_price))# %>% 
 
# Filter out rows with non-positive values in hous_29_a or l_gas_price
l_energy_summary <- l_energy_summary[l_energy_summary$hous_29_a > 0 & l_energy_summary$l_gas_price > 0, ]

# Compute the log of quantity and price
l_energy_summary$log_gas_quantity <- log(l_energy_summary$hous_29_a)
l_energy_summary$log_l_gas_price <- log(l_energy_summary$l_gas_price)

# Estimate a single price elasticity for the entire dataset
model <- lm(log_gas_quantity ~ log_l_gas_price, data = l_energy_summary)
summary_model <- summary(model)

# Extract the price elasticity (coefficient of log_l_gas_price)
l_gas_price_elasticity <- coef(summary_model)["log_l_gas_price", "Estimate"]

# Print the results
print(summary_model)
print(paste("Estimated price elasticity of gas quantity demanded:", l_gas_price_elasticity))

```


We see that this commodity is highly inelastic at -0.088781.The estimated price elasticity of -0.086 suggests that the demand for gas is inelastic. This means that a 1% increase in the price of gas would lead to only a 0.09% decrease in the quantity of gas demanded. The absolute value of the elasticity is much less than 1, indicating that consumers do not significantly reduce their gas consumption in response to price increases. This could be because gas is a necessity for many households, and they cannot easily reduce their usage or switch to alternative sources. We expect electricity, being so universal in the dataset to behave in the same manner. We wanted to use natural gas to compute a similar metric, but there is hardly any variation in prices. Everybody experiences the same price and so there is not enough variation to compute a valid model. We will use the elasticity from liquefied gas for our purposes.

Let's add back the elasticity data to the analysis dataset.


```{r}
ca_microsim_cc$l_gas_price_elasticity <- l_gas_price_elasticity
ca_microsim_cc <- ca_microsim_cc %>% 
  left_join(energy_summary_all, join_by(household_id==household_id))

```


Let's apply the elasticities to the new data.


```{r}
# Calculate the implicit price
# Assuming implicit_price can be calculated from the expenditure
# If we assume baseline quantity consumed is proportional to expenditure/price
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(
    # This is 1 as we don't have baseline price
    electricity_implicit_price = if_else(hous_23 == 0,1,hous_23 / hous_23),  
    electricity_quantity = hous_23 / electricity_implicit_price,
    energy_price_elasticity = l_gas_price_elasticity)

EM_elec_price <- 1.071353 # Price increase in Energy Model
EM_gas_price <- 1.025514

# Calculate the percentage change in prices by decile
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(energy_baseline_dprice  = (energy_PI - 1),
         energy_nzs_dprice = (nzs_2030_energy - 1),
         EM_elec_dprice = (EM_elec_price-1), # Interpolation from Energy Model
         EM_gas_dprice = (EM_gas_price-1)) 

# Estimate the new energy consumption levels
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(
    electricity_baseline_q_sim = electricity_quantity * 
      (1 + energy_baseline_dprice * energy_price_elasticity),
    electricity_nzs_q_sim = electricity_quantity *
      (1 + energy_nzs_dprice * energy_price_elasticity),
    electricity_EM_q_sim = electricity_quantity *
      (1 + EM_elec_dprice * energy_price_elasticity),
    l_gas_baseline_q_sim = hous_29_a * 
      (1 + energy_baseline_dprice * energy_price_elasticity),
    l_gas_nzs_q_sim = hous_29_a *
      (1 + energy_nzs_dprice * energy_price_elasticity),
    l_gas_EM_q_sim = hous_29_a *
      (1 + EM_gas_dprice * energy_price_elasticity),
    n_gas_baseline_q_sim = hous_36_a * 
      (1 + energy_baseline_dprice * energy_price_elasticity),
    n_gas_nzs_q_sim = hous_36_a *
      (1 + energy_nzs_dprice * energy_price_elasticity),
    n_gas_EM_q_sim = hous_36_a *
      (1 + EM_gas_dprice * energy_price_elasticity)
    )

# Calculate the new expenditure levels
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(electricity_baseline_sim = 
           electricity_baseline_q_sim * energy_PI, #because e-price = 1
         l_gas_baseline_sim = 
           l_gas_baseline_q_sim * l_gas_price * energy_PI,
         n_gas_baseline_sim = 
           n_gas_baseline_q_sim * n_gas_price * energy_PI,
         electricity_nzs_sim = 
           electricity_nzs_q_sim * nzs_2030_energy,#because e-price = 1
         l_gas_nzs_sim = 
           l_gas_nzs_q_sim * l_gas_price * nzs_2030_energy,
         n_gas_nzs_sim = 
           n_gas_nzs_q_sim * n_gas_price * nzs_2030_energy,
         electricity_EM_sim = 
           electricity_EM_q_sim * EM_elec_price,#because e-price = 1
         l_gas_EM_sim = 
           l_gas_EM_q_sim * l_gas_price * EM_gas_price,
         n_gas_EM_sim = 
           n_gas_EM_q_sim * n_gas_price * EM_gas_price)
```


Let's plot the distributions to see changes:


```{r}

# Basic density plot comparing food1 and food_exp_sim
ggplot(ca_microsim_cc, aes(x =  hous_23, fill = 'Baseline')) + 
  geom_density(alpha = 0.3) + 
  geom_density(
    data = ca_microsim_cc,
    aes(x = electricity_baseline_sim, fill = 'Baseline + NSZ Energy Prices'),
    alpha = 0.3) +
   geom_density(
    data = ca_microsim_cc,
    aes(x = electricity_EM_sim, fill = 'NSZ + NSZ Energy Prices'),
    alpha = 0.3) +
  #facet_wrap(~decile)+
  labs(
    fill = "Consumption Type", 
    title = "Comparison of Electricity Expenditure Distributions", 
    x = "Energy Expenditure", 
    y = "Density") +
  theme_minimal() +
  coord_cartesian(xlim = c(0, 40000)) + # Adjust the xlim for zoom
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma)


```

```{r}
# Basic density plot comparing food1 and food_exp_sim
# ggplot(ca_microsim_cc, aes(x =  hous_23+hous_29_b+hous_36_b, fill = 'Baseline')) + 
#   geom_density(alpha = 0.3) + 
#   geom_density(
#     data = ca_microsim_cc,
#     aes(x = electricity_baseline_sim+l_gas_baseline_sim+n_gas_baseline_sim, fill = 'Baseline + NSZ Energy Prices'),
#     alpha = 0.3) +
#    geom_density(
#     data = ca_microsim_cc,
#     aes(x = electricity_nzs_sim+l_gas_nzs_sim+n_gas_nzs_sim, fill = 'NSZ + NSZ Energy Prices'),
#     alpha = 0.3) +
#   # facet_wrap(~decile)+
#   labs(
#     fill = "Consumption Type", 
#     title = "Comparison of Energy Expenditure Distributions", 
#     x = "Energy Expenditure", 
#     y = "Density") +
#   theme_minimal() +
#   coord_cartesian(xlim = c(0, 100000)) + # Adjust the xlim for zoom
#   scale_x_continuous(labels = scales::comma) +
#   scale_y_continuous(labels = scales::comma)
```


Calculate losses in consumer surplus and purchasing power loss.


```{r}

# Calculate Purchasing Power loss for food1 and food2 and PI scenarios
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(
    across(
      c(hous_23,
        hous_29_b,
        hous_36_b, 
        tc_2030_baseline,
        tc_2030_nzs,
        l_gas_baseline_sim,
        n_gas_baseline_sim,
        electricity_baseline_sim,
        l_gas_nzs_sim,
        n_gas_nzs_sim,
        electricity_nzs_sim,
        l_gas_EM_sim,
        n_gas_EM_sim,
        electricity_EM_sim), ~replace_na(., 0))) %>%
  mutate(energy_baseline_PPloss = ((hous_23 + hous_29_b + hous_36_b) / 
                           tc_2030_baseline) * energy_baseline_dprice,
         energy_nzs_PPloss = ((hous_23 + hous_29_b + hous_36_b) / 
                           tc_2030_nzs) * energy_nzs_dprice,
         ttl_PPloss_1 = energy_baseline_PPloss,
         ttl_PPloss_2 = energy_nzs_PPloss
         )

# Adjust total expenditure (tc) based on the purchasing power loss
ca_microsim_cc <- ca_microsim_cc %>%
  # mutate(nzs_scale_coef = if_else(
  #   tc_2030_baseline==0, 1, tc_2030_nzs/tc_2022)) %>% 
  mutate(#tc_2030_baseline_energy2 = tc_2030_baseline * (1 - ttl_PPloss_1),
         tc_2030_baseline_energy = 
           tc_2030_baseline -
           ((electricity_baseline_sim +
               l_gas_baseline_sim + 
               n_gas_baseline_sim) - 
              (hous_23 + 
                 hous_36_b + 
                 hous_29_b)),
         #tc_2030_nzs_energy2 = tc_2030_nzs * (1 - ttl_PPloss_2),
         tc_2030_nzs_energy = 
           tc_2030_nzs -
           ((electricity_nzs_sim +
               l_gas_nzs_sim + 
               n_gas_nzs_sim) - 
              (hous_23 + 
                 hous_36_b + 
                 hous_29_b)),
         tc_2030_EM_baseline_energy = 
           tc_2030_baseline -
           ((electricity_EM_sim +
               l_gas_EM_sim + 
               n_gas_EM_sim) - 
              (hous_23 + 
                 hous_36_b + 
                 hous_29_b)),
         tc_2030_EM_nzs_energy = 
           tc_2030_nzs -
           ((electricity_EM_sim +
               l_gas_EM_sim + 
               n_gas_EM_sim) - 
              (hous_23 + 
                 hous_36_b + 
                 hous_29_b))
         )

# View the results
print(ca_microsim_cc %>% select(decile, tc_2030_baseline, tc_2030_baseline_energy, tc_2030_nzs_energy, tc_2030_EM_baseline_energy,tc_2030_EM_nzs_energy))

```


Okay so now we estimate new welfare and poverty.


```{r}
ca_microsim_cc <- ca_microsim_cc %>%
  mutate(aec_r_2030_baseline_energy = tc_2030_baseline_energy / ae_r / PI,
         aec_r_2030_nzs_energy = tc_2030_nzs_energy / ae_r / PI,
         aec_r_2030_EM_baseline_energy =
           tc_2030_EM_baseline_energy / ae_r / PI,
         aec_r_2030_EM_nzs_energy =
           tc_2030_EM_nzs_energy / ae_r / PI) %>%
  mutate(poor_2030_baseline_energy =
           if_else(aec_r_2030_baseline_energy < 52883, 1, 0),
         poor_2030_nzs_energy =
           if_else(aec_r_2030_nzs_energy < 52883, 1, 0),
         poor_2030_EM_baseline_energy = 
           if_else(aec_r_2030_EM_baseline_energy < 52883, 1, 0),
         poor_2030_EM_nzs_energy = 
           if_else(aec_r_2030_EM_nzs_energy < 52883, 1, 0))

```


And now we see who became poor


```{r}
# We make a table to see who became poor. 
test <- ca_microsim_cc

test <- test%>%
  rename(poor_original = poor_Avpovln2022_2030_baseline,
         poor_baseline_energy = poor_2030_baseline_energy
         ) %>%
  group_by(poor_original) %>% 
  summarize(no_hh = round(sum(weight_2030_baseline, na.rm = TRUE)),
            no_pp = round(sum(weight_2030_baseline*hhsize, na.rm = TRUE)))

test %>% 
  gt()

#write.table(price_data_analysis_years, "clipboard", sep="\t", row.names=FALSE)

```


And we map these results.


```{r}
# foodpoor <- ca_microsim_cc %>%
#   mutate(new_poor_food_base = if_else(
#     poor_cc_avg_food2 == 1 & poor_cc_avg == 0, 1, 0),
#          new_poor_food_dryhot = if_else(
#            poor_cc_avg_food1 == 1 & poor_cc_avg == 0, 1, 0),
#     marz = as_factor(marz)) %>% 
#   mutate(marz = if_else(marz == "VayotsDzor", "Vayots Dzor", marz)) %>% 
#   mutate(marz = if_else(marz == "Sjunik", "Syunik", marz)) %>% 
#   select(marz, poor_Avpovln2022, poor_cc_avg, poor_cc_max,
#          poor_cc_avg_food1, poor_cc_avg_food2, new_poor_food_base,
#          new_poor_food_dryhot, weight, hhsize)
# 
# fp <-foodpoor %>% 
#   group_by(marz) %>% 
#   summarize(new_poor = round(sum(new_poor_food_dryhot * weight*hhsize, na.rm = TRUE))) %>% 
#   mutate(label = paste0(marz," (", new_poor, ")"))
# 
# 
# ##write.table(fp, "clipboard", sep="\t", row.names=FALSE)
# fp_map <- adm1 |> 
#   left_join(fp, join_by(marz == marz))
# 
# fp_map <-tm_shape(fp_map)+
#   tm_polygons("new_poor", legend.show = FALSE) +
#   tm_text("label", size = .7, col = "black")+
#   tm_layout(legend.position = c("right", "top"), 
#             title= "Additional Poor Dry-Hot Scenario", 
#             title.position = c('left', 'bottom'),
#             title.size = 0.9)
# 
# fp_map

```


Let's plot how the distribution moves with all these measures.

Food prices


```{r}
# Basic density plot comparing equivalized consumption per capita
ggplot(ca_microsim_cc, 
       aes(x = aec_r_2030_nzs_energy, fill = 'NZS + Energy Price')) +
  geom_density(alpha = 0.5) +
  # geom_density(
  #   data = ca_microsim_cc,
  #   aes(x = aec_r_2030_dry_hot, fill = 'Dry/Hot'),
  #   alpha = 0.5) +
  geom_density(
    data = ca_microsim_cc,
    aes(x = aec_r_2030_baseline_energy, fill = 'Baseline + Energy Price'),
    alpha = 0.5) +
  # geom_density(
  #   data = ca_microsim_cc,
  #   aes(x = aec_r_2030_baseline_lab_cc_avg, fill = 'Direct CC'),
  #   alpha = 0.5) +
  geom_density(
    data = ca_microsim_cc,
    aes(x = aec_r_2030_baseline, fill = 'Baseline'),
    alpha = 0.5) +
  labs(
    fill = "Scenario Variant", 
    # title = "Comparison of Consumption Distributions", 
    x = "Equivalized consumption (Dram)", 
    y = "Probability") +
  theme_minimal()+
  coord_cartesian(xlim = c(00000, 300000))+
                 # ylim = c(0.000005,0.0000160)) + # Zoom in without removing data
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma)+
  geom_vline(xintercept = 55883, 
             color = "red", 
             linetype = "dotted", 
             linewidth =0.8) +
  annotate("text", 
           x = 55883, 
           y = 0.0000055, 
           #label = "Poverty line\nAMD 55,883", 
           label = "Poverty line", 
           color = "black", 
           hjust = -0.1, 
           # vjust = -3.5,
           #angle = 90, 
           size = 3)
```


Energy


```{r}
# Basic density plot comparing equivalized consumption per capita
ggplot(ca_microsim_cc, 
       aes(x = aec_r_2030_nzs_energy, fill = 'NZS + Energy Price')) +
  geom_density(alpha = 0.5) +
  # geom_density(
  #   data = ca_microsim_cc,
  #   aes(x = aec_r_2030_dry_hot, fill = 'Dry/Hot'),
  #   alpha = 0.5) +
  geom_density(
    data = ca_microsim_cc,
    aes(x = aec_r_2030_baseline_energy, fill = 'Baseline + Energy Price'),
    alpha = 0.5) +
  # geom_density(
  #   data = ca_microsim_cc,
  #   aes(x = aec_r_2030_baseline_lab_cc_avg, fill = 'Direct CC'),
  #   alpha = 0.5) +
  geom_density(
    data = ca_microsim_cc,
    aes(x = aec_r_2030_baseline, fill = 'Baseline'),
    alpha = 0.5) +
  labs(
    fill = "Scenario Variant", 
    # title = "Comparison of Consumption Distributions", 
    x = "Equivalized consumption (Dram)", 
    y = "Probability") +
  theme_minimal()+
  coord_cartesian(xlim = c(20000, 150000),
                  ylim = c(0.000005,0.0000160)) + # Zoom in without removing data
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma)+
  geom_vline(xintercept = 55883, 
             color = "red", 
             linetype = "dotted", 
             linewidth =0.8) +
  annotate("text", 
           x = 55883, 
           y = 0.0000110, 
           #label = "Poverty line\nAMD 55,883", 
           label = "Poverty line", 
           color = "black", 
           hjust = -0.1, 
           # vjust = -3.5,
           #angle = 90, 
           size = 3)
```


And we also plot the cumulative distributions.

For food prices and cc


```{r}
# Plot the cumulative distribution with left-facing arrows
ggplot(ca_microsim_cc, 
       aes(x = aec_r_2030_baseline_foodPI, color = 'Direct CC + Food Price')) +
  stat_ecdf(geom = "step") +
  # stat_ecdf(data = ca_microsim_cc, 
  #           aes(x = aec_r_2030_baseline_lab_avg, color = 'Baseline + Labor Productivity')) +
  stat_ecdf(data = ca_microsim_cc, 
            aes(x = aec_r_2030_dry_hot_food2, color = 'Dry/Hot + Food Price')) +
  stat_ecdf(data = ca_microsim_cc, 
            aes(x = aec_r_2030_baseline_lab_cc_avg, color = 'Direct CC')) +
  stat_ecdf(data = ca_microsim_cc, 
            aes(x = aec_r_2030_baseline, color = 'Baseline')) +
  labs(
    color = "Scenario Variant", 
    # title = "Comparison of Cumulative Consumption Distributions", 
    x = "Equivalized consumption (Dram)", 
    y = "Cumulative Probability") +
  theme_minimal() +
  coord_cartesian(xlim = c(40000, 110000)) + 
  scale_x_continuous(labels = scales::comma) +
  # geom_vline(xintercept = 55883, 
  #            color = "red", 
  #            linetype = "dotted", 
  #            linewidth = 0.8) +
  # annotate("text", 
  #          x = 55883, 
  #          y = 0.5, 
  #          label = "Poverty line", 
  #          color = "black", 
  #          hjust = -0.1, 
  #          size = 3) +
  annotate("segment", x = 70000, xend = 65000, y = 0.2, yend = 0.2, 
           arrow = arrow(length = unit(0.3, "cm")), color = "black") +
  annotate("text", x = 72500, y = 0.2, label = "Shift due to shocks", hjust = 0) 
  # annotate("segment", x = 80000, xend = 75000, y = 0.4, yend = 0.4, 
  #          arrow = arrow(length = unit(0.3, "cm")), color = "black") +
  # annotate("text", x = 82500, y = 0.4, label = "Shift due to shocks", hjust = 0)



```


For energy prices


```{r}
# Plot the cumulative distribution with left-facing arrows
ggplot(ca_microsim_cc, 
       aes(x = aec_r_2030_EM_nzs_energy, color = 'NZS + Energy Price')) +
  stat_ecdf(geom = "step") +
  # stat_ecdf(data = ca_microsim_cc, 
  #           aes(x = aec_r_2030_baseline_lab_avg, color = 'Baseline + Labor Productivity')) +
  stat_ecdf(data = ca_microsim_cc, 
            aes(x = aec_r_2030_EM_baseline_energy, color = 'Baseline + Energy Price')) +
  stat_ecdf(data = ca_microsim_cc, 
            aes(x = aec_r_2030_baseline, color = 'Baseline')) +
  labs(
    color = "Scenario Variant", 
    # title = "Comparison of Cumulative Consumption Distributions", 
    x = "Equivalized consumption (Dram)", 
    y = "Cumulative Probability") +
  theme_minimal() +
  coord_cartesian(xlim = c(40000, 110000)) + 
  scale_x_continuous(labels = scales::comma) +
  # geom_vline(xintercept = 55883, 
  #            color = "red", 
  #            linetype = "dotted", 
  #            linewidth = 0.8) +
  # annotate("text", 
  #          x = 55883, 
  #          y = 0.5, 
  #          label = "Poverty line", 
  #          color = "black", 
  #          hjust = -0.1, 
  #          size = 3) +
  annotate("segment", x = 70000, xend = 65000, y = 0.2, yend = 0.2, 
           arrow = arrow(length = unit(0.3, "cm")), color = "black") +
  annotate("text", x = 72500, y = 0.2, label = "Shift due to shocks", hjust = 0) 
  # annotate("segment", x = 80000, xend = 75000, y = 0.4, yend = 0.4, 
  #          arrow = arrow(length = unit(0.3, "cm")), color = "black") +
  # annotate("text", x = 82500, y = 0.4, label = "Shift due to shocks", hjust = 0)



```


### Disaggregation of poverty measures

We bring back poverty to the people's dataset.


```{r}
# We extract household poverty designations from the data
new_poor <- ca_microsim_cc %>% 
  select(household_id,
         weight_2030_baseline,
         weight_2030_dry_hot,
         poor_Avpovln2022_2022, 
         poor_Avpovln2022_2030_baseline, 
         poor_Avpovln2022_2030_dry_hot,
         poor_Avpovln2022_2030_nzs,
         poor_2030_baseline_lab_avg, 
         poor_2030_baseline_lab_max,
         poor_2030_baseline_cc_avg,
         poor_2030_baseline_cc_max, 
         poor_2030_baseline_lab_cc_avg, 
         poor_2030_baseline_lab_cc_max, 
         poor_2030_baseline_food1,
         poor_2030_dry_hot_food2,
         poor_2030_baseline_lab_cc_foodPI,
         poor_2030_baseline_energy,
         poor_2030_nzs_energy,
         poor_2030_EM_baseline_energy,
         poor_2030_EM_nzs_energy
         )

# And merge them back into the people dataset
pp_microsim_cc <- pp_microsim_cc %>% 
  select(-c(poor_Avpovln2022,
           weight_2030_baseline,
           weight_2030_dry_hot)) %>% 
  left_join(new_poor, join_by(household_id)) %>% 
  mutate(female = if_else(gender == 2, 1,0),
         youth = if_else(age < 15, 1, 0))

```


Let's find homes where more than 50% of income comes from agriculture. We first find the fraction of household labor income that comes from agriculture.


```{r}
ag_labinc_fraction <- pp_microsim_cc %>% 
  mutate(
    ag_lab_income =
      if_else(
        lmarket == 1, 
        monthly_labor_income_2030_baseline, NA)
  ) %>% 
  group_by(household_id) %>%
  summarize(
    ag_labinc =
      sum(ag_lab_income, na.rm = TRUE),
    hh_labinc = 
      sum(monthly_labor_income_2030_baseline, na.rm = TRUE)) %>%
  mutate(ag_lab_fraction = if_else(hh_labinc == 0, 0, ag_labinc/ hh_labinc)) %>% 
  select(household_id, ag_lab_fraction)
```


And then we add ag income sources and evaluate if they are at least 50% of total income


```{r}
ag_income_50 <- ic_microsim_cc %>%
  left_join(ag_labinc_fraction, join_by(household_id==household_id)) %>% 
  rename(household_id = household_id) %>% 
  mutate(
    across(
      c(inc2_2030_baseline,
        inc3_2030_baseline,
        inc4, 
        totalinc_2030_baseline), ~replace_na(., 0))) %>%
  mutate(
    ag_income =
      inc2_2030_baseline +
      inc3_2030_baseline +
      inc4 * ag_lab_fraction,
    ag_fraction = if_else(
      totalinc_2030_baseline == 0, 0, ag_income / totalinc_2030_baseline)
    ) %>%
  mutate(
    is_ag_home = if_else(ag_fraction >= 0.5, "Ag. HH (>= 50%)", "Other HH")
  ) %>% 
  select(household_id, is_ag_home)
  
```


We make a table to see who became poor.

### The table


```{r}
#| warning: false
#| message: false

test <- pp_microsim_cc

test <- test%>%
  left_join(ag_income_50, join_by(household_id)) %>% 
#  filter(rural_dummy ==1 & is_ag_home == "Ag. HH (>= 50%)") %>%  
  rename(poor_original = poor_Avpovln2022_2030_baseline,
         poor_dh = poor_Avpovln2022_2030_dry_hot,
         poor_nzs = poor_Avpovln2022_2030_nzs,
         poor_lab = poor_2030_baseline_lab_avg,
         poor_cc = poor_2030_baseline_cc_avg,
         poor_lab_cc = poor_2030_baseline_lab_cc_avg,
         poor_foodPI = poor_2030_baseline_lab_cc_foodPI,
         poor_dh_food = poor_2030_dry_hot_food2,
         poor_b_energy = poor_2030_baseline_energy,
         poor_nzs_energy = poor_2030_nzs_energy,
         poor_EM_b_energy = poor_2030_EM_baseline_energy,
         poor_EM_nzs_energy = poor_2030_EM_nzs_energy
         ) %>%
  group_by(poor_nzs) %>% 
  summarize(no_pp = sum(weight_2030_nzs, na.rm = TRUE),
            female = sum(female*weight_2030_nzs, na.rm = TRUE),
            male = no_pp - female,
            youth = sum(youth*weight_2030_nzs, na.rm = TRUE),
            non_youth = no_pp - youth,
            rural = sum(rural_dummy *weight_2030_nzs, na.rm = TRUE),
            urban = no_pp - rural
            )

test %>% 
  gt()

write.table(test, "clipboard", sep="\t", row.names=FALSE)
```


### Poverty gap


```{r}
# Get the list of columns that start with 'aec_r_2030'
income_columns <- names(ca_microsim_cc)[grepl("^aec_r", names(ca_microsim_cc))]

aecrs <- ca_microsim_cc %>% 
  select(household_id, all_of(income_columns))

pp_microsim_cc_pov <- pp_microsim_cc %>% 
  left_join(aecrs, join_by(household_id))
```


This one is unweighted, just for reference.


```{r}
# Define the poverty line
poverty_line <- 52883

# Create a function to calculate both measures
calculate_measures <- function(column) {
  income <- pp_microsim_cc_pov[[column]]
  fgt1 <- ineq::Foster(income, poverty_line, parameter = 1)
  fgt2 <- ineq::Foster(income, poverty_line, parameter = 2)
  gini <- ineq::Gini(income, corr = FALSE, na.rm = TRUE)
  return(data.frame(
    `Scenario / Variant` = column,
    `FGT (alpha=1)` = fgt1,
    `FGT (alpha=2)` = fgt2,
    `Gini Coefficient` = gini
  ))
}

# Apply the function to each income column and bind the results into a single dataframe
results_df <- income_columns %>%
  map_dfr(calculate_measures)

# Print the results
results_df

write.table(results_df, "clipboard", sep="\t", row.names=FALSE)
```



This one is weighted.


```{r}
# Define the poverty line
poverty_line <- 52883

# Create a lookup table for the weights
lookup_table <- data.frame(
  Income_Variable = 
    c("aec_r_2022",
      "aec_r_2030_baseline", 
      "aec_r_2030_dry_hot", 
      "aec_r_2030_nzs",
      "aec_r_2030_baseline_lab_avg",
      "aec_r_2030_baseline_lab_max",
      "aec_r_2030_baseline_cc_avg",
      "aec_r_2030_baseline_cc_max",
      "aec_r_2030_baseline_lab_cc_avg",
      "aec_r_2030_baseline_lab_cc_max",
      "aec_r_2030_baseline_food1", 
      "aec_r_2030_dry_hot_food2",
      "aec_r_2030_baseline_foodPI",
      "aec_r_2030_baseline_energy",
      "aec_r_2030_nzs_energy", 
      "aec_r_2030_EM_baseline_energy",
      "aec_r_2030_EM_nzs_energy"),
  Weight_Variable = 
    c("weight", 
      "weight_2030_baseline", 
      "weight_2030_dry_hot", 
      "weight_2030_nzs",
      "weight_2030_baseline", 
      "weight_2030_baseline",
      "weight_2030_baseline", 
      "weight_2030_baseline",
      "weight_2030_baseline", 
      "weight_2030_baseline",
      "weight_2030_baseline", 
      "weight_2030_dry_hot",
      "weight_2030_baseline", 
      "weight_2030_baseline",
      "weight_2030_nzs", 
      "weight_2030_baseline",
      "weight_2030_nzs")
)

# Function to calculate the weighted FGT
weighted_FGT <- function(
    income, 
    weight, 
    poverty_line, 
    alpha) {
  if (alpha == 0) {
    # Calculate weighted poverty headcount
    poverty_headcount <- sum(
      weight[income < poverty_line]) / sum(weight)
    return(poverty_headcount)
  } else {
    # Calculate the normalized poverty gap
    # and ensure it is non-negative
    poverty_gap <- pmax(
      0, (poverty_line - income) / poverty_line)
    weighted_poverty_gap <- (poverty_gap ^ alpha) * weight
    FGT <- sum(weighted_poverty_gap) / sum(weight)
    return(FGT)
  }
}


# Function to calculate both measures with weights
calculate_measures <- function(Income_Variable, Weight_Variable) {
  income <- pp_microsim_cc_pov[[Income_Variable]]
  weight <- pp_microsim_cc_pov[[Weight_Variable]]
  
  # Calculate weighted FGT (alpha = 0) for poverty headcount
  fgt0 <- weighted_FGT(income, weight, poverty_line, alpha = 0)
  
  # Calculate weighted FGT (alpha = 1) for poverty gap
  fgt1 <- weighted_FGT(income, weight, poverty_line, alpha = 1)
  
  # Calculate weighted FGT (alpha = 2) for poverty severity
  fgt2 <- weighted_FGT(income, weight, poverty_line, alpha = 2)
  
  # Calculate weighted Gini coefficient
  gini <- acid::weighted.gini(income, w = weight)
  
  return(data.frame(
    `Income Variable` = Income_Variable,
    `FGT (alpha=0) - Poverty Headcount` = fgt0,
    `FGT (alpha=1) - Poverty Gap` = fgt1,
    `FGT (alpha=2) - Poverty Severity` = fgt2,
    `Gini Coefficient` = gini
  ))
}

# Apply the function to each row in the lookup table and bind the results into a single dataframe
results_df1 <- pmap_dfr(list(lookup_table$Income_Variable, lookup_table$Weight_Variable), calculate_measures)

# Print the results
print(results_df1)

write.table(results_df1, "clipboard", sep="\t", row.names=FALSE)
```

```{r}
# foodpoor <- ca_microsim_cc %>%
#   mutate(new_poor_food_base = if_else(
#     poor_2030_baseline_lab_cc_foodPI == 1 &
#       poor_2030_baseline_lab_cc_avg == 0, 1, 0),
#          new_poor_food_dryhot = if_else(
#            poor_cc_avg_food1 == 1 & poor_cc_avg == 0, 1, 0),
#     marz = as_factor(marz)) %>% 
#   mutate(marz = if_else(marz == "VayotsDzor", "Vayots Dzor", marz)) %>% 
#   mutate(marz = if_else(marz == "Sjunik", "Syunik", marz)) %>% 
#   select(marz, poor_Avpovln2022_2022, 
#          poor_Avpovln2022_2030_baseline, 
#          poor_Avpovln2022_2030_dry_hot,
#          poor_2030_baseline_lab_avg, 
#          poor_2030_baseline_lab_max,
#          poor_2030_baseline_cc_avg,
#          poor_2030_baseline_cc_max, 
#          poor_2030_baseline_lab_cc_avg, 
#          poor_2030_baseline_lab_cc_max, 
#          poor_2030_baseline_food1,
#          poor_2030_dry_hot_food2,
#          poor_2030_baseline_lab_cc_foodPI,
#          weight_2030_baseline,
#          weight_2030_dry_hot,
#          hhsize)
# 
# fp <-foodpoor %>% 
#   group_by(marz) %>% 
#   summarize(new_poor = round(sum(new_poor_food_dryhot * weight*hhsize, na.rm = TRUE))) %>% 
#   mutate(label = paste0(marz," (", new_poor, ")"))
# 
# 
# ##write.table(fp, "clipboard", sep="\t", row.names=FALSE)
# fp_map <- adm1 |> 
#   left_join(fp, join_by(marz == marz))
# 
# fp_map <-tm_shape(fp_map)+
#   tm_polygons("new_poor", legend.show = FALSE) +
#   tm_text("label", size = .7, col = "black")+
#   tm_layout(legend.position = c("right", "top"), 
#             title= "Additional Poor Dry-Hot Scenario", 
#             title.position = c('left', 'bottom'),
#             title.size = 0.9)
# 
# fp_map
```

```{r}
new_poor_scenarios <- pp_microsim_cc %>%
  left_join(ag_income_50, join_by(household_id)) %>% 
  mutate(
    poor_baseline = poor_Avpovln2022_2030_baseline,
    poor_dry_hot = poor_Avpovln2022_2030_dry_hot,
    poor_nzs = poor_Avpovln2022_2030_nzs,
    new_poor_lab_cc = if_else(
      poor_Avpovln2022_2030_baseline == 0 &
        poor_2030_baseline_lab_cc_avg == 1,
      1,
      0
    ),
    new_poor_lab_cc_foodPI = if_else(
      poor_Avpovln2022_2030_baseline == 0 &
        poor_2030_baseline_lab_cc_foodPI == 1,
      1,
      0
    ),
    new_poor_dry_hot_food2 = if_else(
      poor_Avpovln2022_2030_dry_hot == 0 &
        poor_2030_dry_hot_food2 == 1,
      1,
      0
    ),
    new_poor_b_energy = if_else(
      poor_Avpovln2022_2030_baseline == 0 &
        poor_2030_baseline_energy == 1,
      1,
      0
    ),
    new_poor_nzs_energy = if_else(
      poor_Avpovln2022_2030_nzs == 0 &
        poor_2030_nzs_energy == 1,
      1,
      0
    ),
    new_poor_EM_b_energy = if_else(
      poor_Avpovln2022_2030_baseline == 0 &
        poor_2030_EM_baseline_energy == 1,
      1,
      0
    ),
    new_poor_EM_nzs_energy = if_else(
      poor_Avpovln2022_2030_nzs == 0 &
        poor_2030_EM_nzs_energy == 1,
      1,
      0
    )
  ) %>%
  group_by(marz) %>% # has to be marz for the next chunk to work
  summarize(
    total_population = sum(weight_2030_baseline, na.rm = TRUE),
    poor_baseline =
      sum(poor_baseline * weight_2030_baseline, na.rm = TRUE),
    poor_dry_hot =
      sum(poor_dry_hot * weight_2030_dry_hot, na.rm = TRUE),
    poor_nzs =
      sum(poor_nzs * weight_2030_nzs, na.rm = TRUE),
    new_p_lab_cc =
      sum(new_poor_lab_cc * weight_2030_baseline, na.rm = TRUE),
    new_p_lab_cc_foodPI =
      sum(new_poor_lab_cc_foodPI * weight_2030_baseline, na.rm = TRUE),
    new_p_dry_hot_food2 =
      sum(new_poor_dry_hot_food2 * weight_2030_dry_hot, na.rm = TRUE),
    new_p_baseline_energy =
      sum(new_poor_b_energy * weight_2030_baseline, na.rm = TRUE),
    new_p_nzs_energy = 
      sum(new_poor_nzs_energy * weight_2030_nzs, na.rm = TRUE),
    new_p_EM_baseline_energy =
      sum(new_poor_EM_b_energy * weight_2030_baseline, na.rm = TRUE),
    new_p_EM_nzs_energy = 
      sum(new_poor_EM_nzs_energy * weight_2030_nzs, na.rm = TRUE)
  )

write.table(new_poor_scenarios, "clipboard", sep="\t", row.names=FALSE)

##write.table(test, "clipboard", sep="\t", row.names=FALSE)

```


And we create labels for our map.


```{r}
new_poor_map <- adm1 %>% # previous chunk has to be grouped by marz
  left_join(new_poor_scenarios, join_by(marz)) %>%
  mutate(
    new_p_lab_cc_pct = new_p_lab_cc / total_population *
          100,
    new_poor_lab_cc_foodPI_pct = new_p_lab_cc_foodPI /
         total_population * 100,
    new_poor_dry_hot_food2_pct = new_p_dry_hot_food2 /
         total_population * 100,
    new_poor_baseline_energy_pct = new_p_baseline_energy /
      total_population*100,
    new_poor_nzs_energy_pct = new_p_nzs_energy / total_population * 100,
    new_poor_EM_baseline_energy_pct = new_p_EM_baseline_energy /
      total_population*100,
    new_poor_EM_nzs_energy_pct = new_p_EM_nzs_energy / total_population * 100
  ) %>% 
  mutate(
    new_p_lab_cc_label    = paste0(marz, "\n(", sprintf("%.1f%%", new_p_lab_cc_pct), ")"),
    new_p_lab_cc_foodPI_label = paste0(marz, "\n(", sprintf("%.1f%%", new_poor_lab_cc_foodPI_pct), ")"),
    new_p_dry_hot_food2_label = paste0(marz, "\n(", sprintf("%.1f%%", new_poor_dry_hot_food2_pct), ")"),
    new_p_b_energy_label = paste0(marz, "\n(", sprintf("%.1f%%", new_poor_baseline_energy_pct), ")"),
    new_p_nzs_energy_label = paste0(marz, "\n(", sprintf("%.1f%%", new_poor_nzs_energy_pct), ")"),
    new_p_EM_b_energy_label = paste0(marz, "\n(", sprintf("%.1f%%", new_poor_EM_baseline_energy_pct), ")"),
    new_p_EM_nzs_energy_label = paste0(marz, "\n(", sprintf("%.1f%%", new_poor_EM_nzs_energy_pct), ")")
  )
```


Let's map different scenarios.


```{r}
map_DirectCC <- tm_shape(new_poor_map)+
  tm_polygons("new_p_lab_cc_pct", 
              title="Percent", 
              #legend.show = TRUE,
              legend.show = FALSE,
              style = "fixed",
              scale = 0.5,
              breaks = c(0,0.5, 1,1.5,2,2.5,3,3.5,4)) +
  tm_text(c("new_p_lab_cc_label"), size = .7, col = "black")+
  tm_layout(legend.position = c("right", "top"),
            frame = FALSE,
            #legend.outside = TRUE,
            title= "Direct CC",
            title.position = c('left', 'bottom'),
            title.size = 0.9)
map_DirectCC

```


And the second variant


```{r}
tm_shape(new_poor_map)+
  tm_polygons("new_poor_lab_cc_foodPI_pct",
              title="Percent", 
              legend.show = TRUE) +
  tm_text(c("new_p_lab_cc_foodPI_label"), size = .7, col = "black")+
  tm_layout(legend.position = c("right", "top"), 
            title= "New poor as a percentage of Marz population\nDirect CC + Food Price",
#            outer.margins=c(.10,.10, .10, .10), 
            title.position = c('left', 'bottom'),
            title.size = 0.9)

```


Second variant b


```{r}
map_dh_fp <- tm_shape(new_poor_map)+
  tm_polygons("new_poor_dry_hot_food2_pct",
              title="Percent", 
              legend.show = TRUE,
              style = "fixed",
              scale = 0.5,
              breaks = c(0,0.5, 1,1.5,2,2.5,3,3.5,4)) +
  tm_text(c("new_p_dry_hot_food2_label"), size = .7, col = "black")+
  tm_layout(
    #legend.outside = TRUE,
    legend.position = c("right", "top"),
    title.snap.to.legend = FALSE,
    title = 
      "\nDry/Hot + Food Price",
    frame = FALSE,
#            outer.margins=c(.10,.10, .10, .10), 
            title.position = c('left', 'bottom'),
            title.size = 0.9)
map_dh_fp
```


And the third variant


```{r}
tm_shape(new_poor_map)+
  tm_polygons("new_poor_baseline_energy_pct",
              title="Percent", 
              legend.show = TRUE,) +
  tm_text(c("new_p_b_energy_label"), size = .7, col = "black")+
  tm_layout(legend.position = c("right", "top"), 
            title= "New poor as a percentage of Marz population\nBaseline + Energy Price",
            # outer.margins=c(.10,.10, .10, .10), 
            title.position = c('left', 'bottom'),
            title.size = 0.9)

```


And the fourth variant


```{r}
tm_shape(new_poor_map)+
  tm_polygons("new_poor_nzs_energy_pct",
              title="Percent", 
              legend.show = TRUE) +
  tm_text(c("new_p_nzs_energy_label"), size = .7, col = "black")+
  tm_layout(legend.position = c("right", "top"), 
            title= "New poor as a percentage of Marz population\nNZS + Energy Price",
            #outer.margins=c(.10,.10, .10, .10), 
            title.position = c('left', 'bottom'),
            title.size = 0.9,
            asp = 1)

```


Fifth


```{r}
tm_shape(new_poor_map)+
  tm_polygons("new_poor_EM_baseline_energy_pct",
              title="Percent", 
              legend.show = TRUE) +
  tm_text(c("new_p_EM_b_energy_label"), size = .7, col = "black")+
  tm_layout(legend.position = c("right", "top"), 
            title= "New poor as a percentage of Marz population\nBaseline + Energy Model Price",
#            outer.margins=c(.10,.10, .10, .10), 
            title.position = c('left', 'bottom'),
            title.size = 0.9)

```


Sixth


```{r}
tm_shape(new_poor_map)+
  tm_polygons("new_poor_EM_nzs_energy_pct",
              title="Percent", 
              legend.show = TRUE) +
  tm_text(c("new_p_EM_nzs_energy_label"), size = .7, col = "black")+
  tm_layout(legend.position = c("right", "top"), 
            title= "New poor as a percentage of Marz population\nNZS + Energy Model Price",
#            outer.margins=c(.10,.10, .10, .10), 
            title.position = c('left', 'bottom'),
            title.size = 0.9)

```


A combined map of Direct CC and Dry/Hot + Food Price


```{r}
tmap_arrange(map_DirectCC, map_dh_fp)

```




Now let's show average losses by decile as a percentage of total spending.


```{r}
avg_scenario_losses <- ca_microsim_cc %>% 
  mutate(
    tc_loss_lab_cc = if_else(
      (tc_2030_baseline_lab_cc_avg - tc_2030_baseline)< 0,
      (tc_2030_baseline_lab_cc_avg - tc_2030_baseline)/
        tc_2030_baseline,NA),
    tc_loss_lab_cc_foodPI = if_else(
      (tc_2030_baseline_lab_cc_foodPI - tc_2030_baseline)< 0,
      (tc_2030_baseline_lab_cc_foodPI - tc_2030_baseline)/
        tc_2030_baseline,NA)
         ) %>%
  group_by(decile) %>% 
  summarize(no_hh = 
              round(
                sum(
                  weight_2030_baseline, na.rm = TRUE), digits = 0
                ),
            avg_tc = 
              round(
                weighted.mean(
                  tc_2030_baseline, weight_2030_baseline, na.rm = TRUE), digits = 2
                ),
            avg_tc_usd = 
              round(
                weighted.mean(
                  tc_2030_baseline, weight_2030_baseline, na.rm = TRUE)*er, digits = 1
                ),
            avg_loss_lab_cc = 
              round(
                weighted.mean(
                  tc_loss_lab_cc, 
                  weight_2030_baseline, 
                  na.rm = TRUE), 
                digits = 4
                ),
            avg_loss_lab_cc_foodPI = 
              round(
                weighted.mean(
                  tc_loss_lab_cc_foodPI, 
                  weight_2030_baseline, 
                  na.rm = TRUE), digits = 4),
            # avg_loss_b_energy = 
            #   round(
            #     weighted.mean(
            #       tc_loss_lab_cc_foodPI, 
            #       weight_2030_baseline, 
            #       na.rm = TRUE), digits = 4),
            # avg_loss_nzs_energy = 
            #   round(
            #     weighted.mean(
            #       tc_loss_lab_cc_foodPI, 
            #       weight_2030_baseline, 
            #       na.rm = TRUE), digits = 4),
            # avg_loss_EM_b_energy = 
            #   round(
            #     weighted.mean(
            #       tc_loss_lab_cc_foodPI, 
            #       weight_2030_baseline, 
            #       na.rm = TRUE), digits = 4),
            # avg_loss_EM_nzs_energy = 
            #   round(
            #     weighted.mean(
            #       tc_loss_lab_cc_foodPI, 
            #       weight_2030_baseline, 
            #       na.rm = TRUE), digits = 4)
            )

##write.table(avg_scenario_losses, "clipboard", sep="\t", row.names=FALSE)

avg_scenario_losses %>% 
  gt()
```


Energy price index interpolation


```{r}
# Sample data
data <- data.frame(
  year = c(2020, 2030),
  value = c(100.00000,103.18920)  
)

# Define the years for interpolation
years <- seq(2020, 2030, by = 1)

# Perform linear interpolation
interpolated_values <- approx(data$year, data$value, xout = years)

# Create a data frame with the interpolated results
interpolated_data <- data.frame(
  year = interpolated_values$x,
  value = interpolated_values$y
)

# Display the result
print(interpolated_data)

```


The inquiry is who is getting hit the most from changes to energy prices.


```{r}
#| warning: false
#| message: false

energy_shares <- ca_microsim_cc %>% 
  left_join(ag_income_50, join_by(household_id)) %>% 
  mutate(
    shr_energy = if_else(tc_2022==0,NA, (hous_23+hous_36_b+hous_29_b)/tc_2022)
  ) %>% 
  group_by(decile, is_ag_home) %>% 
  summarize(no_hh= sum(weight_2022, na.rm = TRUE),
            shr_e = weighted.mean(shr_energy, weight_2022, na.rm=TRUE))

write.table(energy_shares, "clipboard", sep="\t", row.names=FALSE)
```


Inquiry to see why Dry Hot is worse than CC after prices.


```{r}
food_check <- ca_microsim_cc %>% 
  mutate(lower3 = if_else(decile < 5,TRUE, FALSE)) %>%
  filter(lower3==TRUE) %>% 
  summarize(
    avg_exp_cc = weighted.mean(
      aec_r_2030_baseline_lab_cc_avg,
      weight_2030_baseline, na.rm = TRUE),
    distance_cc = weighted.mean(
      aec_r_2030_baseline_lab_cc_avg,
      weight_2030_baseline, na.rm = TRUE) - 52883,
    avg_exp_dh = weighted.mean(
      aec_r_2030_dry_hot, 
      weight_2030_dry_hot, na.rm = TRUE),
    distance_dh = weighted.mean(
      aec_r_2030_dry_hot, 
      weight_2030_dry_hot, na.rm = TRUE) - 52883,
    avg_exp_cc_f = weighted.mean(
      aec_r_2030_baseline_foodPI,
      weight_2030_baseline, na.rm = TRUE),
    distance_cc_f = weighted.mean(
      aec_r_2030_baseline_foodPI,
      weight_2030_baseline, na.rm = TRUE) - 52883,
    avg_exp_dh_f = weighted.mean(
      aec_r_2030_dry_hot_food2, 
      weight_2030_dry_hot, na.rm = TRUE),
    distance_dh_f = weighted.mean(
      aec_r_2030_dry_hot_food2, 
      weight_2030_dry_hot, na.rm = TRUE) - 52883,
  )
food_check

food_check %>% 
  gt()
write.table(food_check, "clipboard", sep="\t", row.names=FALSE)
```

```{r}

```



## End

1058

