---
title: "Vulnerability analysis"
author:
  - name: "Renato Vargas"
    id: rv
    email: renovargas@gmail.com
    affiliation: 
      - name: Consultant
  - name: "Natsuko Kiso Nozaki"
    id: nk
    email: nkiso@worldbank.org
    affiliation: 
      - name: The World Bank
  - name: "Julie Rozenberg"
    id: nk
    email: jrozenberg@worldbank.org
    affiliation: 
      - name: The World Bank
  - name: "Colin Lenoble"
    id: nk
    email: clenoble@worldbank.org
    affiliation: 
      - name: The World Bank
format:
  # pdf:
  #   toc: true
  #   number-sections: true
  #   colorlinks: true
  html:
    toc: true
    number-sections: true
    number-depth: 3
    highlight-style: nord
  # docx:
  #   toc: true
  #   number-sections: true
  #   highlight-style: nord  
editor: source
editor_options: 
  chunk_output_type: console
bibliography: references.bib
csl: apa-6th-edition.csl
---

## Introduction

In the context of the development of the Country Climate and Development Report (CCDR) for Armenia, the poverty team is contributing with inputs for vulnerability analysis at the household level. The methods for these inputs are in active development and benefit greatly from the practical applications and interdisciplinary discussions that take place during the creation of these CCDRs. This guide aims to document the steps carried out to link vulnerability impacts and household survey data.

As a convention, code is presented in the following format in this guide:

```{r eval=FALSE}
# Some comment that is not evaluated by R
some_variable <- some_function(some_object, some_parameter = TRUE)
```

We assume that the reader has created an Rstudio project and is familiar with basic R functions. Within that project we recommend the following file structure:

```{.txt}
root/
├── scripts
│   └── my_script.R
├── data/
|   ├── my_data.sav
|   ├── my_data.dta
|   └── my_data.csv
└── output
    ├── my_output1.csv
    └── my_output2.xlsx
```

Using RStudio project makes it possible to not use `setwd()` to establish the root directory and refer to subdirectories in a relative manner, making interoperability easier within teams and not hard coding a particular computer's file structure into the code. If you are not using RStudio, just add `setwd(r'(C:\My\path\to\project\root)')` at the beginning of your coding session.

## Preamble

We start with a clean environment, making sure that any objects from a previous session are not present. We take this oportunity to keep our country ISO code in a variable `iso` in case we need it later.

```{r}
# Clean workspace
rm(list = ls())

# Armenia country ISO code
iso <- "ARM"
```

Rather than calling our libraries as we go, we will make sure we have everything we need from the beginning.

```{r output=FALSE}
# Load packages
library(tidyverse) # includes dplyr, ggplot2 and others
library(haven)     # to read SPSS and Stata datasets
library(readxl)    # to read from MS-Excel
library(openxlsx)  # to write to MS-Excel.
library(gt)        # pretty tables
library(car)       # Companion to applied regression
library(modelr)    # regression models
library(janitor)   # pretty subtotals

# Geopackages
library(sf)        # to read and write shapefile maps
library(terra)     # to perform geocalculations
library(tmap)      # for static and interactive maps
```

We then load the datasets that we need for this study. We are lucky that the World Bank has processed some of these already for poverty analysis and so we have the original SPSS datasets with all variables for Houeholds `hh` and for Individuals `pp`, as well as a consumption aggregate `ca` and a household income `ic` dataset, which are Stata datasets. This is for the year 2022. These are imported using the `haven` package. These are based on Armenia Integrated Living Conditions Survey 2022 [@armstat_integrated_2023]. 

```{r output=FALSE}
# Original SPSS datasets
# Households (hh)
hh <- read_sav(
  "data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Households.sav")
# Persons (pp)
pp <- read_sav(
  "data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Persons.sav")

# Processed WB datasets
# Consumption aggregate at household level (ca)
ca  <- read_dta("data/ARM-HH-survey/CONSAGG2022.dta")
# Processed income at household level (ic)
ic  <- read_dta("data/ARM-HH-survey/totinc.dta") 
```

We will work non-destructively, meaning we will not rewrite these data sets and we will only create intermediate data frame objects from them to perform transformations, selections and other data management tasks. For example, we will keep household assignment to poverty status and consumption deciles handy by creating a subset of our `ca` data with only our household identifiers, deciles, and poverty.

```{r}
# From the WB processed dataset, we extract deciles and poverty
deciles <- ca |> 
  select( hhid, decile, poor_Avpovln2022, 
          poor_Foodpovln2022, poor_Lpovln2022, poor_Upovln2022)

```

We also have geographical information for level 1 in Shapefile format, which we import with the `sf` package. We rename the column with the name of the administrative region to match our household survey data set conventions to ease mergers. The `dplyr` package from the `tidyverse` meta package allows us to "pipe" or link processing steps using the `|>` pipe, which can be inserted using **Ctrl + m.** Although there is no geoprocessing in this analysis, this will come in handy for graphical presentations.

```{r}
# Geodata
# Armenia marzes or administrative level 1 shapefile
adm1 <- read_sf("data/ARM-Geodata/ARM-ADM1.shp") |> 
  select(NAM_1, COD_HH_SVY, geometry)
names(adm1)[2] <- "hh_02"
plot(adm1["NAM_1"])
```


## Asset value of income flows

### Imputed rent

*"Housing, measured as the welfare value of the flow of services households derive from their dwelling, is one of the most relevant components of households’ welfare aggregate, which is used as a basis for distributional analysis"* [@deaton_guidelines_2002; cited by @ceriani_housing_2019]. In Armenia, most households own their home, so the emergent rental market information is used to impute rent to non-renters using a log linear modeling approach described by [@ceriani_housing_2019], in which imputed rent is predicted using a combination of household characteristics (urban/rural, Marz, number of rooms, presence of an indoor toilet, number of household, square meters, type of dwelling, household members) and head of household characteristics (i.e. sex, highest completed schooling level, age group). The first step is to identify these characteristics for the regression.

We first extract relevant characteristics of the heads of household and create a heads subset of our person's database, which we call `heads`. It has our household id (`interview__key`), sex (`mem_02`), age (`mem_05`), and education level.

```{r}
heads <- pp |> 
  filter(mem_03 == 1) |> 
  select( interview__key ,mem_02, mem_05,ed_03)
```

Since we only have one head of household per household, we can join this data with our household information. We now create a subset of our household data, which we call `imputed_rent` with the relevant dwelling and head of household variables according to the model suggested by @ceriani_housing_2019.

```{r}
imputed_rent <- hh |> 
  left_join( heads , join_by(interview__key == interview__key)) |> 
  select( interview__key, hh_02, hh_03, hous_02, hous_10, hous_04,mem_02, 
          mem_05, ed_03, mem_num, hous_41, hous_19,hous_09, weight)
```

To save on the creation of unnecessary dummy variables for our regression, we take advantage of the factors present in the original SPSS files, which carry over when importing into R and are used by it to create them automatically at prediction time. Pay attention to the creation of age groups using `cut()` .

```{r}
# Convert categorical variables to factors and create dummy variables
imputed_rent <- imputed_rent  |> 
  mutate(hh_02 = as.factor(hh_02),          # Marz
         hh_03 = as.factor(hh_03),          # Urban / Rural
         hous_02 = as.factor(hous_02),      # Ownership or rental
         mem_02 = as.factor(mem_02),        # Sex
         ed_03 = as.factor(ed_03),          # Education level
         hous_41 = as.factor(hous_41),      # Type of toilet
         hous_19 = as.factor(hous_19))  |>  # Source of electricity
  mutate(age_group = cut(mem_05, breaks = c(0, 24, 34, 44, 
                                            54, 64, Inf), 
                         labels = c("15-24", "25-34", "35-44",
                                    "45-54", "55-64", "65+"),
                         right = TRUE)) |>
  mutate(age_group = as.factor(age_group)) |>
  mutate(bathroom_dummy = ifelse(hous_41 == 1, 1, 0)) |> 
  mutate(bathroom_dummy = as.factor(bathroom_dummy)) |> 
  select(-mem_05, -hous_41)  # Remove the original age variable
```

For our model, we need to concentrate on tenants who pay rent. So we subset further creating a data set called `renters_df`. Variable `hous_02` asks whether the household owns this dwelling or it is rented (with possible values 1. own, 2. rent, 3. other). And for renters, we want those whose value is larger than zero.

```{r}
renters_df <- imputed_rent |> 
  filter(hous_02 == 2) |> 
  filter(!is.na(hous_04)) |> 
  filter(hous_04 >0)
```

We are now ready to build our model:

```{r}
log_linear_model <- lm(log(hous_04) ~       # Rent, which depends on:
                         hh_02 +            # Marz
                         hh_03 +            # Urban / Rural
                         hous_10 +          # Number of rooms
                         mem_02 +           # Sex of head of HH
                         ed_03 +            # Education level
                         mem_num +          # Number of HH members
                         bathroom_dummy +   # Flushing toilet dummy
                         hous_09 +          # Total square meters
                         age_group,         # Age brackets
                       data = renters_df)
```

For space considerations, we omit the output of the model, but you can inspect the results of the model with `summary(log_linear_model)` . This particular application for Armenia results in small positive significance for total square meters and having a flushing toilet, small negative significance for being female and high negative significance for the Marzes in relation to Yerevan, as well as high negative significance for rural areas (Multiple R-squared: 0.4883). In other words, rent for Armenians will be higher if they live in urban areas, have a working toilet, have a larger imputed_rent and the head of household is male. With our coefficients we can now impute rent for our non renters. 

Before we move on, we need to de-factor some variables and re-code them so that our predictions run smoothly. We did not get predictions for education level 0 in our renters database, but there are some in our `non_renters_df` data set. Since they are factors (ie. categorical values) and not years of education, when R is running the regression, it creates dummy variables in the background for each level that it encounters in the data. Since that level was missing in the renters data, the prediction does not include it. So when it encounters that value in the non-renters data frame, R does not know how to handle it. This might not happen in your data set, but beware that if it does, this is the reason why your model won't predict. The error that gave this away read.

```{.txt}
Error in model.frame.default(Terms, newdata, 
na.action = na.action, xlev = object$xlevels): 
factor ed_03 has new levels 0 
```
So let's take care of non-trained values by making the decision to change the 12 cases that responded "none" to "primary". Another option would be to change it to "other", but since the prediction there was made with 1 observation we felt it was 
less of a disturbance this way. We find the values to change by indexing in square brackets; a powerful way of base R to slice data sets in multiple ways.

```{r}
# Take care of non training values in  the original data set
# Convert to numeric to perform the operation
imputed_rent$ed_03 <- as.numeric(as.character(imputed_rent$ed_03)) 
imputed_rent$ed_03[imputed_rent$ed_03 == 0] <- 1 # Re-code 0 to 1
imputed_rent$ed_03 <- as.factor(imputed_rent$ed_03) # Convert back to factor
```

With everything in place, we can now predict the imputed rent. Actually, the **log** of predicted rent, so we transform the log value to value in the next pipe. We can do two things. One is to create a non-renters data set, predict rent there and then join with the renters data frame. Another is just to apply the prediction to the entire imputed_rent data set and then just replace the result with missing values for the renters. We will do the latter. 

```{r}
imputed_rent <- imputed_rent |> 
  add_predictions(log_linear_model, 
                  var = "log_rent_predicted") |> 
  mutate(imputed_rent = exp(log_rent_predicted)) |> 
  # Replace renters imputed value with "missing"
  mutate(imputed_rent = if_else(hous_02 %in% c("1", "3"), 
                                NA, imputed_rent)) |> 
  # We just keep the household id and the imputed value going forward
  select( interview__key, imputed_rent)

# Remove intermediate products
rm(heads, log_linear_model, renters_df)
```

At this point we can save the prediction if we wish to do so to disk, but it is not necessary for our purposes here as we can continue using the created object `imputed_rent` in our calculations going forward. For example to output to Excel, Stata, SPSS, and CSV we would write (make sure your outputs directory exists):

```{r eval=FALSE}
# Stata
write_dta(imputed_rent, "outputs/imputed_rent.dta", version = 10)
# Excel
write.xlsx(imputed_rent,"ouptuts/imputed_rent.xlsx",
           sheetName = "imputed_rent",
           rowNames = FALSE,
           colnames = FALSE,
           overwrite = TRUE,
           asTable = FALSE
)
# SPSS
write_sav(data, "outputs/imputed_rent.sav")  
# Comma Separated Values
write.csv(imputed_rent,"outputs/imputed_rent.csv" sep = ",")
```

Let's explore the results, by first summarizing the data.

```{r}
# Average imputed rent by marz
imputed_rent_marz <- hh |> 
  left_join( deciles, join_by( interview__key == hhid)) |>
  left_join( imputed_rent, join_by( interview__key == interview__key)) |>
  select(decile, hh_02, hh_03, hous_10, imputed_rent,weight) |> 
  group_by(as_factor(hh_02)) |> 
  summarize(avg_dwelling_m2 = weighted.mean(hous_10, as.integer(weight), na.rm = TRUE),
            avg_imputed_rent = weighted.mean(imputed_rent, as.integer(weight), na.rm = TRUE))
```

And then making a table.

```{r}
imputed_rent_marz |> 
  gt() |> 
   tab_header(
    title = "Imputed rent in Armenia",
    subtitle = "Average dwelling area and imputed rent (Year 2022)"
  ) |> 
  grand_summary_rows(
    columns = c(avg_dwelling_m2,avg_imputed_rent),
    fns= list(
      Average = ~mean(., na.rm = TRUE)
      ),
    fmt = list(~ fmt_number(., decimals = 1))
  ) |> 
  fmt_number(
    columns = c(avg_dwelling_m2, avg_imputed_rent),
    decimals = 1
  ) |> 
  cols_label(
    `as_factor(hh_02)` = "Marz",
    avg_dwelling_m2 = "Average dwelling area ({{m^2}})",
    avg_imputed_rent = "Average imputed rent (AMD)"
  ) |> 
    tab_source_note(
    source_note = md("Own elaboration based on Armenia Integrated Living Conditions Survey (ARMSTAT, 2023).")
  )

```


