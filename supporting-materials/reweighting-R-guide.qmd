---
title: "A guide to reweighting in R"
author: "R code: Renato Vargas, refactored from\n\n
         Stata code by Juan Manuel Monroy and Ercio Muñoz."

format:
  # pdf:
  #   toc: true
  #   number-sections: true
  #   colorlinks: true
  html:
    toc: true
    number-sections: true
    number-depth: 3
    highlight-style: nord
  # docx:
  #   toc: true
  #   number-sections: true
  #   highlight-style: nord  
editor: source

---

## Introduction

In the context of the development of the Country Climate and Development Report (CCDR) for Armenia, the poverty team is contributing with inputs for vulnerability analysis at the household level. The methods for these inputs are in active development and benefit greatly from the practical applications and interdisciplinary discussions that take place during the creation of these CCDRs. The current guide aims to document the steps taken to use and modify existing household survey data for these efforts. The original code has been written by Juan Manuel Monroy and Ercio Muñoz using Stata and it has been reinterpreted in this guide using R to take advantage of its data tidying and processing facilities. Where necessary, other routines have been implemented to provide elements for a particular discussion. R has chosen for convenience and speed, because it doesn't require saving intermediate datasets to disk or the use of memory-intensive for loops, which saves on coding and execution times. At the same time, it is also a statistical language with most techniques implemented in its base library or through libraries.

As a convention, code is presented in the following format in this guide:

```{r eval=FALSE}
# Some comment that is not evaluated by R
some_variable <- some_function(some_object, some_parameter = TRUE)
```

We assume that the reader has created an Rstudio project and is familiar with basic R functions. Within that project we recommend the following file structure:

```{txt eval=FALSE}
root/
├── scripts
│   └── my_script.R
├── data/
|   ├── my_data.sav
|   ├── my_data.dta
|   └── my_data.csv
└── output
    ├── my_output1.csv
    └── my_output2.xlsx
```

Using RStudio project makes it possible to not use `setwd()` to establish the root directory and refer to subdirectories in a relative manner, making interoperability easier within teams and not hard coding a particular computer's file structure into the code.
If you are not using RStudio, just add `setwd(r'(C:\My\path\to\root)')` at the beginning of your coding session.

## Preamble

We start with a clean environment, making sure that any objects from a previous session are not present. We take this oportunity to keep our country ISO code in a variable `iso` in case we need it later.

```{r}
# Clean workspace
rm(list = ls())

# Armenia country ISO code
iso <- "ARM"
```

Rather than calling our libraries as we go, we will make sure we have everything we need from the beginning. 

```{r output=FALSE}
# Load packages
library(tidyverse) # includes dplyr, ggplot2 and others
library(haven)     # to read SPSS and Stata datasets
library(readxl)    # to read from MS-Excel
library(openxlsx)  # to write to MS-Excel.
library(gt)        # pretty tables
library(car)       # Companion to applied regression
library(modelr)    # regression models
library(janitor)   # pretty subtotals

# Geopackages
library(sf)        # to read and write shapefile maps
library(terra)     # to perform geocalculations
library(tmap)      # for static and interactive maps
```

We then load the datasets that we need for this study. We are lucky that the World Bank has processed some of these already for poverty analysis and so we have the original SPSS datasets with all variables for Houeholds `hh` and for Individuals `pp`, as well as a consumption aggregate `ca` and a household income `ic` dataset, which are Stata datasets. This is for the year 2022. These are imported using the `haven` package.

```{r}
# Original SPSS datasets
# Households (hh)
hh <- read_sav(
  "data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Households.sav")
# Persons (pp)
pp <- read_sav(
  "data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Persons.sav")

# Processed WB datasets
# Consumption aggregate at household level (ca)
ca  <- read_dta("data/ARM-HH-survey/CONSAGG2022.dta")
# Processed income at household level (ic)
ic  <- read_dta("data/ARM-HH-survey/totinc.dta") 
```

We will work non-destructively, meaning we will not rewrite these datasets and we will only create intermediate data frame objects from them to perform transformations, selections and other data management tasks. 

We also have geographical information for level 1 in Shapefile format, which we import with the `sf` package. We rename the column with the name of the adminstrative region to match our household survey dataset conventions to ease mergers. The `dplyr` package from the `tidyverse` meta package allows us to "pipe" or link processing steps using the `|>` pipe, which in RStudio is created with

```{r}
# Geodata
# Armenia marzes or administrative level 1 shapefile
adm1 <- read_sf("data/ARM-Geodata/ARM-ADM1.shp") |> 
  select(NAM_1, COD_HH_SVY, geometry)
names(adm1)[2] <- "hh_02"
```


















