[
  {
    "objectID": "supporting-materials/vulnerability-hh-level-impacts.html",
    "href": "supporting-materials/vulnerability-hh-level-impacts.html",
    "title": "Vulnerability Analysis Calculations",
    "section": "",
    "text": "In the context of the development of the Country Climate and Development Report (CCDR) for Armenia, the poverty team is contributing with inputs for vulnerability analysis at the household level. The methods for these inputs are in active development and benefit greatly from the practical applications and interdisciplinary discussions that take place during the creation of these CCDRs. This guide aims to document the steps carried out to link vulnerability impacts and household survey data.\nAs a convention, code is presented in the following format in this guide:\n\n# Some comment that is not evaluated by R\nsome_variable &lt;- some_function(some_object, some_parameter = TRUE)\n\nWe assume that the reader has created an Rstudio project and is familiar with basic R functions. Within that project we recommend the following file structure:\nroot/\n├── scripts\n│   └── my_script.R\n├── data/\n|   ├── my_data.sav\n|   ├── my_data.dta\n|   └── my_data.csv\n└── output\n    ├── my_output1.csv\n    └── my_output2.xlsx\nUsing RStudio project makes it possible to not use setwd() to establish the root directory and refer to subdirectories in a relative manner, making interoperability easier within teams and not hard coding a particular computer’s file structure into the code. If you are not using RStudio, just add setwd(r'(C:\\My\\path\\to\\project\\root)') at the beginning of your coding session.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis Calculations"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability-hh-level-impacts.html#introduction",
    "href": "supporting-materials/vulnerability-hh-level-impacts.html#introduction",
    "title": "Vulnerability Analysis Calculations",
    "section": "",
    "text": "In the context of the development of the Country Climate and Development Report (CCDR) for Armenia, the poverty team is contributing with inputs for vulnerability analysis at the household level. The methods for these inputs are in active development and benefit greatly from the practical applications and interdisciplinary discussions that take place during the creation of these CCDRs. This guide aims to document the steps carried out to link vulnerability impacts and household survey data.\nAs a convention, code is presented in the following format in this guide:\n\n# Some comment that is not evaluated by R\nsome_variable &lt;- some_function(some_object, some_parameter = TRUE)\n\nWe assume that the reader has created an Rstudio project and is familiar with basic R functions. Within that project we recommend the following file structure:\nroot/\n├── scripts\n│   └── my_script.R\n├── data/\n|   ├── my_data.sav\n|   ├── my_data.dta\n|   └── my_data.csv\n└── output\n    ├── my_output1.csv\n    └── my_output2.xlsx\nUsing RStudio project makes it possible to not use setwd() to establish the root directory and refer to subdirectories in a relative manner, making interoperability easier within teams and not hard coding a particular computer’s file structure into the code. If you are not using RStudio, just add setwd(r'(C:\\My\\path\\to\\project\\root)') at the beginning of your coding session.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis Calculations"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability-hh-level-impacts.html#preamble",
    "href": "supporting-materials/vulnerability-hh-level-impacts.html#preamble",
    "title": "Vulnerability Analysis Calculations",
    "section": "2 Preamble",
    "text": "2 Preamble\nWe start with a clean environment, making sure that any objects from a previous session are not present. We take this opportunity to keep our country ISO code in a variable iso in case we need it later.\n\n# Clean workspace\nrm(list = ls())\n\n# Armenia country ISO code\niso &lt;- \"ARM\"\n\n# Exchange rate USD per dram\ner &lt;- 0.002310\n\nRather than calling our libraries as we go, we will make sure we have everything we need from the beginning.\n\n# Load packages\nlibrary(tidyverse) # includes dplyr, ggplot2 and others\nlibrary(haven)     # to read SPSS and Stata datasets\nlibrary(readxl)    # to read from MS-Excel\nlibrary(openxlsx)  # to write to MS-Excel.\nlibrary(gt)        # pretty tables\nlibrary(car)       # Companion to applied regression\nlibrary(modelr)    # regression models\nlibrary(janitor)   # pretty subtotals\nlibrary(purrr)     # map vectors (aggregation)\n\n# Geopackages\nlibrary(sf)        # to read and write shapefile maps\nlibrary(terra)     # to perform geocalculations\nlibrary(tmap)      # for static and interactive maps",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis Calculations"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability-hh-level-impacts.html#datasets",
    "href": "supporting-materials/vulnerability-hh-level-impacts.html#datasets",
    "title": "Vulnerability Analysis Calculations",
    "section": "3 Datasets",
    "text": "3 Datasets\nWe then load the datasets that we need for this study. We are lucky that the World Bank has processed some of these already for poverty analysis and so we have the original SPSS datasets with all variables for Houeholds hh and for Individuals pp, as well as a consumption aggregate ca and a household income ic dataset, which are Stata datasets. This is for the year 2022. These are imported using the haven package. These are based on Armenia Integrated Living Conditions Survey 2022 (ARMSTAT, 2023).\n\n# Original SPSS datasets\n# Households (hh)\nhh &lt;- read_sav(\n  \"data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Households.sav\")\n# Persons (pp)\npp &lt;- read_sav(\n  \"data/ARM-HH-survey/original-spss-files/ILCS-ARM-2022-Persons.sav\")\n\n# Processed WB datasets\n# Consumption aggregate at household level (ca)\nca  &lt;- read_dta(\"data/ARM-HH-survey/CONSAGG2022.dta\")\n# Processed income at household level (ic)\nic  &lt;- read_dta(\"data/ARM-HH-survey/totinc.dta\") \n\nWe will work non-destructively, meaning we will not rewrite these data sets and we will only create intermediate data frame objects from them to perform transformations, selections and other data management tasks. For example, we will keep household assignment to poverty status and consumption deciles handy by creating a subset of our ca data with only our household identifiers, deciles, and poverty.\n\n# From the WB processed dataset, we extract deciles and poverty\ndeciles &lt;- ca |&gt; \n  select( hhid, decile, poor_Avpovln2022, \n          poor_Foodpovln2022, poor_Lpovln2022, poor_Upovln2022)\n\nWe also have geographical information for level 1 in Shapefile format, which we import with the sf package. We rename the column with the name of the administrative region to match our household survey data set conventions to ease mergers. The dplyr package from the tidyverse meta package allows us to “pipe” or link processing steps using the |&gt; pipe, which can be inserted using Ctrl + m. Although there is no geoprocessing in this analysis, this will come in handy for graphical presentations. Let’s have a look at it.\n\n# Geodata\n# Armenia marzes or administrative level 1 shapefile\nadm1 &lt;- read_sf(\"data/ARM-Geodata/ARM-ADM1.shp\") |&gt; \n  select(NAM_1, COD_HH_SVY, geometry) |&gt; \n    # Make sure that names match the rest of datasets\n  mutate(NAM_1 = if_else(NAM_1 == \"Gergharkunik\", \"Gegharkunik\", NAM_1))\nnames(adm1)[2] &lt;- \"hh_02\"\n\ntm_shape(adm1)+\n  tm_polygons(\"NAM_1\", legend.show = FALSE) +\n  tm_text(\"NAM_1\", size = 3/4)\n\n\n\n\n\n\n\n\nMarzes names are more accurate in the shapefile than in the survey. We will use them from here on instead of the survey factor labels.\n\nhh &lt;- hh |&gt; \n  left_join(adm1, join_by(hh_02 == hh_02)) |&gt; \n  select(-geometry)\n\nic &lt;- ic |&gt; \n  left_join(adm1, join_by(hh_02 == hh_02)) |&gt; \n  select(-geometry)\n\nFinally, but not least important, we have our vulnerability information.\n\nbuildings_aal &lt;- \n  read_xlsx(\"data/ARM-Vulnerability-Analysis/Data_AAL_AAE.xlsx\",\n            sheet = \"Building_AAL\") |&gt; \n    # Make sure that names match the rest of datasets\n  mutate(NAM_1 = if_else(NAM_1 == \"Gergharkunik\", \"Gegharkunik\", NAM_1))\n# buildings_1in100 &lt;- \n#   read_xlsx(\"data/ARM-Vulnerability-Analysis/Data_AAL_AAE.xlsx\",\n#             sheet = \"Building_1in100\") |&gt; \n#   mutate(NAM_1 = if_else(NAM_1 == \"Gergharkunik\", \"Gegharkunik\", NAM_1))\ncrops_productivity &lt;- \n  read.csv(\"data/ARM-Vulnerability-Analysis/ARM_crops_combined_REF_shock_admin1.csv\") |&gt; \n  rename(NAM_1 = Province)\n# crops_1in100 &lt;- \n#   read_xlsx(\"data/ARM-Vulnerability-Analysis/damages_1in100_agri_ADM2.xlsx\",\n#             sheet = \"crops_1in100\")\n\ncrops_aal &lt;- \n  read_xlsx(\"data/ARM-Vulnerability-Analysis/Data_AAL_AAE.xlsx\",\n            sheet = \"Agriculture_AAL\") |&gt; \n    # Make sure that names match the rest of datasets\n  mutate(NAM_1 = if_else(NAM_1 == \"Gergharkunik\", \"Gegharkunik\", NAM_1))",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis Calculations"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability-hh-level-impacts.html#asset-value-of-income-flows",
    "href": "supporting-materials/vulnerability-hh-level-impacts.html#asset-value-of-income-flows",
    "title": "Vulnerability Analysis Calculations",
    "section": "4 Asset value of income flows",
    "text": "4 Asset value of income flows\n\n4.1 Imputed rent\n“Housing, measured as the welfare value of the flow of services households derive from their dwelling, is one of the most relevant components of households’ welfare aggregate, which is used as a basis for distributional analysis” (Deaton & Zaidi, 2002; cited by Ceriani, Olivieri, & Ranzani, 2019). In Armenia, most households own their home, so the emergent rental market information is used to impute rent to non-renters using a log linear modeling approach described by (Ceriani et al., 2019), in which imputed rent is predicted using a combination of household characteristics (urban/rural, Marz, number of rooms, presence of an indoor toilet, number of household, square meters, type of dwelling, household members) and head of household characteristics (i.e. sex, highest completed schooling level, age group). The first step is to identify these characteristics for the regression.\nWe first extract relevant characteristics of the heads of household and create a heads subset of our person’s database, which we call heads. It has our household id (interview__key), sex (mem_02), age (mem_05), and education level.\n\nheads &lt;- pp |&gt; \n  filter(mem_03 == 1) |&gt; \n  select( interview__key ,mem_02, mem_05,ed_03)\n\nSince we only have one head of household per household, we can join this data with our household information. We now create a subset of our household data, which we call imputed_rent with the relevant dwelling and head of household variables according to the model suggested by Ceriani et al. (2019).\n\nimputed_rent &lt;- hh |&gt; \n  left_join( heads , join_by(interview__key == interview__key)) |&gt; \n  select( interview__key, hh_02, hh_03, hous_02, hous_10, hous_04,mem_02, \n          mem_05, ed_03, mem_num, hous_41, hous_19,hous_09, weight)\n\nTo save on the creation of unnecessary dummy variables for our regression, we take advantage of the factors present in the original SPSS files, which carry over when importing into R and are used by it to create them automatically at prediction time. Pay attention to the creation of age groups using cut() .\n\n# Convert categorical variables to factors and create dummy variables\nimputed_rent &lt;- imputed_rent  |&gt; \n  mutate(hh_02 = as.factor(hh_02),          # Marz\n         hh_03 = as.factor(hh_03),          # Urban / Rural\n         hous_02 = as.factor(hous_02),      # Ownership or rental\n         mem_02 = as.factor(mem_02),        # Sex\n         ed_03 = as.factor(ed_03),          # Education level\n         hous_41 = as.factor(hous_41),      # Type of toilet\n         hous_19 = as.factor(hous_19))  |&gt;  # Source of electricity\n  mutate(age_group = cut(mem_05, breaks = c(0, 24, 34, 44, \n                                            54, 64, Inf), \n                         labels = c(\"15-24\", \"25-34\", \"35-44\",\n                                    \"45-54\", \"55-64\", \"65+\"),\n                         right = TRUE)) |&gt;\n  mutate(age_group = as.factor(age_group)) |&gt;\n  mutate(bathroom_dummy = ifelse(hous_41 == 1, 1, 0)) |&gt; \n  mutate(bathroom_dummy = as.factor(bathroom_dummy)) |&gt; \n  select(-mem_05, -hous_41)  # Remove the original age variable\n\nFor our model, we need to concentrate on tenants who pay rent. So we subset further creating a data set called renters_df. Variable hous_02 asks whether the household owns this dwelling or it is rented (with possible values 1. own, 2. rent, 3. other). And for renters, we want those whose value is larger than zero.\n\nrenters_df &lt;- imputed_rent |&gt; \n  filter(hous_02 == 2) |&gt; \n  filter(!is.na(hous_04)) |&gt; \n  filter(hous_04 &gt;0)\n\nWe are now ready to build our model:\n\nlog_linear_model &lt;- lm(log(hous_04) ~       # Rent, which depends on:\n                         hh_02 +            # Marz\n                         hh_03 +            # Urban / Rural\n                         hous_10 +          # Number of rooms\n                         mem_02 +           # Sex of head of HH\n                         ed_03 +            # Education level\n                         mem_num +          # Number of HH members\n                         bathroom_dummy +   # Flushing toilet dummy\n                         hous_09 +          # Total square meters\n                         age_group,         # Age brackets\n                       data = renters_df)\n\nFor space considerations, we omit the output of the model, but you can inspect the results of the model with summary(log_linear_model) . This particular application for Armenia results in small positive significance for total square meters and having a flushing toilet, small negative significance for being female and high negative significance for the Marzes in relation to Yerevan, as well as high negative significance for rural areas (Multiple R-squared: 0.4883). In other words, rent for Armenians will be higher if they live in urban areas, have a working toilet, have a larger imputed_rent and the head of household is male. With our coefficients we can now impute rent for our non renters.\nBefore we move on, we need to de-factor some variables and re-code them so that our predictions run smoothly. We did not get predictions for education level 0 in our renters database, but there are some in our non_renters_df data set. Since they are factors (ie. categorical values) and not years of education, when R is running the regression, it creates dummy variables in the background for each level that it encounters in the data. Since that level was missing in the renters data, the prediction does not include it. So when it encounters that value in the non-renters data frame, R does not know how to handle it. This might not happen in your data set, but beware that if it does, this is the reason why your model won’t predict. The error that gave this away read.\nError in model.frame.default(Terms, newdata, \nna.action = na.action, xlev = object$xlevels): \nfactor ed_03 has new levels 0 \nSo let’s take care of non-trained values by making the decision to change the 12 cases that responded “none” to “primary”. Another option would be to change it to “other”, but since the prediction there was made with 1 observation we felt it was less of a disturbance this way. We find the values to change by indexing in square brackets; a powerful way of base R to slice data sets in multiple ways.\n\n# Take care of non training values in  the original data set\n# Convert to numeric to perform the operation\nimputed_rent$ed_03 &lt;- as.numeric(as.character(imputed_rent$ed_03)) \nimputed_rent$ed_03[imputed_rent$ed_03 == 0] &lt;- 1 # Re-code 0 to 1\nimputed_rent$ed_03 &lt;- as.factor(imputed_rent$ed_03) # Convert back to factor\n\nWith everything in place, we can now predict the imputed rent. Actually, the log of predicted rent, so we transform the log value to value in the next pipe. We can do two things. One is to create a non-renters data set, predict rent there and then join with the renters data frame. Another is just to apply the prediction to the entire imputed_rent data set and then just replace the result with missing values for the renters. We will do the latter.\n\nimputed_rent &lt;- imputed_rent |&gt; \n  add_predictions(log_linear_model, \n                  var = \"log_rent_predicted\") |&gt; \n  mutate(imputed_rent = exp(log_rent_predicted)) |&gt; \n  # Replace renters imputed value with \"missing\"\n  mutate(imputed_rent = if_else(hous_02 %in% c(\"2\", \"3\"),\n                                NA, imputed_rent)) |&gt;\n  # We just keep the household id and the imputed value going forward\n  select( interview__key, imputed_rent)\n\n# Remove intermediate products\nrm(heads, log_linear_model, renters_df)\n\nAt this point we can save the prediction if we wish to do so to disk, but it is not necessary for our purposes here as we can continue using the created object imputed_rent in our calculations going forward. For example to output to Excel, Stata, SPSS, and CSV we would write (make sure your outputs directory exists):\n\n# Stata\nwrite_dta(imputed_rent, \"outputs/imputed_rent.dta\", version = 10)\n# Excel\nwrite.xlsx(imputed_rent,\"ouptuts/imputed_rent.xlsx\",\n           sheetName = \"imputed_rent\",\n           rowNames = FALSE,\n           colnames = FALSE,\n           overwrite = TRUE,\n           asTable = FALSE\n)\n# SPSS\nwrite_sav(data, \"outputs/imputed_rent.sav\")  \n# Comma Separated Values\nwrite.csv(imputed_rent,\"outputs/imputed_rent.csv\" sep = \",\")\n\nLet’s explore the results, by first summarizing the data.\n\n# Average imputed rent by marz\nimputed_rent_marz &lt;- hh |&gt; \n  left_join( deciles, join_by( interview__key == hhid)) |&gt;\n  left_join( imputed_rent, join_by( interview__key == interview__key)) |&gt;\n  select(decile, hh_02, hh_03, hous_10, imputed_rent,weight, NAM_1) |&gt; \n  group_by(NAM_1) |&gt; \n  summarize(avg_dwelling_m2 = \n              weighted.mean(hous_10, as.integer(weight), na.rm = TRUE),\n            avg_imputed_rent = \n              weighted.mean(imputed_rent, as.integer(weight), na.rm = TRUE)*er)\n\nAnd then making a table.\n\ngt_table &lt;- imputed_rent_marz |&gt; \n  gt() |&gt; \n   tab_header(\n    title = \"Imputed rent in Armenia\",\n    subtitle = \"Average dwelling area and imputed rent (Year 2022)\"\n  ) |&gt; \n  grand_summary_rows(\n    columns = c(avg_dwelling_m2,avg_imputed_rent),\n    fns= list(\n      Average = ~mean(., na.rm = TRUE)\n      ),\n    fmt = list(~ fmt_number(., decimals = 1))\n  ) |&gt; \n  fmt_number(\n    columns = c(avg_dwelling_m2, avg_imputed_rent),\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    NAM_1 = \"Marz\",\n    avg_dwelling_m2 = \"Average dwelling area ({{m^2}})\",\n    avg_imputed_rent = \"Average imputed monthly rent (USD)\"\n  ) |&gt; \n    tab_source_note(\n    source_note = md(\"Own elaboration based on Armenia Integrated Living Conditions Survey (ARMSTAT, 2023).\")\n  )\n# gt_table |&gt; \n#   as_raw_html()\ngt_table\n\n\n\n\n\n\n\nImputed rent in Armenia\n\n\nAverage dwelling area and imputed rent (Year 2022)\n\n\n\nMarz\nAverage dwelling area (m2)\nAverage imputed monthly rent (USD)\n\n\n\n\n\nAragatsotn\n103.8\n87.2\n\n\n\nArarat\n102.6\n93.3\n\n\n\nArmavir\n109.3\n92.9\n\n\n\nGegharkunik\n115.4\n68.1\n\n\n\nKotayk\n96.2\n100.4\n\n\n\nLori\n87.9\n51.8\n\n\n\nShirak\n82.7\n65.9\n\n\n\nSyunik\n95.1\n89.2\n\n\n\nTavush\n97.5\n53.4\n\n\n\nVayots Dzor\n104.7\n66.6\n\n\n\nYerevan\n70.9\n216.2\n\n\nAverage\n—\n96.9\n89.5\n\n\n\nOwn elaboration based on Armenia Integrated Living Conditions Survey (ARMSTAT, 2023).\n\n\n\n\n\n\n\n\n\n\n4.2 Net present value of imputed rent\nThe previous steps help us determine the imputed monthly rent for home owners. We can treat this income as an asset by considering the net present value of future rents. We use the traditional formula:\n\\[\n\\text{NPV} = \\sum_{t=0}^{N} \\frac{C_t}{(1 + r)^t}\n\\tag{1}\\]\nWhere:\n\n\\(NPV\\) = Net Present Value\n\\(C_t\\) = Net cash inflow during the period \\(t\\)\n\\(r\\) = Discount rate\n\\(t\\) = Time period\n\\(N\\) = Total number of periods\n\nWe will use an annual discount rate of 6%, which is customary for homes, an inflation of 5% for 27 years, since the survey was conducted in the last few months of 2022 and we are making the calculation from January 01 2023 to December 31, 2050.\n\n# Parameters\ndiscount_rate &lt;- 0.06 # Annual discount rate, for example, 5%\ninflation_rate &lt;- 0.05 # Annual inflation rate, for example, 5%\nyears &lt;- 28 # Number of years to discount\n\n# Adjust rates for monthly compounding, to avoid overestimation\nmonthly_discount_rate &lt;- (1 + discount_rate)^(1/12) - 1\nmonthly_inflation_rate &lt;- (1 + inflation_rate)^(1/12) - 1\n\n# Annual imputed rent\nimputed_rent$annual_imputed_rent &lt;- imputed_rent$imputed_rent * 12 \n\nWe can do two things, either annualize the monthly income or divide our rates by 12 and have the periods in the formula be months. It depends on the kind of shocks that we want to do. For example, if we know that a 1 in a 100 year event will have an impact that will last, let’s say one and a half year, then having months is useful as we can introduce the shock as a tax that has an effect on 18 months worth of net present value. However, if we know that our shocks will have annual consequences, then doing our calculations year by year is enough.\nTo calculate each months worth of discounted present value, we use sapply() to perform the calculation over \\(years * 12\\) months. This is similar to using for loops in other languages, but it is much more efficient, because it works hard to summarize results as vectors, and avoids iterations. In this case, since we are operating the formula over the entire vector of imputed rents, month, the result return(present_value) is not a vector but a matrix called present_value that gets attached to our data set at once (not column by column) where each column represents a month’s worth of discounted present value for each household in the rows. Notice that we are using our modified monthly rates, which are adjusted (not just the annual divided by 12) to more accurately reflect the compounding value of money.\n\n# Monthly periods\nimputed_rent$present_value_rent &lt;- sapply(1:(years * 12), function(n) {\n  future_rent &lt;- imputed_rent$imputed_rent * (1 + monthly_inflation_rate)^n\n  present_value &lt;- future_rent / ((1 + monthly_discount_rate)^n)\n  return(present_value)\n})\n\nThat results in the creation of a matrix containing the monthly discounted values by month. We can see a snippet of this attached matrix, filtering for the observations that are not missing values and showing only the first four valid households and months using:\n\nimputed_rent$present_value_rent[\n  !is.na(imputed_rent$present_value_rent[, 1]), ][1:4, 1:4]\n\n      [,1]     [,2]     [,3]     [,4]\n1 20118.27 20102.39 20086.51 20070.65\n2 20619.64 20603.36 20587.09 20570.84\n3 20475.11 20458.94 20442.78 20426.64\n4 25308.52 25288.54 25268.57 25248.62\n\n\nAfter that we sum over the columns corresponding to our monthly discounted values:\n\n# Sum up the present values for the total present value over the period\nimputed_rent$net_present_value_rent &lt;- rowSums(imputed_rent$present_value_rent)\n\nFor comparison, we can do it annually as well. Here we use our annual rates (discount, and inflation) to generate a similar matrix, where all columns refer to years.\n\n# Annual periods\nimputed_rent$present_value_rent2 &lt;- sapply(1:(years), function(n) {\n  future_rent2 &lt;- imputed_rent$annual_imputed_rent * (1 + inflation_rate)^(n)\n  present_value2 &lt;- future_rent2 / ((1 + discount_rate)^n)\n  return(present_value2)\n})\n\n\n# Sum up the present values for the total present value over the period\nimputed_rent$net_present_value_rent2 &lt;- rowSums(imputed_rent$present_value_rent2)\n\n\n# Delete partial calculations\nimputed_rent &lt;- imputed_rent |&gt; \n  select(interview__key, imputed_rent, net_present_value_rent, net_present_value_rent2)\n\nFor a comparison between the two calculations of net present value, we can compare their means and their difference should be zero:\n\nhh |&gt; \n  left_join( deciles, join_by( interview__key == hhid)) |&gt;\n  left_join( imputed_rent, join_by( interview__key == interview__key)) |&gt;\n  select(decile, hh_02, hh_03, net_present_value_rent, net_present_value_rent2, NAM_1, weight) |&gt; \n  group_by(NAM_1) |&gt; \n  summarize(avg_net_present_value1 = weighted.mean(net_present_value_rent, as.integer(weight), na.rm = TRUE)*er,\n            avg_net_present_value2 = weighted.mean(net_present_value_rent2, as.integer(weight), na.rm = TRUE)*er,\n            difference = \n              round(avg_net_present_value1 - avg_net_present_value2)) |&gt;\n  gt() |&gt; \n  fmt_number(\n    columns = everything(),\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    NAM_1 = \"Marz\",\n    avg_net_present_value1 = \"Average net present value in USD (calculated monthly)\",\n    avg_net_present_value2 = \"Average net present value in USD (calculated annual)\",\n    difference = \"Difference\"\n  )\n\n\n\n\n\n\n\nMarz\nAverage net present value in USD (calculated monthly)\nAverage net present value in USD (calculated annual)\nDifference\n\n\n\n\nAragatsotn\n25,737.3\n25,625.6\n112.0\n\n\nArarat\n27,523.3\n27,403.9\n119.0\n\n\nArmavir\n27,418.9\n27,300.0\n119.0\n\n\nGegharkunik\n20,088.9\n20,001.8\n87.0\n\n\nKotayk\n29,623.7\n29,495.1\n129.0\n\n\nLori\n15,273.7\n15,207.5\n66.0\n\n\nShirak\n19,432.8\n19,348.5\n84.0\n\n\nSyunik\n26,307.7\n26,193.5\n114.0\n\n\nTavush\n15,760.6\n15,692.2\n68.0\n\n\nVayots Dzor\n19,633.0\n19,547.9\n85.0\n\n\nYerevan\n63,775.7\n63,499.0\n277.0\n\n\n\n\n\n\n\nUsing our Shapefile, we can explore how the average net present value of imputed rent distributes geographically (labels in million dram).\n\nnpv &lt;- hh |&gt; \n  left_join( imputed_rent, join_by( interview__key == interview__key)) |&gt;\n  select(hh_02, hh_03, net_present_value_rent, \n         net_present_value_rent2, NAM_1, weight) |&gt; \n  group_by(NAM_1) |&gt; \n  summarize(\n    avg_npv = weighted.mean(\n      net_present_value_rent, as.integer(weight), na.rm = TRUE\n      ),\n    avg_npv_labels =\n      formatC(\n        weighted.mean(net_present_value_rent, \n                      as.integer(weight), na.rm = TRUE)*er, \n        big.mark = \",\", format = \"f\", digits = 1)\n      )\n\nnpv_map &lt;- adm1 |&gt; \n  left_join(npv, join_by(NAM_1 == NAM_1))\n\nnpv_map &lt;-tm_shape(npv_map)+\n  tm_polygons(\"avg_npv\", legend.show = FALSE) +\n  tm_text(\"avg_npv_labels\", size = .7, col = \"black\")+\n  tm_layout(legend.position = c(\"right\", \"top\"), \n            title= \"Average Imputed Rent NPV (USD)\", \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\nnpv_map\n\n\n\n\n\n\n\nFigure 1: Average Net Present Value of Imputed Rent by Marz (Year 2022, USD)\n\n\n\n\n\nIn the next section we will perform the same calculations to treat agricultural income as a future discounted asset so that we can implement shocks, according to vulnerability data.\n\n\n4.3 Net Present Value of Agricultural Income\nFor the Armenian case, we have access to an already processed data set with income aggregations from hired employment, self-employment, income on property, public pensions, transfers, other income, and, especially important for this section, agricultural income. Let’s calculate the net present value for that income in the same way we did our imputed rent. We will focus on the annual version of our calculations. There is one caveat, which is related to the fact that agricultural income shows seasonal variations. So multiplying the monthly income by 12 is likely to overestimate the net present value so we use a scaling factor which should reflect that seasonality. We will use the same rates as before so we will not create new ones.\n\nag_scaling &lt;- 0.65\nag_income &lt;- ic |&gt; \n  mutate(lvstk_onlyinc = if_else(lvstk_onlyinc&lt;0, 0, lvstk_onlyinc)) |&gt; \n  mutate(annual_ag_income = ((inc4) * 12 * ag_scaling))\n\nAnd we perform the same Net Present Value calculations as before (see Equation 1).\n\n# Annual periods\nag_income$present_value_ag_income &lt;- sapply(1:(years), function(n) {\n  future_ag_income &lt;- ag_income$annual_ag_income * (1 + inflation_rate)^(n)\n  present_ag_value &lt;- future_ag_income / ((1 + discount_rate)^n)\n  return(present_ag_value)\n})\n\n\n# Sum up the present values for the total present value over the period\nag_income$net_present_ag_value &lt;- rowSums(ag_income$present_value_ag_income)\n\n\n# Delete partial calculations\nag_income &lt;-ag_income |&gt; \n  select(interview__key, present_value_ag_income, annual_ag_income, net_present_ag_value)\n\nWe will create a map object to show a side-by-side comparison of both NPVs.\n\nnpv_ag &lt;- hh |&gt; \n  left_join( ag_income, join_by( interview__key == interview__key)) |&gt; \n  select(hh_02, hh_03, annual_ag_income, net_present_ag_value, NAM_1, weight) |&gt;\n  group_by(NAM_1) |&gt; \n  summarize( \n    avg_ag_npv = weighted.mean( \n      net_present_ag_value, as.integer(weight), na.rm = TRUE ),\n    avg_ag_npv_labels =  \n        formatC( \n          weighted.mean(\n            net_present_ag_value *er, \n            as.integer(weight), na.rm = TRUE), \n          big.mark = \",\", \n          format = \"f\", digits = 1) )\n\nnpv_ag_map &lt;- adm1 |&gt; \n  left_join(npv_ag, join_by(NAM_1 == NAM_1))\n\nnpv_ag_map &lt;- tm_shape(npv_ag_map)+ \n  tm_polygons(\"avg_ag_npv\", legend.show = FALSE) + \n  tm_text(\"avg_ag_npv_labels\", size = .7, col = \"black\")+\n  tm_layout(legend.position = c(\"right\", \"top\"), \n            title= \"Average Ag. Income NPV (USD)\", \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\nAnd now we can compare the spatial distributions of both Net Present Values from the map objects npv_map and npv_ag_map that we created before.\n\ntmap_arrange(npv_map, npv_ag_map)\n\n\n\n\n\n\n\nFigure 2: Average Net Present Value of Imputed Rent and Agricultural Income (Year 2022, million AMD)\n\n\n\n\n\nWith both Net Present Values calculated, in the following section we will apply our vulnerability shocks to a selection of Armenian households.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis Calculations"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability-hh-level-impacts.html#vulnerability-shocks",
    "href": "supporting-materials/vulnerability-hh-level-impacts.html#vulnerability-shocks",
    "title": "Vulnerability Analysis Calculations",
    "section": "5 Vulnerability shocks",
    "text": "5 Vulnerability shocks\nThis section was replaced by new selection method. See Section 6 below.\n\n5.1 Buildings\nWe previously estimated the imputed rent values for households that own their homes, assuming that they derive welfare from owning those assets. We then treated that discounted future income flow as an asset value. Our data suggests that some of those buildings are damaged due to increased rain and flood events. In each administrative region a percentage of buildings receive these shocks, effectively taxing their monthly imputed value by a percentage. Let’s find a way to randomly select from our data set a number of weighted households that matches the shocks. Let’s move step by step.\nWe first merge the household data set with the imputed_rent data set to have the descriptive variables per household.\n\n# Create a placeholder for our chosen HH's\nrent_dataset &lt;- hh |&gt; \n  select(hous_45__7, interview__key, NAM_1, weight, hh_02)  |&gt;  \n  mutate(selected_for_tax = FALSE, # initialize with FALSE\n         is_dilapidated = if_else(hous_45__7 == 1, TRUE, FALSE)\n         ) |&gt; \n  mutate(is_dilapidated = if_else(is.na(hous_45__7), FALSE, is_dilapidated)) |&gt; \n  left_join(imputed_rent, join_by(interview__key == interview__key )) |&gt; \n  rename(household_id = interview__key)\n\nexposure_dataset &lt;- buildings_aal\n\nWe merge with the exposure data set and prepare the necessary columns.\n\nrent_dataset &lt;- rent_dataset |&gt;\n  left_join(exposure_dataset, by = \"NAM_1\") |&gt;\n  mutate(is_dilapidated = if_else(is.na(hous_45__7) | hous_45__7 == 0, FALSE, TRUE))\n\nThe next step involves calculating the target weight for each marz (NAM_1) and randomly selecting households based on their weight until the cumulative sum matches the target.\n\nset.seed(123)  # Ensure reproducibility\n\nrent_dataset &lt;- rent_dataset |&gt;\n  group_by(NAM_1) |&gt;\n  mutate(total_weight = sum(weight, na.rm = TRUE),\n         target_weight = total_weight * pct_AA_exposed_buildings / 100) |&gt;\n  ungroup() |&gt;\n  arrange(NAM_1, runif(n())) |&gt;\n  group_by(NAM_1) |&gt;\n  mutate(cum_weight = cumsum(weight),\n         selected_for_tax = cum_weight &lt;= target_weight) |&gt;\n  ungroup()\n\nWe can explore how many observations were targeted and their weighted values.\n\nrent_dataset |&gt; \n  filter(selected_for_tax == TRUE) |&gt; \n  group_by(hh_02,NAM_1)  |&gt; \n  summarise(Selected_Cases = sum(selected_for_tax, na.rm = TRUE),\n            Weighted_no_HHs = as.integer(sum(weight, na.rm = TRUE))) |&gt; \n  arrange(hh_02) |&gt; \n  adorn_totals(\"row\") |&gt; \n  ungroup() |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = everything(),\n    decimals = 0\n  ) |&gt; \n  cols_label(\n    hh_02 = \"\",\n    NAM_1 = \"Marz\",\n    Selected_Cases = \"No. of targeted observations\",\n    Weighted_no_HHs = \"No. of targeted weighted households\"\n  )\n\n\n\n\n\n\n\n\nMarz\nNo. of targeted observations\nNo. of targeted weighted households\n\n\n\n\n1\nYerevan\n31\n5,973\n\n\n2\nAragatsotn\n10\n1,135\n\n\n3\nArarat\n19\n3,434\n\n\n4\nArmavir\n14\n1,866\n\n\n5\nGegharkunik\n13\n2,217\n\n\n6\nLori\n15\n2,286\n\n\n7\nKotayk\n9\n2,155\n\n\n8\nShirak\n13\n2,060\n\n\n9\nSyunik\n13\n1,526\n\n\n10\nVayots Dzor\n14\n623\n\n\n11\nTavush\n6\n752\n\n\nTotal\n-\n157\n24,027\n\n\n\n\n\n\n\nNow, we apply the “vulnerability tax” to the imputed_rent according to the building’s state of dilapidation and the specific tax rates for normal and dilapidated conditions.\n\nrent_dataset &lt;- rent_dataset |&gt;\n  mutate(adjusted_rent = case_when(\n    selected_for_tax & is_dilapidated ~ imputed_rent * (1 - perc_AAL_dilapidated / 100),\n    selected_for_tax & !is_dilapidated ~ imputed_rent * (1 - perc_AAL_normal / 100),\n    TRUE ~ imputed_rent\n  ))\n\nWe then compare our values in a table. In this case, we see that, although the percentages of impacted households are small per marz, the mean imputed rent decrease, which is a value that is expected to compound over time.\nAnd we can now estimate a new net present value with the adjusted values in the same manner as before.\n\n# Annual adjusted imputed rent\nrent_dataset$annual_adjusted_rent &lt;- rent_dataset$adjusted_rent * 12 \n\n\nrent_dataset$adjusted_present_value_rent &lt;- sapply(1:(years), function(n) {\n  future_adjusted_rent &lt;- rent_dataset$annual_adjusted_rent * (1 + inflation_rate)^(n)\n  present_adjusted_value &lt;- future_adjusted_rent / ((1 + discount_rate)^n)\n  return(present_adjusted_value)\n})\n\n\n# Sum up the present values for the total present value over the period\nrent_dataset$adjusted_net_present_value_rent &lt;-\n  rowSums(rent_dataset$adjusted_present_value_rent)\n\nAnd we can view the compounded differences in NPVs for those affected by Marz and Poverty condition. Note that the weighted sum of households (24,069-24,075) in the tables differs slightly, because of rounding during the sliced calculations to avoid showing fractions of individual homes.\n\nbuilding_losses &lt;- rent_dataset |&gt; \n  left_join(deciles, join_by(household_id == hhid)) |&gt; \n  rename(poor = poor_Avpovln2022) |&gt; \n  filter(selected_for_tax == TRUE) |&gt; \n  group_by(hh_02,NAM_1) |&gt; \n  summarize(\n    Average_NPV = weighted.mean(net_present_value_rent, weight, na.rm = TRUE)*er,\n    Average_Adjusted_NPV = weighted.mean(\n      adjusted_net_present_value_rent, weight, na.rm = TRUE) * er,\n    Difference =  Average_NPV - Average_Adjusted_NPV,\n    No_HH = round(sum(weight, na.rm = TRUE))\n  ) |&gt;\n   ungroup()\n\nbuilding_losses |&gt; \n    gt() |&gt; \n  fmt_number(\n    columns = c(Average_NPV,Average_Adjusted_NPV, Difference) ,\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    hh_02 = \"\",\n    NAM_1 = \"Marz\",\n    Average_NPV = \"Average NPV of imputed rent (USD)\",\n    Average_Adjusted_NPV = \"Adjusted average NPV of imputed rent (USD)\",\n    Difference = \"Loss (USD)\",\n    No_HH = \"No. HH\"\n  )\n\n\n\n\n\n\n\n\nMarz\nAverage NPV of imputed rent (USD)\nAdjusted average NPV of imputed rent (USD)\nLoss (USD)\nNo. HH\n\n\n\n\n1\nYerevan\n69,393.2\n63,836.2\n5,556.9\n5974\n\n\n2\nAragatsotn\n25,113.2\n23,068.3\n2,044.9\n1135\n\n\n3\nArarat\n21,198.6\n19,480.6\n1,718.0\n3434\n\n\n4\nArmavir\n32,639.3\n29,604.2\n3,035.1\n1867\n\n\n5\nGegharkunik\n21,037.9\n19,259.3\n1,778.6\n2218\n\n\n6\nLori\n15,147.7\n11,898.6\n3,249.1\n2287\n\n\n7\nKotayk\n23,241.7\n20,949.7\n2,292.1\n2156\n\n\n8\nShirak\n22,164.2\n20,083.8\n2,080.4\n2060\n\n\n9\nSyunik\n26,799.7\n21,865.6\n4,934.1\n1526\n\n\n10\nVayots Dzor\n20,955.0\n17,532.2\n3,422.9\n624\n\n\n11\nTavush\n21,176.9\n16,922.1\n4,254.9\n752\n\n\n\n\n\n\n\n\nrent_dataset |&gt; \n  left_join(deciles, join_by(household_id == hhid)) |&gt; \n  #rename(poor = poor_Avpovln2022) |&gt; \n  filter(selected_for_tax == TRUE) |&gt; \n  mutate(poor = if_else(poor_Avpovln2022==1, \n                        \"Below poverty line\", \n                        \"Above poverty line\")) |&gt; \n  group_by( poor) |&gt; \n  summarize(\n    Average_NPV = weighted.mean(net_present_value_rent, weight, na.rm = TRUE) * er,\n    Average_Adjusted_NPV = weighted.mean(\n      adjusted_net_present_value_rent, weight, na.rm = TRUE) * er,\n    Difference =  Average_NPV - Average_Adjusted_NPV,\n    No_HH = round(sum(weight, na.rm = TRUE))\n  ) |&gt;\n   ungroup() |&gt; \n    gt() |&gt; \n  fmt_number(\n    columns = c(Average_NPV,Average_Adjusted_NPV, Difference) ,\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    poor = \"Poverty\",\n    Average_NPV = \"Average NPV of imputed rent (USD)\",\n    Average_Adjusted_NPV = \"Adjusted average NPV of imputed rent (USD)\",\n    Difference = \"Loss (USD)\",\n    No_HH = \"No. HH\"\n  )\n\n\n\n\n\n\n\nPoverty\nAverage NPV of imputed rent (USD)\nAdjusted average NPV of imputed rent (USD)\nLoss (USD)\nNo. HH\n\n\n\n\nAbove poverty line\n30,949.6\n27,781.6\n3,167.9\n19095\n\n\nBelow poverty line\n41,032.3\n37,253.2\n3,779.1\n4939\n\n\n\n\n\n\n\n\n\n5.2 Agriculture\nIn the case of agriculture, we have percentage losses in agricultural productivity per year and per climate scenario from our crops_productivity data set.\n\ncrops_productivity |&gt; \n     select(-GID_1) |&gt;\n  group_by(climate_scenario) |&gt; \n  summarize(\"Mean percent change all years\" = mean(pct_change_prod)) |&gt; \n  gt()\n\n\n\n\n\n\n\nclimate_scenario\nMean percent change all years\n\n\n\n\nDry/Hot mean\n-0.19475663\n\n\nSSP1-1.9 mean\n-0.04033261\n\n\nSSP2-4.5 CAMS-CSM1-0\n-0.06785020\n\n\nSSP2-4.5 CMCC-CM2-SR5\n-0.03269785\n\n\nSSP2-4.5 CNRM-CM6-1\n-0.08440299\n\n\nSSP3-7.0 BCC-CSM2-MR\n-0.15777422\n\n\nSSP3-7.0 KACE-1-0-g\n-0.20606020\n\n\nSSP3-7.0 UKESM1-0-LL\n-0.21341230\n\n\nSSP3-7.0 mean\n-0.08120867\n\n\nWet/Warm mean\n-0.06320857\n\n\n\n\n\n\n\nSo we will apply this to our agricultural net present value calculations per year. Remember that when we calculated the present values of each year we were left with a matrix identifying each year’s value per household id. So we are going to pivot the data set into long format, so that we can match the appropriate loss in productivity according to year and marz. To test out our methodology we will keep one scenario only in our ag_exposure data set. Also, we will change the percent change to decimal so that we are not over-estimating productivity losses. We also leave out 2021-2022 because our NPV calculations started from 2023 to 2050.\n\nag_exposure &lt;- crops_productivity |&gt; \n  filter(climate_scenario==\"Dry/Hot mean\" & year &gt; 2022 ) |&gt; \n     select(-GID_1, -climate_scenario) #|&gt; \n  #mutate(pct_change_prod = pct_change_prod / 100)\n\nOur ag_income data set from before has the present values of each individual household in columns that represent each year. We can rename those columns with our year variables so that we can match them with our exposure data set.\n\n# Define the years range\nyear_names &lt;- as.character(2023:2050)\n\n# Rename the columns of the matrix\ncolnames(ag_income$present_value_ag_income) &lt;- year_names\n\nWe extract our present value calculations from the matrix column and convert it into a data set on its own, which we can manipulate into long format to merge with our exposure data set.\n\n# Convert the matrix to a data.frame.\nag_income_long &lt;- as.data.frame(ag_income$present_value_ag_income)  |&gt;\n  mutate(household_id = ag_income$interview__key) |&gt;\n  pivot_longer(cols = -household_id, names_to = \"year\", \n               values_to = \"present_value_ag_income\") |&gt; \n  left_join(hh, join_by(household_id == interview__key)) |&gt; \n  select(household_id, present_value_ag_income, year, hh_02, NAM_1)\n\nag_income_long$year &lt;- as.integer(ag_income_long$year)\n\n# inspect the final result\nhead(ag_income_long[!is.na(\n  ag_income_long$present_value_ag_income),])\n\n# A tibble: 6 × 5\n  household_id present_value_ag_income  year hh_02            NAM_1      \n  &lt;chr&gt;                          &lt;dbl&gt; &lt;int&gt; &lt;dbl+lbl&gt;        &lt;chr&gt;      \n1 00-03-45-50                  193160.  2023 10 [VAYOTS DZOR] Vayots Dzor\n2 00-03-45-50                  191338.  2024 10 [VAYOTS DZOR] Vayots Dzor\n3 00-03-45-50                  189533.  2025 10 [VAYOTS DZOR] Vayots Dzor\n4 00-03-45-50                  187745.  2026 10 [VAYOTS DZOR] Vayots Dzor\n5 00-03-45-50                  185974.  2027 10 [VAYOTS DZOR] Vayots Dzor\n6 00-03-45-50                  184219.  2028 10 [VAYOTS DZOR] Vayots Dzor\n\n\nSo now we can match our exposure values according to year and marz and modify our annual present values.\n\nag_income_long &lt;- ag_income_long |&gt; \n  left_join(ag_exposure, join_by(NAM_1, year)) |&gt; \n  mutate(adjusted_present_value_ag = present_value_ag_income * (1 + pct_change_prod))\n\nAnd we can collapse our dataset again to sum over the years for each household and join it back with our ag_income dataset.\n\nag_income_long &lt;- ag_income_long |&gt; \n  select(household_id, adjusted_present_value_ag) |&gt; \n  group_by(household_id) |&gt; \n  summarize( net_present_ag_value_adjusted =\n               sum(adjusted_present_value_ag, na.rm = TRUE))\n\nag_income &lt;- ag_income |&gt;\n  left_join(ag_income_long, join_by(interview__key == household_id)) |&gt; \n  select(interview__key, annual_ag_income, net_present_ag_value, net_present_ag_value_adjusted)\n\nLet’s compare the two mean values.\n\nag_losses &lt;- hh |&gt; \n  left_join(deciles, join_by(interview__key == hhid)) |&gt; \n  left_join(ag_income, join_by(interview__key==interview__key)) |&gt;\n  filter(!is.na(net_present_ag_value)) |&gt; \n  rename(poor = poor_Avpovln2022) |&gt; \n  group_by(hh_02,NAM_1) |&gt; \n  summarize(\n    Average_NPV = weighted.mean(net_present_ag_value, weight, na.rm = TRUE)*er,\n    Average_Adjusted_NPV = weighted.mean(\n      net_present_ag_value_adjusted, weight, na.rm = TRUE) * er,\n    Difference =  Average_NPV - Average_Adjusted_NPV,\n    No_HH = round(sum(weight, na.rm = TRUE))\n  ) |&gt; \n  ungroup()\n\nag_losses |&gt; \n    gt() |&gt; \n  fmt_number(\n    columns = c(Average_NPV,Average_Adjusted_NPV, Difference) ,\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    hh_02 = \"\",\n    NAM_1 = \"Marz\",\n    Average_NPV = \"Avg. NPV of ag income (USD)\",\n    Average_Adjusted_NPV = \"Adjusted avg. NPV of ag income (USD)\",\n    Difference = \"Loss (USD)\",\n    No_HH = \"No. HH\"\n  )\n\n\n\n\n\n\n\n\nMarz\nAvg. NPV of ag income (USD)\nAdjusted avg. NPV of ag income (USD)\nLoss (USD)\nNo. HH\n\n\n\n\n1\nYerevan\n3,639.9\n2,949.5\n690.4\n1005\n\n\n2\nAragatsotn\n37,721.3\n30,321.9\n7,399.4\n20865\n\n\n3\nArarat\n29,091.2\n22,750.0\n6,341.2\n22185\n\n\n4\nArmavir\n46,713.9\n37,001.0\n9,713.0\n24788\n\n\n5\nGegharkunik\n14,437.6\n11,755.4\n2,682.2\n28854\n\n\n6\nLori\n15,100.1\n12,399.5\n2,700.6\n21479\n\n\n7\nKotayk\n28,639.2\n23,425.6\n5,213.6\n17288\n\n\n8\nShirak\n55,604.9\n45,065.4\n10,539.5\n21000\n\n\n9\nSyunik\n38,137.7\n32,267.9\n5,869.8\n10796\n\n\n10\nVayots Dzor\n25,405.5\n19,010.7\n6,394.8\n5228\n\n\n11\nTavush\n18,736.1\n15,316.2\n3,419.9\n14471\n\n\n\n\n\n\n\nAnd like in our previous example, we can see how the change affects the poor. It appears that in this case those above the poverty line have the greatest average impact.\n\nhh |&gt; \n  left_join(deciles, join_by(interview__key == hhid)) |&gt; \n  left_join(ag_income, join_by(interview__key==interview__key)) |&gt;\n  filter(!is.na(net_present_ag_value)) |&gt; \n  mutate(poor = if_else(poor_Avpovln2022==1, \n                        \"Below poverty line\", \n                        \"Above poverty line\")) |&gt; \n  group_by(poor) |&gt; \n  summarize(\n    Average_NPV = weighted.mean(net_present_ag_value, weight, na.rm = TRUE)*er,\n    Average_Adjusted_NPV = weighted.mean(\n      net_present_ag_value_adjusted, weight, na.rm = TRUE) * er,\n    Difference =  Average_NPV - Average_Adjusted_NPV,\n    No_HH = round(sum(weight, na.rm = TRUE))\n  ) |&gt; \n    gt() |&gt; \n  fmt_number(\n    columns = c(Average_NPV,Average_Adjusted_NPV, Difference) ,\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    poor = \"Poverty\",\n    Average_NPV = \"Average NPV of ag income (USD)\",\n    Average_Adjusted_NPV = \"Adjusted average NPV of ag income (USD)\",\n    Difference = \"Loss (USD)\",\n    No_HH = \"No. HH\"\n  )\n\n\n\n\n\n\n\nPoverty\nAverage NPV of ag income (USD)\nAdjusted average NPV of ag income (USD)\nLoss (USD)\nNo. HH\n\n\n\n\nAbove poverty line\n33,024.6\n26,621.6\n6,403.0\n147868\n\n\nBelow poverty line\n23,201.8\n18,640.1\n4,561.8\n40090\n\n\n\n\n\n\n\nWe can also explore how both losses are geographically distributed.\n\n# For Buildings\nbuilding_losses &lt;- adm1 |&gt; \n  left_join(building_losses, join_by(NAM_1 == NAM_1)) |&gt; \n  mutate(map_labels = formatC(building_losses$Difference, \n                                           big.mark = \",\", \n                                           format = \"f\", \n                                           digits = 1))\n  \n\nbuilding_losses_map &lt;- tm_shape(building_losses)+\n  tm_polygons(col = \"Difference\", legend.show = FALSE,\n              palette = c(\"YlGn\"))+\n  tm_text(\"map_labels\", size = .7, col = \"black\")+\n  tm_layout(legend.position = c(\"right\", \"top\"), \n            title= \"Average Imputed Rent NPV Losses (USD)\", \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\n\n# ag_losses &lt;- adm1 |&gt; \n#   left_join(ag_losses, join_by(NAM_1 == NAM_1)) |&gt; \n#   mutate(Difference = if_else(is.na(Difference), \n#                                0, Difference)) |&gt; \n#   mutate(map_labels = formatC(ag_losses$Difference, \n#                                            big.mark = \",\", \n#                                            format = \"f\", \n#                                            digits = 1))\n#   \n# \n# ag_losses_map &lt;- tm_shape(ag_losses)+\n#   tm_polygons(col = \"Difference\", legend.show = FALSE,\n#               palette = c(\"YlGn\"))+\n#   tm_text(\"map_labels\", size = .7, col = \"black\")+\n#   tm_layout(legend.position = c(\"right\", \"top\"), \n#             title= \"Average Ag. Income NPV Losses (USD)\", \n#             title.position = c('left', 'bottom'),\n#             title.size = 1)\n# ```\n# \n# And now we can compare the spatial distributions of both Net Present Values from the map objects `npv_map` and `npv_ag_map` that we created before.\n# \n# ```{r warning=FALSE, message=FALSE}\n# #| label: fig-map-npv-losses \n# #| fig-align: \"left\" \n# #| fig-cap: \"Average Losses of NPV of Imputed Rent and Agricultural Income (Year 2022, USD)\" \n# \n# tmap_arrange(building_losses_map, ag_losses_map)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis Calculations"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability-hh-level-impacts.html#sec-vulshocks",
    "href": "supporting-materials/vulnerability-hh-level-impacts.html#sec-vulshocks",
    "title": "Vulnerability Analysis Calculations",
    "section": "6 Vulnerability Shocks",
    "text": "6 Vulnerability Shocks\n\n6.1 Buildings method two (selection via weights)\nIt was pointed out that the method above, makes a random selection, but if we were to make another selection we might get two completely different results. That means that we are not truly making the selection in an aleatory manner. However, we could argue that a climate event doesn’t either. Here we try a different approach in which we create two calculations from the same household each. One in which the weights are adjusted to match the exposure percentage and one where the weights are adjusted to match the remainder and adjust the value for each type. We continue using the same exposure_dataset we created before.\n\nrent_by_weights &lt;- hh |&gt;\n  select(hous_45__7, interview__key, NAM_1, weight, hh_02) |&gt; \n   mutate(\n         is_dilapidated = if_else(hous_45__7 == 1, TRUE, FALSE)\n         ) |&gt; \n  mutate(is_dilapidated = if_else(is.na(hous_45__7), FALSE, is_dilapidated)) |&gt; \n  left_join(imputed_rent, join_by(interview__key == interview__key )) |&gt; \n  rename(household_id = interview__key) |&gt;\n  left_join(exposure_dataset, by = \"NAM_1\") |&gt;\n  mutate(is_dilapidated = if_else(is.na(hous_45__7) | hous_45__7 == 0, FALSE, TRUE))\n\nWe now create two new weights columns weight_exposed and weight_unexposed.\n\nrent_by_weights &lt;- rent_by_weights |&gt; \n  mutate(weight_exposed = weight * (pct_AA_exposed_buildings/100),\n         weight_unexposed = weight * (1- pct_AA_exposed_buildings/100))\n\nAfter that, we apply the shock to ag income, depending on state of dilapidation.\n\nrent_by_weights &lt;- rent_by_weights |&gt; \n  mutate(adjusted_rent_by_weight = case_when(\n    is_dilapidated ~ imputed_rent * (1 - perc_AAL_dilapidated / 100),\n    !is_dilapidated ~ imputed_rent * (1 - perc_AAL_normal / 100),\n    TRUE ~ imputed_rent\n  ))\n\nAnd we can now estimate a new net present value with the adjusted values in the same manner as before.\n\n# Annual adjusted imputed rent\nrent_by_weights$annual_adjusted_rent_by_weight &lt;-\n  rent_by_weights$adjusted_rent_by_weight * 12 \n\nrent_by_weights$present_value_rent_by_weight &lt;- sapply(1:(years), function(n) {\n  future_adjusted_rent &lt;- rent_by_weights$annual_adjusted_rent_by_weight * (1 + inflation_rate)^(n)\n  present_value_by_weight &lt;- future_adjusted_rent / ((1 + discount_rate)^n)\n  return(present_value_by_weight)\n})\n\n\n# Sum up the present values for the total present value over the period\nrent_by_weights$npv_rent_by_weight &lt;-\n  rowSums(rent_by_weights$present_value_rent_by_weight)\n\nrent_by_weights &lt;- rent_by_weights |&gt; \n  select(-present_value_rent_by_weight)\n\nAnd we can view the compounded differences in NPVs for those affected by Marz and Poverty condition. Note that the weighted sum of households (24,069-24,075) in the tables differs slightly, because of rounding during the sliced calculations to avoid showing fractions of individual homes.\n\nbuilding_losses &lt;- rent_by_weights |&gt; \n  left_join(deciles, join_by(household_id == hhid)) |&gt; \n  rename(poor = poor_Avpovln2022) |&gt;\n  filter(!is.na(imputed_rent)) |&gt; \n  group_by(hh_02,NAM_1) |&gt; \n  summarize(\n    Average_NPV = weighted.mean(net_present_value_rent, weight_exposed, na.rm = TRUE)*er,\n    Average_Adjusted_NPV = weighted.mean(\n      npv_rent_by_weight, weight_exposed, na.rm = TRUE) * er,\n    Difference =  Average_NPV - Average_Adjusted_NPV,\n    No_HH = round(sum(weight_exposed, na.rm = TRUE))\n  ) |&gt;\n   ungroup()\n\nbuilding_losses |&gt; \n    gt() |&gt; \n  fmt_number(\n    columns = c(Average_NPV,Average_Adjusted_NPV, Difference) ,\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    hh_02 = \"\",\n    NAM_1 = \"Marz\",\n    Average_NPV = \"Average NPV of imputed rent (USD)\",\n    Average_Adjusted_NPV = \"Adjusted average NPV of imputed rent (USD)\",\n    Difference = \"Loss (USD)\",\n    No_HH = \"No. HH\"\n  )\n\n\n\n\n\n\n\n\nMarz\nAverage NPV of imputed rent (USD)\nAdjusted average NPV of imputed rent (USD)\nLoss (USD)\nNo. HH\n\n\n\n\n1\nYerevan\n63,777.4\n58,688.1\n5,089.3\n5004\n\n\n2\nAragatsotn\n25,757.8\n23,636.3\n2,121.5\n1045\n\n\n3\nArarat\n27,523.6\n25,244.3\n2,279.3\n3132\n\n\n4\nArmavir\n27,452.5\n24,979.8\n2,472.8\n1675\n\n\n5\nGegharkunik\n20,080.5\n18,361.4\n1,719.1\n2028\n\n\n6\nLori\n15,268.3\n12,060.6\n3,207.7\n2038\n\n\n7\nKotayk\n29,627.0\n26,766.2\n2,860.8\n2111\n\n\n8\nShirak\n19,430.0\n17,569.2\n1,860.8\n1823\n\n\n9\nSyunik\n26,310.9\n21,452.3\n4,858.6\n1445\n\n\n10\nVayots Dzor\n19,603.1\n16,405.2\n3,197.9\n586\n\n\n11\nTavush\n15,743.5\n12,397.4\n3,346.1\n689\n\n\n\n\n\n\n\n\nrent_by_weights |&gt; \n  left_join(deciles, join_by(household_id == hhid)) |&gt; \n  #rename(poor = poor_Avpovln2022) |&gt; \n  filter(!is.na(imputed_rent)) |&gt; \n  mutate(poor = if_else(poor_Avpovln2022==1, \n                        \"Below poverty line\", \n                        \"Above poverty line\")) |&gt; \n  group_by( poor) |&gt; \n  summarize(\n    Average_NPV = weighted.mean(net_present_value_rent, weight_exposed, na.rm = TRUE) * er,\n    Average_Adjusted_NPV = weighted.mean(\n      npv_rent_by_weight, weight_exposed, na.rm = TRUE) * er,\n    Difference =  Average_NPV - Average_Adjusted_NPV,\n    No_HH = round(sum(weight_exposed, na.rm = TRUE))\n  ) |&gt;\n   ungroup() |&gt; \n    gt() |&gt; \n  fmt_number(\n    columns = c(Average_NPV,Average_Adjusted_NPV, Difference) ,\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    poor = \"Poverty\",\n    Average_NPV = \"Average NPV of imputed rent (USD)\",\n    Average_Adjusted_NPV = \"Adjusted average NPV of imputed rent (USD)\",\n    Difference = \"Loss (USD)\",\n    No_HH = \"No. HH\"\n  )\n\n\n\n\n\n\n\nPoverty\nAverage NPV of imputed rent (USD)\nAdjusted average NPV of imputed rent (USD)\nLoss (USD)\nNo. HH\n\n\n\n\nAbove poverty line\n33,373.3\n30,087.4\n3,285.9\n17685\n\n\nBelow poverty line\n30,373.0\n27,415.4\n2,957.7\n3892\n\n\n\n\n\n\n\nAlthough the values are similar for the first method, there are clear differences, the main one being that poor households do not lose more than non-poor households.\n\n\n6.2 Agriculture method two (selection via weights)\nWe now turn our attention to agricultural impacts, using the second method. This time, we also have new flood exposure data for a subset of households, based on a percentage given in the crops_aal dataset (AAL stands for Annual Average Losses), which differs from crops_productivity, in that we only get one productivity loss value for any year. To annualize the monthly ag income variable, we apply a scaling factor of 65%, because with agriculture there is a seasonal component and not all months are equal.\n\nag_income_by_weights &lt;- ag_income |&gt; \n  left_join(ic, join_by(interview__key)) |&gt; \n  select( interview__key, hh_02,NAM_1,totalinc, lvstk_onlyinc, inc4, annual_ag_income, net_present_ag_value ,weight)\n\nAnd now we create two columns for weights, but we focus only on households with agricultural income.\n\nag_income_by_weights &lt;- ag_income_by_weights |&gt; \n  filter(!is.na(annual_ag_income)) |&gt;  # Filter by HHs w. ag inc\n  mutate(lvstk_onlyinc = \n           if_else(is.na(lvstk_onlyinc), 0, lvstk_onlyinc)) |&gt; \n  left_join(crops_aal, join_by(NAM_1)) |&gt; \n  mutate(weight_exposed = weight * (pct_AAE/100),\n         weight_unexposed = weight * (1- pct_AAE/100))\n\nIn this case, we apply the shock to every household with agricultural income. Note that the variable inc4 includes sales of agricultural products and livestock (including imputed value of ag products for own consumption) and so we deduct the livestock component (lvstk_onlyinc) before applying the shock.\n\nag_income_by_weights &lt;- ag_income_by_weights |&gt;\n  # mutate(annual_ag_income = ((inc4 - lvstk_onlyinc) * 12 * ag_scaling))\n  mutate(ag_no_lvstk = (inc4 - lvstk_onlyinc)) |&gt;\n  mutate(adjusted_inc4 = \n           ag_no_lvstk * (1- pct_AAL/100) +\n           lvstk_onlyinc) |&gt; \n  mutate(adjusted_ag_income_by_weights =\n           ag_no_lvstk * (1- pct_AAL/100) ) |&gt; \n  mutate(adjusted_ag_income_by_weights = \n           adjusted_ag_income_by_weights + lvstk_onlyinc) |&gt; \n  mutate(adjusted_ag_income_by_weights =\n           adjusted_ag_income_by_weights * 12 * ag_scaling)\n\nAnd then we recalculate NPV for those households affected.\n\nag_income_by_weights$ag_present_value_by_weight &lt;- \n  sapply(1:(years), function(n) {\n  future_adjusted_rent &lt;- \n    ag_income_by_weights$adjusted_ag_income_by_weights * \n    (1 + inflation_rate)^(n)\n  ag_present_value_by_weight &lt;- \n    future_adjusted_rent / ((1 + discount_rate)^n)\n  return(ag_present_value_by_weight)\n})\n\nWe calculate Net Present Value once more.\n\n# Sum up the present values for the total present value over the period\nag_income_by_weights$npv_ag_income_by_weight &lt;-\n  rowSums(ag_income_by_weights$ag_present_value_by_weight) \n\nag_income_by_weights &lt;- ag_income_by_weights |&gt; \n  select(-ag_present_value_by_weight)\n\nAnd compare the losses for those impacted.\n\nag_losses2 &lt;- ag_income_by_weights |&gt; \n  left_join(deciles, join_by(interview__key == hhid)) |&gt; \n  rename(poor = poor_Avpovln2022) |&gt;\n  filter(!is.na(annual_ag_income)) |&gt; \n  group_by(hh_02,NAM_1) |&gt; \n  summarize(\n    Average_NPV = weighted.mean(net_present_ag_value, weight_exposed, na.rm = TRUE)*er,\n    Average_Adjusted_NPV = weighted.mean(\n      npv_ag_income_by_weight, weight_exposed, na.rm = TRUE) * er,\n    Difference =  Average_NPV - Average_Adjusted_NPV,\n    No_HH = round(sum(weight_exposed, na.rm = TRUE))\n  ) |&gt;\n   ungroup()\n\nag_losses2 |&gt; \n    gt() |&gt; \n  fmt_number(\n    columns = c(Average_NPV,Average_Adjusted_NPV, Difference) ,\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    hh_02 = \"\",\n    NAM_1 = \"Marz\",\n    Average_NPV = \"Average NPV of agricultural income (USD)\",\n    Average_Adjusted_NPV = \"Adjusted average NPV of imputed rent (USD)\",\n    Difference = \"Loss (USD)\",\n    No_HH = \"No. HH\"\n  )\n\n\n\n\n\n\n\n\nMarz\nAverage NPV of agricultural income (USD)\nAdjusted average NPV of imputed rent (USD)\nLoss (USD)\nNo. HH\n\n\n\n\n1\nYerevan\n3,639.9\n3,018.6\n621.3\n42\n\n\n2\nAragatsotn\n37,721.3\n32,543.6\n5,177.7\n804\n\n\n3\nArarat\n29,091.2\n23,422.8\n5,668.4\n1509\n\n\n4\nArmavir\n46,713.9\n39,410.4\n7,303.6\n1220\n\n\n5\nGegharkunik\n14,437.6\n12,817.4\n1,620.3\n1611\n\n\n6\nLori\n15,100.1\n12,984.5\n2,115.6\n733\n\n\n7\nKotayk\n28,639.2\n23,934.7\n4,704.5\n576\n\n\n8\nShirak\n55,604.9\n46,262.5\n9,342.4\n678\n\n\n9\nSyunik\n38,137.7\n32,105.0\n6,032.8\n188\n\n\n10\nVayots Dzor\n25,405.5\n19,522.4\n5,883.1\n141\n\n\n11\nTavush\n18,736.1\n15,077.5\n3,658.7\n208\n\n\n\n\n\n\n\n\nag_income_by_weights |&gt; \n  left_join(deciles, join_by(interview__key == hhid)) |&gt; \n  #rename(poor = poor_Avpovln2022) |&gt; \n  filter(!is.na(annual_ag_income)) |&gt; \n  mutate(poor = if_else(poor_Avpovln2022==1, \n                        \"Below poverty line\", \n                        \"Above poverty line\")) |&gt; \n  group_by( decile) |&gt; \n  summarize(\n    Average_NPV = weighted.mean(net_present_ag_value, weight_exposed, na.rm = TRUE) * er,\n    Average_Adjusted_NPV = weighted.mean(\n      npv_ag_income_by_weight, weight_exposed, na.rm = TRUE) * er,\n    Difference =  Average_NPV - Average_Adjusted_NPV,\n    No_HH = round(sum(weight_exposed, na.rm = TRUE))\n  ) |&gt;\n   ungroup() |&gt; \n    gt() |&gt; \n  fmt_number(\n    columns = c(Average_NPV,Average_Adjusted_NPV, Difference) ,\n    decimals = 1\n  ) |&gt; \n  cols_label(\n    decile = \"Decile\",\n    Average_NPV = \"Average NPV of ag income (USD)\",\n    Average_Adjusted_NPV = \"Adjusted average NPV of ag income (USD)\",\n    Difference = \"Loss (USD)\",\n    No_HH = \"No. HH\"\n  )\n\n\n\n\n\n\n\nDecile\nAverage NPV of ag income (USD)\nAdjusted average NPV of ag income (USD)\nLoss (USD)\nNo. HH\n\n\n\n\n1\n23,757.7\n20,274.7\n3,483.0\n533\n\n\n2\n22,535.7\n18,812.6\n3,723.1\n800\n\n\n3\n34,730.9\n28,736.7\n5,994.2\n722\n\n\n4\n23,769.6\n19,933.4\n3,836.2\n703\n\n\n5\n28,212.2\n23,805.1\n4,407.1\n818\n\n\n6\n34,301.5\n29,370.4\n4,931.1\n794\n\n\n7\n29,781.4\n25,055.9\n4,725.5\n824\n\n\n8\n32,046.7\n26,483.7\n5,563.0\n852\n\n\n9\n34,380.8\n28,697.7\n5,683.1\n715\n\n\n10\n37,223.9\n31,421.5\n5,802.4\n950",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis Calculations"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability-hh-level-impacts.html#impacts-on-the-income-distribution",
    "href": "supporting-materials/vulnerability-hh-level-impacts.html#impacts-on-the-income-distribution",
    "title": "Vulnerability Analysis Calculations",
    "section": "7 Impacts on the income distribution",
    "text": "7 Impacts on the income distribution\nAfter evaluating the long term impacts to the asset value of imputed rent and agricultural income, it is interesting to evaluate the shorter term repercussions that floods can have in the shor term for those affected.\nIn the case of agriculture, the impacts can be readily evaluated, since the variables affected are already part of the income calculations. However, imputed rent is not included in the income calculations so we need to adjust our poverty line to reflect this additional value.\nWe will try two ways of doing this; the first will be to increase the poverty line by the total weighted average of imputed rent. The second will be to increase the poverty line by the regional weighted average of imputed rent.\n\n7.1 Agriculture impacts\nLet’s subtract the monthly impacts from total expenditure on ag income and see how it affects the poverty calculations. We use expenditure here, because official poverty calculations for Armenia are estimated from the consumption side.\n\nag_poverty_impacts &lt;- ca |&gt; \n  left_join(ag_income_by_weights, join_by(hhid == interview__key)) |&gt;\n  filter(!is.na(inc4)) |&gt; \n  mutate(new_totc = totc - (inc4 -\n           adjusted_inc4) ) |&gt;\n  # Equivalized consumption per person per month adjusted by\n  # prices and absentiism:\n  # Total hh consumption / adult equivalent (adj. absent) / price index\n  mutate(new_aec_r = new_totc / ae_r / PI) |&gt; \n  # Recalculate the poverty headcount\n  mutate(new_ag_poorAvpovln2022 = \n           if_else(new_aec_r &lt; 52883, 1, 0)) |&gt;  # Official poverty line\n  ungroup()\n\nLet’s have a look at the two distributions.\n\n# Basic density plot comparing equivalized consumption per capita\nggplot(ag_poverty_impacts, aes(x = aec_r, fill = 'Total Consumption')) + \n  geom_density(alpha = 0.5) + \n  geom_density(data = ag_poverty_impacts, aes(x = new_aec_r, fill = 'Modified Total Consumption'), alpha = 0.5) +\n  labs(fill = \"Consumption Type\", title = \"Comparison of Consumption Distributions\", x = \"Equivalized consumption\", y = \"Density\") +\n  theme_minimal()+\n  coord_cartesian(xlim = c(0, 300000)) + # Zoom in without removing data\n  scale_x_continuous(labels = scales::comma) +\n  scale_y_continuous(labels = scales::comma)+\n  geom_vline(xintercept = 55883, \n             color = \"red\", \n             linetype = \"dotted\", \n             size =0.8) +\n  annotate(\"text\", \n           x = 55883, \n           y = 0.0000025, \n           label = \"Poverty line\\nAMD 55,883\", \n           color = \"black\", \n           hjust = -0.1, \n           # vjust = -3.5,\n           #angle = 90, \n           size = 3)\n\n\n\n\n\n\n\n\nWe’ll try to understand the proportion of total income that agriculture (inc4) represents for this group and also, how much the loss represents out of total income. We will also evaluate the average differences between income and expenditure.\n\n# Agriculture income share\nag_poverty_impacts |&gt; \n  mutate(inc4 = if_else(is.na(inc4), 0, inc4)) |&gt;  # Prevent NA divisions\n  mutate(ag_share = inc4 / totalinc) |&gt;  # Ag share\n  mutate(loss_share = (inc4 - adjusted_inc4)/totc) |&gt; \n  group_by(NAM_1) |&gt; \n  summarize( avg_ag_share = \n               round(weighted.mean(ag_share,weight_exposed ,na.rm=TRUE)*100, digits=1),\n             avg_loss_share = \n               round(weighted.mean(loss_share,weight_exposed, na.rm=TRUE)*100, digits=1),\n             avg_total_income = \n               round(weighted.mean(totalinc,weight_exposed, na.rm=TRUE), digits=1),\n             avg_total_consumption = \n               round(weighted.mean(totc,weight_exposed, na.rm=TRUE), digits=1),\n             ) |&gt; \n  ungroup()|&gt; \n  gt()\n\n\n\n\n\n\n\nNAM_1\navg_ag_share\navg_loss_share\navg_total_income\navg_total_consumption\n\n\n\n\nAragatsotn\n24.4\n5.3\n401463.2\n236041.2\n\n\nArarat\n22.4\n6.1\n330124.5\n203609.2\n\n\nArmavir\n34.8\n8.1\n315773.4\n219602.2\n\n\nGegharkunik\n17.5\n2.1\n259912.3\n207924.2\n\n\nKotayk\n15.6\n4.1\n402557.2\n249147.2\n\n\nLori\n14.5\n2.5\n212144.4\n219069.1\n\n\nShirak\n34.3\n9.9\n281733.7\n181769.2\n\n\nSyunik\n22.3\n5.4\n310146.5\n223218.2\n\n\nTavush\n14.8\n3.8\n251614.5\n208656.7\n\n\nVayots Dzor\n23.5\n6.0\n250903.3\n268811.3\n\n\nYerevan\n5.3\n0.7\n222904.9\n314544.0\n\n\n\n\n\n\n\nWe fixed an earlier mistake in which the poverty calculation methodology differed from the official headcount. Now we can check is if any of the households that were not poor before became poor after the shock.\n\nag_poverty_impacts |&gt;\n  rename(old_poor = poor_Avpovln2022,\n         new_poor = new_ag_poorAvpovln2022) |&gt; \n  group_by(old_poor, new_poor) |&gt;\n  summarize(no_poor = round(sum(weight_exposed, na.rm = TRUE))) |&gt; \n  ungroup() |&gt; \n  gt() |&gt; \n  cols_label(\n    old_poor = \"Previous Poor = 1\",\n    new_poor = \"Poor after shock = 1\",\n    no_poor = \"Number of households\"\n  ) |&gt; \n  grand_summary_rows(\n    columns = c(no_poor),\n    fns= list(\n      Total = ~sum(., na.rm = TRUE)\n      ),\n    fmt = list(~ fmt_number(., decimals = 0))\n  ) \n\n\n\n\n\n\n\n\nPrevious Poor = 1\nPoor after shock = 1\nNumber of households\n\n\n\n\n\n0\n0\n5674\n\n\n\n0\n1\n391\n\n\n\n1\n1\n1646\n\n\nTotal\n—\n—\n7,711\n\n\n\n\n\n\n\nThis shows that 391 out of 7,711 households with agricultural income affected by floods (5%) that were previously non-poor would fall into poverty in 2022.\n\n\n7.2 Buildings impacts\nFor buildings there is the problem that the original poverty calculations did not include imputed rent as an allowance of the household so there is no variable to impact directly. What we can do is modify the poverty line individually according to the increase in imputed rent and then evaluate who falls into poverty after the shock.\nActually, this is the same as just impacting total consumption by the loss amount and leaving the poverty line where it is.\n\nrent_poverty_impacts &lt;- ca |&gt; \n  left_join(rent_by_weights, join_by(hhid == household_id)) |&gt;\n  #filter(!is.na(imputed_rent)) |&gt; \n  mutate(new_totc = totc - (imputed_rent -\n           adjusted_rent_by_weight) ) |&gt;\n  # Equivalized consumption per person per month adjusted by\n  # prices and absentiism:\n  # Total hh consumption / adult equivalent (adj. absent) / price index\n  mutate(new_aec_r = new_totc / ae_r / PI) |&gt; \n  # Recalculate the poverty headcount\n  mutate(new_buildings_poorAvpovln2022 = \n           if_else(new_aec_r &lt; 52883, 1, 0)) |&gt;  # Official poverty line\n  ungroup()\n\nAnd now we can check impacts on poverty.\n\nrent_poverty_impacts |&gt;\n  filter(!is.na(imputed_rent)) |&gt; \n  rename(old_poor = poor_Avpovln2022,\n         new_poor = new_buildings_poorAvpovln2022) |&gt; \n  group_by(old_poor, new_poor) |&gt;\n  summarize(no_poor = round(sum(weight_exposed, na.rm = TRUE))) |&gt; \n  ungroup() |&gt; \n  gt() |&gt; \n  cols_label(\n    old_poor = \"Previous Poor = 1\",\n    new_poor = \"Poor after shock = 1\",\n    no_poor = \"Number of households\"\n  ) |&gt; \n  grand_summary_rows(\n    columns = c(no_poor),\n    fns= list(\n      Total = ~sum(., na.rm = TRUE)\n      ),\n    fmt = list(~ fmt_number(., decimals = 0))\n  ) \n\n\n\n\n\n\n\n\nPrevious Poor = 1\nPoor after shock = 1\nNumber of households\n\n\n\n\n\n0\n0\n17214\n\n\n\n0\n1\n471\n\n\n\n1\n1\n3892\n\n\nTotal\n—\n—\n21,577\n\n\n\n\n\n\n\nThis shows that 471 out of 21,577 households with imputed rent affected by floods (2%) that were previously non-poor would fall into poverty in 2022.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis Calculations"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Armenia Country Climate and Development Report",
    "section": "",
    "text": "This website contains background documents and guides created for Armenia’s Country Climate and Development Report. Authorship is indicated in each document."
  },
  {
    "objectID": "drafts/tasks.html",
    "href": "drafts/tasks.html",
    "title": "Tasks",
    "section": "",
    "text": "You will re-do the impact of flooding on imputed rent with the admin1 data attached (Data_AAL_AAE.xlsx) and with a duplication of households instead of random selection. We cannot calculate a poverty impact or income distribution impact, however showing who is affected more (poor vs non poor for example) is already a very useful story for the CCDR.\nYou will do the analysis of flooding on agriculture income using the average annual losses from the attached data (Data_AAL_AAE.xlsx) and with a duplication of households instead of random selection. For this one we can calculate an impact on poverty or income distribution. For example, are there households that fall into poverty because of the shocks?\nFor both these impacts it would be interesting to show the total impact for poor vs non poor (or other groups, for example urban vs rural) but also the impact relative to the households’ income for these same groups."
  },
  {
    "objectID": "drafts/tasks.html#flood-analysis",
    "href": "drafts/tasks.html#flood-analysis",
    "title": "Tasks",
    "section": "",
    "text": "You will re-do the impact of flooding on imputed rent with the admin1 data attached (Data_AAL_AAE.xlsx) and with a duplication of households instead of random selection. We cannot calculate a poverty impact or income distribution impact, however showing who is affected more (poor vs non poor for example) is already a very useful story for the CCDR.\nYou will do the analysis of flooding on agriculture income using the average annual losses from the attached data (Data_AAL_AAE.xlsx) and with a duplication of households instead of random selection. For this one we can calculate an impact on poverty or income distribution. For example, are there households that fall into poverty because of the shocks?\nFor both these impacts it would be interesting to show the total impact for poor vs non poor (or other groups, for example urban vs rural) but also the impact relative to the households’ income for these same groups."
  },
  {
    "objectID": "bg-notes/hh-assets-and-fuelwood-use.html",
    "href": "bg-notes/hh-assets-and-fuelwood-use.html",
    "title": "Household Assets and Fuelwood Use",
    "section": "",
    "text": "Homes are perhaps the most important asset owned by households. In 2022, most of the 800,604 Armenian households owned their dwelling (about 89.4%), as shown in Figure 1, with only about 5.9% of homes renting and 4.7% with other forms of tenure (ARMSTAT, 2023). Also, about 97% of households lived in houses or apartments, as opposed to hostel; railcar / container; other temporary lodging; or “other” (3% combined). Houses averaged 112.0 m2, while apartments averaged 68.3 m2. As expected, 96.2% of apartments were located in urban areas, with about half of them in Yerevan (55.3%). Houses, on the other hand, were located mostly in rural areas (65.8%), with about 13.4% of them located in Yerevan.\nFigure 1. Dwelling ownership by Marz\n[CHART]\nSource: Integrated Living Conditions Survey, 2022 (ARMSTAT, 2023).\nThe rental market is small and an urban phenomenon, with 92% of rentals occurring in that area. The average rent for a house was AMD 56,613.6 (about USD 143.1) with an average price of AMD 882.4 (USD 2.23) per square meter. Conversely, apartments were rented at a more expensive mean of AMD 82,124.2 (USD 207.6) with an average price of AMD 1,447.8 (USD 3.7) per square meter.\nOwned dwellings are an asset from which households derive welfare. Non renters derived an average of AMD 54,338.1 (USD 137.33) in monthly imputed rent. The emergent rental market information was used to impute rent to non-renters using a log linear modeling approach described by Ceriani et al. (2019), in which imputed rent was predicted using a combination of household characteristics (urban/rural, Marz, number of rooms, presence of an indoor toilet, number of household, square meters, type of dwelling, members) and head of household characteristics (sex, highest completed schooling level, age group). These values are shown in Table 1 by decile and for the whole country. Net present value of that monthly imputed rent (for a 2050 horizon) was also estimated at AMD 17.3 million (USD 43,881.5), using a 5% annual discount rate and a 5% average inflation rate.\nTable 1. Imputed rent and average net present value (2050 horizon) for non-renters\n\n\n\n\n\n\n\n\n\nDecile\nAverage dwelling area (m2)\nAverage imputed rent (Dram per month)\nAverage net present value of rent (2050 horizon)\n\n\n\n\n1\n89.4\n45,632.3\n14,565,638.7\n\n\n2\n91.1\n51,149.9\n16,326,813.0\n\n\n3\n91.1\n52,635.7\n16,801,095.0\n\n\n4\n89.5\n55,010.5\n17,559,108.4\n\n\n5\n88.3\n53,896.9\n17,203,666.3\n\n\n6\n87.2\n54,230.5\n17,310,143.3\n\n\n7\n93.0\n54,532.6\n17,406,560.2\n\n\n8\n89.1\n52,558.3\n16,776,366.9\n\n\n9\n86.7\n56,791.0\n18,127,439.9\n\n\n10\n87.5\n59,735.1\n19,067,188.6\n\n\nCountry\n89.0\n54,338.1\n17,344,482.6\n\n\n\nSource: author based on log linear imputed rent approach (Ceriani et al., 2019)\nA little over a third (288,718 or 36.1%) of households owned a car in 2022 and used it in the month prior to the survey. However, a higher percentage of homes in rural areas (47.5%) own a vehicle. Given the characteristics of rural areas and the availability of public transportation, it is a particularly important asset for household mobility. This also means that these households are exposed to energy transition risks derived from changes to prices of fuels and technological changes in car technologies (TNFD, 2023).\nArmenians access water mainly through centralized water supply (95.6% or 765,728 households), 2.7% of households have their own system of water supply, and the remaining 1.6% access water through spring water or well; delivered water; bought water; or “other”. Urban households spend an average of about AMD 2,506.5 (USD 6.3) on water, while rural households spend about AMD 1,790.1 (USD 4.5).\nMost homes (99.8% or 798,835 households) access electricity through the national grid, with only a small share 0.2% using solar panels. Both urban and rural homes spend about the same average expenditure on electricity of about AMD 7,948.3 (USD 20.1).",
    "crumbs": [
      "Home",
      "Background notes",
      "Household Assets and Fuelwood Use"
    ]
  },
  {
    "objectID": "bg-notes/hh-assets-and-fuelwood-use.html#household-assets",
    "href": "bg-notes/hh-assets-and-fuelwood-use.html#household-assets",
    "title": "Household Assets and Fuelwood Use",
    "section": "",
    "text": "Homes are perhaps the most important asset owned by households. In 2022, most of the 800,604 Armenian households owned their dwelling (about 89.4%), as shown in Figure 1, with only about 5.9% of homes renting and 4.7% with other forms of tenure (ARMSTAT, 2023). Also, about 97% of households lived in houses or apartments, as opposed to hostel; railcar / container; other temporary lodging; or “other” (3% combined). Houses averaged 112.0 m2, while apartments averaged 68.3 m2. As expected, 96.2% of apartments were located in urban areas, with about half of them in Yerevan (55.3%). Houses, on the other hand, were located mostly in rural areas (65.8%), with about 13.4% of them located in Yerevan.\nFigure 1. Dwelling ownership by Marz\n[CHART]\nSource: Integrated Living Conditions Survey, 2022 (ARMSTAT, 2023).\nThe rental market is small and an urban phenomenon, with 92% of rentals occurring in that area. The average rent for a house was AMD 56,613.6 (about USD 143.1) with an average price of AMD 882.4 (USD 2.23) per square meter. Conversely, apartments were rented at a more expensive mean of AMD 82,124.2 (USD 207.6) with an average price of AMD 1,447.8 (USD 3.7) per square meter.\nOwned dwellings are an asset from which households derive welfare. Non renters derived an average of AMD 54,338.1 (USD 137.33) in monthly imputed rent. The emergent rental market information was used to impute rent to non-renters using a log linear modeling approach described by Ceriani et al. (2019), in which imputed rent was predicted using a combination of household characteristics (urban/rural, Marz, number of rooms, presence of an indoor toilet, number of household, square meters, type of dwelling, members) and head of household characteristics (sex, highest completed schooling level, age group). These values are shown in Table 1 by decile and for the whole country. Net present value of that monthly imputed rent (for a 2050 horizon) was also estimated at AMD 17.3 million (USD 43,881.5), using a 5% annual discount rate and a 5% average inflation rate.\nTable 1. Imputed rent and average net present value (2050 horizon) for non-renters\n\n\n\n\n\n\n\n\n\nDecile\nAverage dwelling area (m2)\nAverage imputed rent (Dram per month)\nAverage net present value of rent (2050 horizon)\n\n\n\n\n1\n89.4\n45,632.3\n14,565,638.7\n\n\n2\n91.1\n51,149.9\n16,326,813.0\n\n\n3\n91.1\n52,635.7\n16,801,095.0\n\n\n4\n89.5\n55,010.5\n17,559,108.4\n\n\n5\n88.3\n53,896.9\n17,203,666.3\n\n\n6\n87.2\n54,230.5\n17,310,143.3\n\n\n7\n93.0\n54,532.6\n17,406,560.2\n\n\n8\n89.1\n52,558.3\n16,776,366.9\n\n\n9\n86.7\n56,791.0\n18,127,439.9\n\n\n10\n87.5\n59,735.1\n19,067,188.6\n\n\nCountry\n89.0\n54,338.1\n17,344,482.6\n\n\n\nSource: author based on log linear imputed rent approach (Ceriani et al., 2019)\nA little over a third (288,718 or 36.1%) of households owned a car in 2022 and used it in the month prior to the survey. However, a higher percentage of homes in rural areas (47.5%) own a vehicle. Given the characteristics of rural areas and the availability of public transportation, it is a particularly important asset for household mobility. This also means that these households are exposed to energy transition risks derived from changes to prices of fuels and technological changes in car technologies (TNFD, 2023).\nArmenians access water mainly through centralized water supply (95.6% or 765,728 households), 2.7% of households have their own system of water supply, and the remaining 1.6% access water through spring water or well; delivered water; bought water; or “other”. Urban households spend an average of about AMD 2,506.5 (USD 6.3) on water, while rural households spend about AMD 1,790.1 (USD 4.5).\nMost homes (99.8% or 798,835 households) access electricity through the national grid, with only a small share 0.2% using solar panels. Both urban and rural homes spend about the same average expenditure on electricity of about AMD 7,948.3 (USD 20.1).",
    "crumbs": [
      "Home",
      "Background notes",
      "Household Assets and Fuelwood Use"
    ]
  },
  {
    "objectID": "bg-notes/hh-assets-and-fuelwood-use.html#household-exposure-to-the-agricultural-sector",
    "href": "bg-notes/hh-assets-and-fuelwood-use.html#household-exposure-to-the-agricultural-sector",
    "title": "Household Assets and Fuelwood Use",
    "section": "Household exposure to the agricultural sector",
    "text": "Household exposure to the agricultural sector\nAbout a fourth of all Armenian households (23.4%) had a monthly agricultural income component; a number that rises to 61% when discussing rural households, with that income representing an average 22.6% of total income. Overall, 91.3% of those 187,176 households that derived an agricultural income were located in rural areas. This income averaged AMD 72,275.2 (USD 182.67) and represented an average of 23.7% of total income for rural homes. These same figures averaged AMD 47,853.1 (USD 120.94) and 12.0% in urban areas, respectively. When it comes to deciles, perhaps unintuitively, the average share of total income that comes from agriculture rises from 20.7% for the first decile to 26.3% for the tenth, as shown in Table 2.\nTable 2. Average agricultural income\n\n\n\n\n\n\n\n\n\nDecile\nAverage total\nincome\nAverage agricultural\nIncome\nAverage agricultural income\nshare of total income\n\n\n\n\n1\n272,739.6\n54,013.3\n20.7%\n\n\n2\n277,204.7\n47,470.2\n19.3%\n\n\n3\n308,608.9\n75,184.5\n22.0%\n\n\n4\n280,508.0\n51,349.7\n18.3%\n\n\n5\n306,497.2\n68,414.4\n24.0%\n\n\n6\n301,499.4\n69,378.7\n22.8%\n\n\n7\n315,422.2\n72,267.4\n21.5%\n\n\n8\n337,909.6\n78,487.8\n25.5%\n\n\n9\n295,644.2\n78,357.8\n23.5%\n\n\n10\n315,725.2\n92,134.7\n26.3%\n\n\nCountry\n303,234.5\n70,156.4\n22.6%\n\n\n\nSource: author based on Integrated Living Conditions Survey, 2022 (ARMSTAT, 2023).\nNote: column three is the average of the share calculated at the household level and weighted by population weights, not column two divided by column one.\nWhile only 23.4% of households, derive income from the agricultural sector, exposure to agriculture is larger, since 41% of households use land for agricultural purposes (owned and/or rented). A total of 98% out of the 328,438 households that use agricultural land own their plots, and 5.3% of those (also) rented. The average area used by households for agricultural purposes is 7,329.9 m2, of which an average 70.6%, or 5,551.2 m2, is used for crops. This suggests that own consumption of agricultural output plays a role in Armenian incomes. Table 3 shows that for households without agricultural sales, 4.3% of income can be attributed to imputed use of agricultural products for own consumption. More generally, this table shows the shares of household income from different sources, for households with agricultural land, with or without deriving income from that land, compared with households without agricultural land. It is evident that public pensions and benefits plays a much bigger role (29.7%) for all households, along with hired employment (41.3%).\nTable 3. Average shares of sources of income for households with and without agricultural land\n\n\n\n\n\n\n\n\n\n\n\nHouseholds with a gricultural land (owned or not) with a gricultural income\nHouseholds with a gricultural land (owned or not) with no a gricultural income\nHouseholds without a gricultural land (owned or not) with or without a gricultural income\nAll households\n\n\n\n\nNumber of households\n184,738\n143,700\n472,166\n800,604\n\n\nAverage total income (Dram)\n302,290.3\n223,874.8\n247,434.9\n255,863.9\n\n\nAverage share of income coming from:\n\n\n\n\n\n\n\nSale of a gricultural products\n\n22.8%\n0.0%\n0.1%\n5.3%\n\n\n\nImputed use of a gricultural products for own\nconsumption\n\n8.7%\n4.3%\n0.6%\n3.2%\n\n\n\nHired\nemployment\n\n28.5%\n40.5%\n46.6%\n41.3%\n\n\n\nSelf -employment\n\n10.2%\n9.2%\n8.0%\n8.7%\n\n\n\nProperty (rent, interest, equity gain)\n\n0.1%\n0.1%\n0.2%\n0.2%\n\n\n\nPublic pensions and benefits\n\n22.2%\n33.8%\n31.5%\n29.7%\n\n\n\nTransfers\n\n7.2%\n10.5%\n11.6%\n10.4%\n\n\n\nOther\n\n0.7%\n1.3%\n1.4%\n1.2%\n\n\nAll income shares\n100%\n100%\n100%\n100%\n\n\n\nSource: author based on Integrated Living Conditions Survey, 2022 (ARMSTAT, 2023).",
    "crumbs": [
      "Home",
      "Background notes",
      "Household Assets and Fuelwood Use"
    ]
  },
  {
    "objectID": "bg-notes/hh-assets-and-fuelwood-use.html#household-reliance-on-firewood-for-heating",
    "href": "bg-notes/hh-assets-and-fuelwood-use.html#household-reliance-on-firewood-for-heating",
    "title": "Household Assets and Fuelwood Use",
    "section": "Household reliance on firewood for heating",
    "text": "Household reliance on firewood for heating\n\nExpenditure elasticities for fuelwood\nMost homes in Armenia use natural gas for heating (61.9% or 495,203 households), but an important 23.8% (190,884 households) use wood for heating, followed by 21.7% that use electricity and 8.2% pressed dung. Negligible percentages of households use liquefied gas or coal (0.2% and 0.9% respectively). In rural areas, 51.5% of rural homes (143,724 households) use wood for heating, which correlates with the 54.8% of rural households that have a self-made heater as main technology. Not only is wood used as heating source, but it is also used as an “energy carrier” (mainly cooking) by 11.3% of all households. In rural areas, 25.8% of homes use it for this purpose.\nWhile there is a market for fuelwood, many homes do not pay for fuelwood annually. Figure 2 shows the distribution for this concept, showing a clear component of households paying zero Dram for their fuelwood consumption annually. This is possibly related to those households that collect wood for free. However, as shown in Table 4, homes that do pay for fuelwood spend an average of AMD 128,209.2 (about USD 317.8) annually, which is roughly 5.5% of total annual expenditure for the average household.\nFigure 2. Annual wood expenditure distribution\nSource: Integrated Living Conditions Survey, 2022 (ARMSTAT, 2023).\nTable 4. Average fuelwood expenditure and quantity used annually and in the month prior to the survey\n\n\n\n\n\n\n\n\n\n\n\n\nArea\nAverage monthly household total expenditure (Dram)\nAverage monthly household energy expenditure (Dram)\nFuelwood expenditure in month prior to survey (Dram)\nFuelwood quantity used in month prior to survey (m3)\nFuelwood expenditure annually\n(Dram)\nFuelwood quantity used annually\n(m3)\n\n\n\n\nURBAN\n187,752.5\n12,700.4\n2,510.2\n0.6\n116,428.6\n6.4\n\n\nRURAL\n201,881.6\n15,652.8\n1,821.9\n0.6\n131,653.5\n6.8\n\n\nCountry\n192,673.8\n13,728.7\n1,977.6\n0.6\n128,209.2\n6.7\n\n\n\nSource: author based on Integrated Living Conditions Survey, 2022 (ARMSTAT, 2023).\nHowever, an expenditure elasticity of annual wood expenditure across income deciles1 (when moving from decile to decile) points to a complex relationship between income and fuelwood expenditure. The higher elasticities in the middle deciles might reflect an increased ability and desire to spend on fuelwood, possibly for heating during colder months. The negative figures in the higher deciles could suggest a shift towards more modern heating solutions, or that beyond a certain income level, the relative importance of fuelwood decreases. The variations between deciles underscore the diverse factors influencing energy choices, including affordability, accessibility, and preferences. (see Table 5). The higher expenditure elasticity for fuelwood in decile 5 could be indicative of larger household sizes or larger homes that require more wood for heating and cooking. This would naturally lead to a higher quantity of fuelwood being used, which would increase expenditure on fuelwood without necessarily implying luxury consumption that theory would suggest with high elasticities.\nThis interpretation would be consistent with a scenario where these households, perhaps due to their size or location, have not yet transitioned to other energy sources, which are often more accessible in urban settings or to wealthier households that can afford the initial investment in more modern heating systems. This considers the socio-economic context that might prevent a switch to alternative fuels, even when households have slightly more income. Issues such as availability of infrastructure, initial costs of switching to gas or electric heating, and cultural preferences for wood.\nIn rural areas for example, the availability of fuelwood and the lack of infrastructure for alternative energy sources can lead to a situation where households spend more on wood simply because it’s one of the few options available to them, and not because they particularly prefer wood over other fuels. Indeed, when conducting this analysis across urban to rural, the elasticity value reaches 3.25 (growth of wood expenditure is three times the growth of total consumption across urban/rural), confirming that living in rural areas might be a big determinant of fuelwood use, simply because it’s the technology to which those homes have access and other infrastructure is lacking.\nTable 5. Expenditure elasticity of annual wood expenditure across deciles\n\n\n\nDecile\nElasticity of Annual Wood Expenditure\n\n\n\n\n1\n-\n\n\n2\n0.5\n\n\n3\n0.2\n\n\n4\n1.6\n\n\n5\n3.3\n\n\n6\n2.1\n\n\n7\n-0.3\n\n\n8\n0.4\n\n\n9\n-0.1\n\n\n10\n-0.2\n\n\n\nSource: author based on Integrated Living Conditions Survey, 2022 (ARMSTAT, 2023).\nFor comparison, the expenditure elasticity of natural gas expenditure (which has a more traditionally priced market) across income deciles suggest that natural gas is not consistently treated as a normal or inferior good across the income spectrum. The negative elasticities in higher deciles may indicate a trend of higher-income households either becoming more energy-efficient, having better-insulated homes, or switching to alternative fuels that are perceived as cleaner or more convenient. This might be consistent with the higher percentage of urban homes that use electricity for cooking and heating. The very high negative elasticity in decile 9 is particularly notable and could warrant a closer investigation to understand the underlying causes.\nTable 6. Expenditure elasticity of natural gas expenditure across deciles\n\n\n\nDecile\nElasticity\n\n\n\n\n1\n-\n\n\n2\n0.62\n\n\n3\n0.10\n\n\n4\n-0.88\n\n\n5\n-0.44\n\n\n6\n0.22\n\n\n7\n-0.29\n\n\n8\n-0.48\n\n\n9\n-6.59\n\n\n10\n-0.55\n\n\n\nSource: author based on Integrated Living Conditions Survey, 2022 (ARMSTAT, 2023).\nWhen comparing pressed dung, the elasticity behavior shows a component that responds much more to income levels. Table 7 shows the household expenditure elasticity of press dung expenditure across deciles, suggesting big leaps to lower levels of expenditure on pressed dung as households move from decile to decile, especially moving from decile 3 to 4, from decile 5 to 6 and then from 6 to 7.\nTable 7. Expenditure elasticity of pressed dung expenditure across deciles\n\n\n\nDecile\nElasticity of Pressed Dung Expenditure\n\n\n\n\n1\n0.00\n\n\n2\n0.43\n\n\n3\n-0.56\n\n\n4\n-6.41\n\n\n5\n-3.35\n\n\n6\n-25.71\n\n\n7\n-12.18\n\n\n8\n1.02\n\n\n9\n0.48\n\n\n10\n-4.81\n\n\n\nSource: author based on Integrated Living Conditions Survey, 2022 (ARMSTAT, 2023).\n\n\nDeterminants of fuelwood consumption\nThere are various factors that influence fuelwood consumption by households. While income is important, it’s not the only determinant, and there are other factors, which include affordability and availability of fuels, scarcity of fuelwood supply, fuel preferences, and cost and performance of end-use equipment. Moreover, all these factors also on whether the household is in an urban or rural setting (Lefevre et al., 1997).\nTo better understand this, a linear model was conducted on household data for Armenia (to explain annual wood quantity used by household as determined by Marz, urban/rural, total household income, dwelling size in square meters, hectares of forests per thousand inhabitants by Marz2 (see Table 8), average price of natural gas in Marz and area (urban/rural), computed as the average of the division of total spent on natural gas by amount of natural gas used by households in that Marz and area (urban/rural); and average electricity bill in that Marz and Area.\nThe explanatory power of the model is moderate3 (Adjusted R-squared: 0.2668), but the results are interesting as shown in Table 9. The baseline level of annual wood consumption is high (with an intercept 26.51 cubic meters of wood). The effect of administrative division is small and statistically insignificant (ADM1 administrative division -0.0271). The effect of being in a rural area, compared to an urban area, is not significant. Results indicate that for each unit increase in total income, wood consumption increases by approximately 0.0000029 cubic meters per year. This effect is highly significant (p &lt; 2.26e-16), suggesting a positive relationship between income and wood consumption, which is counterintuitive. More in line with expectations is dwelling size, which is also highly significant, suggesting that higher dwelling sizes lead to higher fuelwood use. The number of hectares of forest by thousand inhabitants is a significant predictor. The coefficient indicates that more forest availability leads to higher wood consumption. Both the price of natural gas and average expenditure on electricity in Marz and area are non-significant.\nTable 8. Hectares of forest per thousand inhabitants\n\n\n\n\n\n\n\n\n\n\n\nMarz\nForested areas (Ha)\nNot Forested areas (Ha)\nTotal area (Ha)\nPopulation 2020 (thousand inhabitants)\nHectares of forest per thousand inhabitants\n\n\n\n\nYerevan\n-\n23,246.8\n23,246.8\n1,084.0\n-\n\n\nAragatsotn\n1,948.2\n270,744.9\n272,693.1\n26.8\n72.7\n\n\nArarat\n3,417.5\n207,130.8\n210,548.3\n72.1\n47.4\n\n\nArmavir\n196.5\n125,429.7\n125,626.2\n82.4\n2.4\n\n\nGegharkunik\n13,525.9\n383,155.5\n396,681.4\n66.6\n203.1\n\n\nLori\n81,492.8\n293,208.2\n374,701.0\n126.1\n646.3\n\n\nKotayk\n11,571.6\n199,289.4\n210,861.0\n136.8\n84.6\n\n\nShirak\n882.2\n269,527.6\n270,409.8\n135.6\n6.5\n\n\nSyunik\n44,390.9\n402,134.9\n446,525.9\n93.2\n476.3\n\n\nVayots Dzor\n2,500.0\n226,086.5\n228,586.5\n17.1\n146.2\n\n\nTavush\n121,962.8\n149,079.3\n271,042.2\n93.2\n1,308.6\n\n\n\nSource: author land use land cover information from ESA CCI Land Cover time-series v.2.0.7, 1992-2020 (ESA, 2023) and population data (ARMSTAT, 2020).\nTable 9. Regression results on the determinants of fuelwood use\n\n\n\n\nMin\n1Q\nMedian\n3Q\nMax\n\n\n\n\nResiduals:\n-13.625\n-1.716\n-0.501\n1.35\n13.445\n\n\n\nCoefficients: Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) 6.19E+00 1.58E+01 0.391 0.696   ADM1 administrative divisions -2.71E-02 3.33E-02 -0.815 0.415\nUrban/Rural 7.22E-02 2.02E-01 0.358 0.72\nDwelling size (m2) 2.08E-02 2.22E-03 9.4 &lt; 2e-16 *** Total income (Dram) 2.22E-06 3.14E-07 7.081 2.26E-12 *** Ha. of forest / 1000 inhabitants 3.28E-03 3.23E-04 10.145 &lt; 2e-16 *** Avg. price of natural gas (Dram/m3) -2.47E-02 1.14E-01 -0.217 0.828\nAvg. electricity expenditure (Dram) -2.88E-06 9.76E-05 -0.03 0.976  \nSignificance codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ’ ’ 1\nResidual standard error: 2.808 on 1392 degrees of freedom (3784 observations deleted due to missingness)\nMultiple R-squared: 0.2704, Adjusted R-squared: 0.2668.\nF-statistic: 73.71 on 7 and 1392 DF, p-value: &lt; 2.2e-16.\nOverall, it can be concluded that there is an income effect that is counter intuitive. Higher income is associated with increased wood consumption. Wealthier households probably consume more wood due to larger homes as captured in the effect of dwelling size, and a strong cultural preference for wood as a fuel source with probably limited alternatives due to infrastructure or other reasons. Forest availability is also a strong predictor, suggesting that more available forest resources lead to higher wood consumption. There’s a tendency for wood consumption to decrease as natural gas prices increase, though this is almost insignificant and general electricity expenditure does not seem to be a significant determinant of wood consumption at all.",
    "crumbs": [
      "Home",
      "Background notes",
      "Household Assets and Fuelwood Use"
    ]
  },
  {
    "objectID": "bg-notes/hh-assets-and-fuelwood-use.html#references",
    "href": "bg-notes/hh-assets-and-fuelwood-use.html#references",
    "title": "Household Assets and Fuelwood Use",
    "section": "References",
    "text": "References\nARMSTAT. (2020). Marzes of the Republic of Armenia and Yerevan city in figures, 2020.\nARMSTAT. (2023). Integrated Living Conditions Survey 2022 [dataset].\nCeriani, L., Olivieri, S., & Ranzani, M. (2019). Housing, imputed rent, and households’ welfare. Poverty & Equity Global Practice Working Papers, 213. https://documents1.worldbank.org/curated/pt/336451565194643402/pdf/Housing-Imputed-Rent-and-Households-Welfare.pdf\nESA. (2023). ESA CCI Land Cover time-series v.2.0.7 (1992-2020). European Space Agency.\nLefevre, T., Todoc, J., & Raj Timilsina, G. (1997). The Role of Wood Energy in Asia. Food and Agriculture Organization of the United Nations.\nTNFD. (2023). Recommendations of the Taskforce on Nature-related Financial Disclosures. Green Finance Institute.",
    "crumbs": [
      "Home",
      "Background notes",
      "Household Assets and Fuelwood Use"
    ]
  },
  {
    "objectID": "bg-notes/hh-assets-and-fuelwood-use.html#footnotes",
    "href": "bg-notes/hh-assets-and-fuelwood-use.html#footnotes",
    "title": "Household Assets and Fuelwood Use",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is calculated as: Decile Expenditure Elasticity of Demand = % Change in average expenditure from decile to decile / % Change in average Fuelwood Expenditure Demanded by (expenditure) decile.\n​↩︎\nAuthor calculated this variable using land use land cover information from ESA CCI Land Cover time-series v.2.0.7, 1992-2020 (ESA, 2023) and population data (ARMSTAT, 2020).↩︎\nModerate but robust. The model has been probed using the Variance Inflation Factor, showing that the model does not appear to suffer from sever multicollinearity. Correlations among variables are moderate or low as well. A concern about interaction between urban/rural and dwelling size, which removed the slight significance of a previous model without dwelling size was ruled out, testing a model with the interaction of these variables, which was not significant.↩︎",
    "crumbs": [
      "Home",
      "Background notes",
      "Household Assets and Fuelwood Use"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "data/ARM-Geodata/ARM-ADM1.html",
    "href": "data/ARM-Geodata/ARM-ADM1.html",
    "title": "Armenia CCDR",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n        0 0     false"
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "",
    "text": "Filename: 01_Master.do\nThe master file explains the structured workflow:\n\nSetup and Preprocessing: The initial segments define the working environment, set the necessary paths, and import necessary libraries or tools. The globals defined will help in driving the subsequent operations.\nMacro Inputs & Creation of Globals: Fetches macro inputs from an Excel file and dynamically define some global variables. There are placeholder comments suggesting an alternate approach to fetch scenarios and years, which might have been used in earlier iterations or for debugging purposes.\nMFmod Microsimulation: Run a microsimulation model to generate simulated weights and welfare aggregate measures.\nIndicator Generation: Using the simulated data, compute various indicators. These are poverty rates, income measures, and other socio-economic indicators.\nOpening the Excel Scenario File: Lastly, the main workflow ends by opening an Excel file to inspect or use the scenarios and results interactively.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#program-setup",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#program-setup",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "2.1 Program setup",
    "text": "2.1 Program setup\nThis sets the minimum required Stata version to run the code to 15.1. We also perform some housekeeping:\n\ndrop _all removes all variables from the dataset in memory.\nclear all removes all data from memory.\nset more off turns off the ‘more’ feature, which pauses output at the screen every time it’s filled.\n\nversion 15.1\ndrop _all\nclear all\nset more off\nChecks if the current Stata user’s name is \"wb527706\". If it is, it sets the global macro path to the specified directory. This tailors the code to a specific user’s directory structure.\nif \"`c(username)'\"==\"wb527706\" {\n    global path \"C:\\Users\\WB527706\\OneDrive - WBG\\Madagascar\"\n}\nThe next lines set up a series of global macros with directory paths based on the earlier-defined path:\nglobal HHsurvey    = \"$path\\data\"\nglobal inputs      = \"$path/inputs\"    \nglobal outputs     = \"$path/outputs\"\nglobal MAGclimsim    \"$path\\MagClimSim.xlsx\"",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#hh-consumption-aggregates-and-characteristics",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#hh-consumption-aggregates-and-characteristics",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "2.2 HH consumption aggregates and characteristics",
    "text": "2.2 HH consumption aggregates and characteristics\nThis loads a dataset from the specified directory, which was previously defined in the global macro HHsurvey. The clear option ensures that any current data in memory is replaced. Note that we don’t have access to that survey.\nuse \"$HHsurvey\\outputdata\\ca_real_pl.dta\", clear\nHere, a new variable rural is created, which is equal to 1 if the area is “Rural” and 0 if the area is “Urbain”.\ngen     rural   = 1     if  area==\"Rural\"\nreplace rural   = 0     if  area==\"Urbain\"\nThe variable pcer is renamed to pcc (indicating per capita expenditure).\nren pcer pcc\nA new variable yhh is created by multiplying pcc (per capita expenditure) by hhsize (household size).\ngen yhh=pcc*hhsize\nThese lines rename the variables: wgt becomes wgt0 and wgt_adj becomes wgt.\nren wgt wgt0 \nren wgt_adj wgt\nThis line keeps only the listed variables in the dataset, dropping all others.\nkeep  hhid rural hhsize region pcc yhh wgt yhh // \n      pline215 pline365 pline685 ubpl lbpl\nA temporary file named HHcha is specified, and the current dataset is saved to that file.\ntempfile HHcha\nsave `HHcha'\nSo far:\n\nSets up paths tailored to the user’s directory structure.\nLoads a specific dataset related to household consumption aggregates and characteristics.\nManipulates and keeps only select variables of interest.\nSaves the modified data to a temporary file for later use.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#demographic-characteristics",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#demographic-characteristics",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "2.3 Demographic characteristics",
    "text": "2.3 Demographic characteristics\nThis line loads a dataset related to demographic characteristics from the directory specified by the global macro HHsurvey, replacing data in memory.\nuse \"$HHsurvey\\outputdata\\S01_DEMO_01.dta\", clear\nHere, a new variable hhgrap is created, identical to the cluster variable. The dataset in memory is then merged with the DéfinitionsQuatreMilieux.dta dataset based on the hhgrap variable. The resulting _merge variable (indicating merge success for each observation) is dropped as customary.\ngen hhgrap = cluster \nmerge n:1 hhgrap using \"$HHsurvey\\outputdata\\DéfinitionsQuatreMilieux.dta\"\ndrop _merge\nThe variable MILIEU4 is renamed to zone and the variable sex is renamed to gender. A new binary variable head is created, which takes a value of 1 when relhead equals 1 (presumably indicating that the individual is the head of the household) and 0 otherwise. The variable relhead is renamed to rel.\nren MILIEU4 zone\nren sex gender\ngen head = relhead == 1\nren relhead rel\nOnly the specified variables are retained, and all other variables are dropped.\nkeep hhid pid gender age head rel zone\nThe dataset in memory is saved to a temporary file named demo.\ntempfile demo\nsave `demo'",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#years-of-education",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#years-of-education",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "2.4 Years of education",
    "text": "2.4 Years of education\nA new dataset related to education is loaded, replacing the current dataset in memory. Note that we don’t have access to that one.\nuse \"$HHsurvey\\inputdata\\EPM21\\S02_EDUC.dta\", clear\nA new variable yos (probably standing for the availability of “years of schooling”) is created based on the variable q2_26. However, its value is set to 0 wherever the variable q2_01 is not equal to 1. Note that the consultant made a code annotation explicitly sayin that it is NOT “years of schooling”. Then the variable yos is renamed to educy.\ngen yos = q2_26\nreplace yos=0 if q2_01 != 1\nrename yos educy\nThe data is sorted by hhgrap and hhnum. Then, a new variable hhid is created by concatenating hhgrap and hhnum, presumably to create a unique household ID. The variables hhgrap and q2_0x are then renamed to cluster and pid, respectively.\nsort hhgrap hhnum\negen hhid = concat(hhgrap hhnum), format(%9.0g) punct(\",\")\nrename hhgrap cluster\nrename q2_0x pid\nOnly the specified variables are retained, and all others are dropped. The dataset in memory is saved to a temporary file named edu.\nkeep hhid pid educy\ntempfile edu\nsave `edu'\nTo summarize, this code segment:\n\nLoads a dataset related to demographic characteristics.\nMerges it with another dataset to enhance the information.\nMakes some modifications to the variable names and keeps relevant variables.\nSaves the modified dataset to a temporary file.\nLoads a new dataset related to years of education.\nMakes transformations related to educational years and constructs a unique household ID.\nKeeps the necessary variables and saves the modified dataset to another temporary file.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#non-labor-income",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#non-labor-income",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "2.5 Non labor income",
    "text": "2.5 Non labor income\n\n2.5.1 Pensions, rents, and dividends\nThis section of code is focused on calculating and aggregating non-labor income. First, we have pensions, rents, dividends, and lotteries. The script loads a dataset related to various revenues.\nuse \"$HHsurvey\\inputdata\\EPM21\\S05_REVE.dta\", clear\nThe next series of lines, as before, creates a unique household ID by concatenating hhgrap and hhnum, and then renames some variables.\nsort    hhgrap hhnum\negen    hhid =  concat(hhgrap hhnum), format(%9.0g) punct(\",\")\nrename  hhgrap  cluster\nrename  q5_0x   pid \nFor each type of income (pensions, rents, dividends, and occasional income like lottery winnings), the script creates a new variable only if another corresponding variable is set to 1 (probably indicating that the income source is relevant for that observation).\nSurvey: Pension annual basis: retrate/veuvage/dinvalidité/alimentaire.\ngen nli_pen1=q5_02 if q5_01==1\ngen nli_pen2=q5_04 if q5_03==1 \ngen nli_pen3=q5_06 if q5_05==1 \ngen nli_pen4=q5_08 if q5_07==1 \nSurvey: Rents.\ngen nli_rent=q5_10 if q5_09==1\nSurvey: Dividends.\ngen nli_div=q5_12 if q5_11==1\nSurvey: Lottery winnings, inheritance, sale of property, etc.\ngen nli_occ=q5_14 if q5_13==1\nThis line creates a new variable, nli_prdo (presumably non-labor income pensions, rents, dividents, other), that sums up the previously created income variables for each observation. The data is then collapsed (aggregated) by hhid, and saved into a temporary file.\negen nli_prdo=rsum(nli_pen1 nli_pen2 nli_pen3 nli_pen4 nli_rent nli_div nli_occ)\ncollapse (sum) nli_prdo ,by(hhid)\ntempfile nli_prdo\nsave `nli_prdo'\n\n\n2.5.2 Individual transfers\nThe next section focuses on individual transfers. It follows a similar structure: load data, create a unique household ID, create variables for different income sources (in this case, transfers), aggregate by household, and save to a temporary file.\nThe new variables (nli_hhs1 and nli_hhs2) are generated based on conditions related to the frequency of the transfer (monthly, quarterly, etc.), and then aggregated into nli_itrans.\nuse \"$HHsurvey\\inputdata\\EPM21\\S13_TRAN_A.dta\", clear\n\n//ID at HH and IND definition \n   \nsort    hhgrap hhnum\negen    hhid =  concat(hhgrap hhnum), format(%9.0g) punct(\",\")\nrename  hhgrap  cluster\n    \ngen      nli_hhs1=q13_18a*12     if q13_18b==1 & (q13_01==1 | q13_02==1) \nreplace  nli_hhs1=q13_18a*4      if q13_18b==2 & (q13_01==1 | q13_02==1)\nreplace  nli_hhs1=q13_18a*2      if q13_18b==3 & (q13_01==1 | q13_02==1)\nreplace  nli_hhs1=q13_18a        if q13_18b==4 & (q13_01==1 | q13_02==1)\nreplace  nli_hhs1=q13_18a        if q13_18b==5 & (q13_01==1 | q13_02==1)\n    \ngen     nli_hhs2=q13_21a*12      if q13_21b==1 & (q13_01==1 | q13_02==1)\nreplace  nli_hhs2=q13_21a*4      if q13_21b==2 & (q13_01==1 | q13_02==1)\nreplace  nli_hhs2=q13_21a*2      if q13_21b==3 & (q13_01==1 | q13_02==1)\nreplace  nli_hhs2=q13_21a        if q13_21b==4 & (q13_01==1 | q13_02==1)\nreplace  nli_hhs2=q13_21a        if q13_21b==5 & (q13_01==1 | q13_02==1)\n    \negen nli_itrans=rsum(nli_hhs1 nli_hhs2)\ncollapse (sum) nli_itrans ,by(hhid)\nSaved temporarily in:\ntempfile nli_itrans\nsave `nli_itrans'\n\n\n2.5.3 Public Transfers\nThis section deals with public transfers. The data handling is quite similar to the previous sections. The income from public transfers is calculated based on the frequency, aggregated by household, and saved into a temporary file nli_gov.\nu \"$HHsurvey\\inputdata\\EPM21\\S15_FILE.dta\", clear\n\n//ID at HH and IND definition \nsort    hhgrap hhnum\negen    hhid =  concat(hhgrap hhnum), format(%9.0g) punct(\",\")\nrename  hhgrap  cluster\n    \ng        nli_gov=q15_10a*12     if q15_10b==1 & (q15_02==1 ) \nreplace  nli_gov=q15_10a*4      if q15_10b==2 & (q15_02==1 )  \nreplace  nli_gov=q15_10a*2      if q15_10b==3 & (q15_02==1 ) \nreplace  nli_gov=q15_10a        if q15_10b==4 & (q15_02==1 )\nreplace  nli_gov=q15_10a        if q15_10b==5 & (q15_02==1 )    \n\ncollapse (sum) nli_gov ,by(hhid)\ntempfile nli_gov\nsave `nli_gov'\nThe last piece of code merges the aggregated data from the three previous sections\nu  `nli_prdo', clear\nmerge 1:1 hhid using `nli_itrans' , nogen\nmerge 1:1 hhid using `nli_gov' , nogen\nHere, the script loads the data related to pensions, rents, dividends, etc., and then merges it with the data from individual and public transfers using hhid as the key variable.\nA new variable, nli_hh, is created, which is the sum of all non-labor income sources for each household.\negen nli_hh=rsum(nli_prdo nli_gov nli_itrans)\nFinally, this aggregated data is saved into another temporary file.\ntempfile nli\nsave `nli'\nTo summarize, this segment of the code:\n\nLoads datasets related to various non-labor income sources: pensions, rents, dividends, individual transfers, and public transfers.\nProcesses each data source to calculate the total income for each type.\nMerges the data from the various sources and aggregates the total non-labor income by household.\nSaves the resulting dataset for future use.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#labor-market-variables",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#labor-market-variables",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "2.6 Labor market variables",
    "text": "2.6 Labor market variables\nA dataset related to employment is loaded into Stata.\nu \"$HHsurvey\\inputdata\\EPM21\\S04_EMPL_AI.dta\", clear\nThe subsequent lines create a unique household ID by concatenating hhgrap and hhnum, and rename some variables. This pattern has been repeated from the previous chunks of code. The data is then merged with the non-labor income dataset (created in the previous section):\nsort    hhgrap hhnum\negen    hhid =  concat(hhgrap hhnum), format(%9.0g) punct(\",\")\nrename  hhgrap  cluster\nrename  q4a_xx  pid\n    \n// Merge non-labor income part\nmerge n:1 hhid using `nli' , nogen\n\n2.6.1 Labor Force Status:\nThe variable lstatus is created based on different responses to the employment-related questions. This variable categorizes individuals into employed, unemployed and seeking work, unemployed but not seeking work, or outside the labor force (OLF).\n//employed\ng lstatus = 1 if  q4a_01==1 | q4a_02==1 | q4a_03==1 | //\n                  q4a_04==1 | q4a_09&lt;4\n\n// Unemployed - available and searching \nreplace lstatus = 2  if q4a_96==1 \n\n// Unemployed - available, but not searching\nreplace lstatus = 3  if q4a_96==2   \n\n//OLF\nreplace lstatus = 4  if missing(lstatus) \n\nlab var lstatus \"Labor force status\"\nlab def lstatus_lab 1 \"employed\" 2 \"unemployed - seeking\" //\n                    3 \"unemployed - not-seeking\" 4 \"OLF\"\nlab val lstatus lstatus_lab\n\n\n2.6.2 Employed Population and Salaried Status:\nThe code identifies which individuals are employed (employed variable) and then aggregates this at the household level. It then determines if employed individuals are salaried or self-employed.\ngen employed = lstatus==1\nbysort hhid : egen employed_hh=max(employed)\n\ngen salaried = .\nreplace salaried = 1 if q4a_24 ==1\n\n// self-employed if employed and salary is missing.\nreplace salaried = 0 if mi(salaried) & employed==1 \nlab var salaried \"Employment status\"\nlab def salaried 1 \"paid employee\" 0 \"self-employed\"\nlab val salaried salaried\n\n\n2.6.3 Labor Income Computations:\nThe subsequent part of the code calculates labor income (lab_pri) based on different frequencies of payment (daily, weekly, monthly, etc.). Similar calculations are done for bonuses (lab_ikb), other in-kind incomes (lab_iko, lab_ikf), and incomes from a second job (lab_sec, lab_sik, lab_sit, lab_sif). The total labor income is then aggregated into lab_tot.\nSurvey: What was [NAME]’s salary for this job (for the time period considered)?\ng        lab_pri= q4a_46a*365               if q4a_46b==1  \nreplace  lab_pri= q4a_46a*(365/7)*(1)       if q4a_46b==2\nreplace  lab_pri= q4a_46a*12                if q4a_46b==3\nreplace  lab_pri= q4a_46a                   if q4a_46b==4\nSurvey: In-kind bonus. A combien évaluez-vous les primes ( uniquement ceux qui ne sont pas inclus dans le salaire)?\ng        lab_ikb= q4a_48a*365               if q4a_48b==1  \nreplace  lab_ikb= q4a_48a*(365/7)*(1)       if q4a_48b==2\nreplace  lab_ikb= q4a_48a*12                if q4a_48b==3\nreplace  lab_ikb= q4a_48a                   if q4a_48b==4\nSurvey: Other inkind. A combien évaluez-vous ces avantages ( uniquement ceux qui ne sont pas inclus dans le salaire)?\ng        lab_iko= q4a_50a*365               if q4a_50b==1  \nreplace  lab_iko= q4a_50a*(365/7)*(1)       if q4a_50b==2\nreplace  lab_iko= q4a_50a*12                if q4a_50b==3\nreplace  lab_iko= q4a_50a                   if q4a_50b==4\nSurvey: Food from the job.\ng        lab_ikf= q4a_52a*365               if q4a_52b==1  \nreplace  lab_ikf= q4a_52a*(365/7)*(1)       if q4a_52b==2\nreplace  lab_ikf= q4a_52a*12                      if q4a_52b==3\nreplace  lab_ikf= q4a_52a                   if q4a_52b==4\nSurvey: Second activity labor income.\ng        lab_sec= q4a_62a*365               if q4a_62b==1  \nreplace  lab_sec= q4a_62a*(365/7)*(1)       if q4a_62b==2\nreplace  lab_sec= q4a_62a*12                if q4a_62b==3\nreplace  lab_sec= q4a_62a                   if q4a_62b==4   \nSurvey: In-kind second bonus.\ng        lab_sik= q4a_64a*365               if q4a_64b==1  \nreplace  lab_sik= q4a_64a*(365/7)*(1)       if q4a_64b==2\nreplace  lab_sik= q4a_64a*12                if q4a_64b==3\nreplace  lab_sik= q4a_64a                   if q4a_64b==4\nSurvey: Other in-kind, such as transport.\ng        lab_sit= q4a_66a*365               if q4a_66b==1  \nreplace  lab_sit= q4a_66a*(365/7)*(1)       if q4a_66b==2\nreplace  lab_sit= q4a_66a*12                if q4a_66b==3\nreplace  lab_sit= q4a_66a                   if q4a_66b==4\nSurvey: In-kind food.\ng        lab_sif= q4a_68a*365               if q4a_68b==1  \nreplace  lab_sif= q4a_68a*(365/7)*(1)       if q4a_68b==2\nreplace  lab_sif= q4a_68a*12                if q4a_68b==3\nreplace  lab_sif= q4a_68a                   if q4a_68b==4\nAll labor aggregated into lab_tot.\negen lab_tot=rsum(lab_pri lab_ikb lab_iko lab_ikf //\n                  lab_sec lab_sik lab_sit lab_sif)\n\n// Code turned off, presumably used with already processed surveys.\n*egen lab_tot=rsum(lab_pri  lab_sec)\n\n// All labor income expressed in thousands.\nreplace lab_tot=lab_tot*1000\n\n\n2.6.4 Treatment of Missing Data and Outliers:\nThe script examines missing labor income values among employed individuals and identifies outliers. Observations with labor incomes more than 5 standard deviations away from the mean are marked as outliers. There’s an annotation that explains that missings represent 10% of those employed. Mainly primary sector and household workers.\n//Outliers sd&gt;5\nsum lab_tot if employed==1 & lab_tot&gt;0\ngen d = lab_tot/r(sd)\ngen outlier = 1 if d&gt;5\nreplace outlier = 1 if employed==1 & lab_tot==0\nreplace outlier = 0 if outlier==.\n\n// Missing\ngen missings = 1     if employed==1 & lab_tot==0\nreplace missings = 0 if missings==.\n\n\n2.6.5 Merge with Demographic Characteristics:\nThe dataset is merged with household characteristics (HHcha), demographics (demo), and education (edu) datasets.\nmerge n:1 hhid using `HHcha' \nkeep if _merge==3\nmerge 1:1 hhid pid using `demo' , nogen\nmerge 1:1 hhid pid using `edu' , gen(edu)\n\n\n2.6.6 Sector Categorization:\nThe sector variable categorizes individuals into primary, secondary, or tertiary sectors based on their reported economic activity (q4a_230).\n***Sector\ngen sector=1 if q4a_230==\"A\" | q4a_230==\"B\" | q4a_230==\"C\" | q4a_230==\"0\" | //\n                q4a_230==\"1\" | q4a_230==\"2\" | q4a_230==\"3\" | q4a_230==\"4\" | //\n                q4a_230==\"5\" | q4a_230==\"6\" | q4a_230==\"7\" | q4a_230==\"8\" | //\n                q4a_230==\"9\" \n\nreplace sector=2 if  q4a_230==\"D\"| q4a_230==\"E\"| q4a_230==\"F\"\n\nreplace sector=3 if  q4a_230==\"G\" | q4a_230==\"H\" | q4a_230==\"I\" |   //\n                     q4a_230==\"J\" |q4a_230==\"K\"  | q4a_230==\"L\" |   //\n                     q4a_230==\"M\" | q4a_230==\"N\" | q4a_230==\"O\" |   //\n                     q4a_230==\"P\" | q4a_230==\"Q\" | q4a_230==\"R\" |   //\n                     q4a_230==\"S\" | q4a_230==\"T\" | q4a_230==\"U\"\nThere’s also imputation logic in place for missing sector information, where an employed individual without a specified sector is assigned the sector of the household head.\ngen aux = sector if head==1\nbysort hhid : egen sectorhh=max(aux)\nreplace sector=sectorhh if sector==. & employed==1\n\nreplace sector=2 if sector==. & employed==1 //to check \nreplace sector=. if lstatus==2 | lstatus==3\nlab var sector \"Economic activity sector\"\n\nlab def sector_lab 0 \"unemployed\" 1 \"primary (Agr)\" //\n                   2 \"secondary (Ind)\" 3 \"tertiary (Ser)\" \nlab val sector sector_lab\nreplace sector = . if lstatus==4 //No sector for OLF",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#model-for-predicting-labor-income",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#model-for-predicting-labor-income",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "2.7 Model for Predicting Labor Income:",
    "text": "2.7 Model for Predicting Labor Income:\nThe code calculates squared values for education (educy2) and age (age2) and creates a binary variable for males (male). A natural logarithm of total labor income is then calculated (lnlab).\nclonevar industry = sector\n\ngen educy2   = educy * educy\ngen age2     = age*age\ngen male     = 1 if gender==1\nreplace male = 0 if gender==2\nSubsequently, a regression model (reg) predicts the logarithm of labor income (lnlab) based on various factors, but only for employed individuals who are neither outliers nor missing income values.\ngen lnlab    = ln(lab_tot)\nreg lnlab age gender i.educy age2 i.region i.q4a_24 i.sector [iw=wgt]  //\n          if employed==1 & outlier==0 & missings==0\nUsing this model, predicted income values (remp2 and temp2) are generated for employed outliers or those missing labor income data.\npredict remp2 if employed==1 & outlier==1 | missings==1 , xb\npredict temp2 if employed==1 & outlier==1 | missings==1 \nFinally, these predicted values are transformed to actual income scale (simuli) using the exponential function, and negative predictions are set to zero.\ngen simuli = .\nreplace simuli = exp(temp2)\nreplace simuli = 0 if simuli&lt;0\nIn summary, this section of the code:\n\nLoads and processes labor market data.\nCalculates labor force status and categorizes people based on their employment and income details.\nComputes and aggregates labor income for different sources.\nTreats missing data and outliers for labor income.\nMerges the processed labor data with demographic and education datasets.\nCategorizes individuals based on their sector of economic activity.\nPredicts labor income for those missing data using regression, and adjusts the predictions as needed.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#shares-and-total-income-to-the-model",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#shares-and-total-income-to-the-model",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "2.8 Shares and total income to the model",
    "text": "2.8 Shares and total income to the model\nThis section is focused on computing shares and total income in preparation for a model.\nHere, for those individuals who are employed and are either considered outliers or have missing labor income data (lab_tot), their labor income is replaced with the simulated value (simuli) generated in the previous section.\nreplace lab_tot=simuli if  employed==1 & (outlier==1 | missings==1 )\nThis line calculates the total labor income at the household level, aggregating all individual incomes within each household.\nbysort hhid : egen lab_hh=sum(lab_tot)\nThe total income for each household is computed by summing the total labor income (lab_hh) and non-labor income (nli_hh).\negen    income_hh=rsum(lab_hh nli_hh)\nThen we calculate the share of labor and non-labor income out of the total income for each household.\ngen       s_lab    = lab_hh/income_hh\ngen       s_nli    = nli_hh/income_hh\nAnd compute the natural logarithms of total income (income_hh) and household consumption (yhh).\ngen     lny      =ln(income_hh)\ngen     lnc      =ln(yhh)\nThe marginal propensity to consume (mpc) is calculated as the ratio of household consumption (yhh) to total income (income_hh).\ng       mpc      = yhh/income_hh\nThe subsequent lines compute shares and derive other variables related to labor income and consumption:\n\nshare captures the individual’s share of labor income in the household’s total labor income, but only for those employed.\nylb gives the portion of household consumption funded by labor income, while ynl represents the portion of household consumption sourced from non-labor income.\nylbi represents the individual’s portion of household consumption funded by their labor income, again limited to the employed.\n\ngen share = lab_tot/lab_hh  if employed==1\n\n// HH Consumption from labor\ngen ylb = yhh*s_lab\nlab var ylb   //\n    \"Household consumption from labor income -nominal (Ariary/hh/year)\"\n\n// HH Consumption from non-labor\ngen ynl = yhh*(1-s_lab)\nlab var ynl  //\n    \"Household consumption from non-labor income - nominal (Ariary/hh/year)\"\n\ng ylbi=ylb*share if employed==1\nThe dataset is then pruned to keep only select variables, and saved to a temporary file.\nkeep hhid pid industry yhh ylb ynl ylbi salaried  \ntempfile labor\nsave `labor'",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#final-datasets",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#final-datasets",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "2.9 Final datasets",
    "text": "2.9 Final datasets\nThe main household characteristics dataset (HHcha) is loaded again. It then gets merged sequentially with the demographic (demo), education (edu), and labor (labor) datasets.\nOnce all necessary merges are done, the generation variables (dem, edu, labo) are dropped. The resulting final dataset, which combines household characteristics, demographics, education, and labor variables, is then saved as MAG_assigned.dta.\nuse `HHcha' , clear\nmerge 1:n hhid using `demo' , gen(dem)\nkeep if dem==3\nmerge 1:1 hhid pid using `edu' , gen(edu)\nmerge 1:1 hhid pid using `labor' , gen(labo)\ndrop dem edu labo\nsave  \"$HHsurvey\\MAG_assigned.dta\", replace\nIn summary, this segment:\n\nAdjusts individual labor income values based on simulations for outliers and missing data.\nComputes various shares related to labor and non-labor incomes.\nCreates the logarithm of incomes and computes the marginal propensity to consume.\nDerives individual and household-level variables for consumption funded by labor and non-labor income.\nMerges several datasets to compile a comprehensive dataset containing household characteristics, demographics, education, and labor information.\nSaves the final dataset for subsequent analysis.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#import-population-data-to-be-used-in-the-creation-of-globals",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#import-population-data-to-be-used-in-the-creation-of-globals",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "3.1 Import population data to be used in the creation of globals",
    "text": "3.1 Import population data to be used in the creation of globals\nWe first load a dataset specified by the global macro popdata, but only for the observations where the variable country matches the value specified by the global macro country. Here, we are aggregating the data by Variant and country using gcollapse (an enhanced version of Stata’s collapse command). The (sum) function sums up all the variables starting with yf and ym. And we reshape the dataset from wide to long format based on the yf and ym variables. The combined identifiers are country and Variant, while the variable year is created to represent the time dimension.\nuse \"$popdata\" if country==\"$country\", clear\nqui gcollapse (sum) yf* ym*, by(Variant country) \nqui reshape long yf ym, i(country Variant) j(year)\nHere, we generate a new variable named pop, which is the sum of the yf (likely female population) and ym (likely male population) variables, essentially getting the total population. The individual gender-based population variables (yf and ym) are then dropped, as we now have the combined pop variable. The variable country is also dropped from the dataset. The dataset is then saved into a temporary file named pop.\nqui g pop = yf+ym \nqui drop yf ym\ndrop country\ntempfile pop\nsave `pop'\nThe year variable is summarized to get its basic statistics. Two local macros are defined: minyear, which is assigned the value of the global macro surveyyear, and maxyear, which is assigned the maximum value of the year variable.\nqui sum year\nlocal minyear = $surveyyear\nlocal maxyear = r(max)\nA local macro v is initialized to 1. The subsequent loop then runs over several population projection variants. For each variant and for every year between minyear and maxyear, the total population (pop) for that year (pop_t) and the base year (pop_base) is calculated. The population growth rate is then computed by dividing pop_t by pop_base and saved into a global macro with a naming convention based on the year and variant. The counter v increments for each variant.\nlocal v = 1\nforeach variant in \"Medium\" \"Low\" \"High\" \"Constant-fertility\" //\n                   \"Instant-replacement\" \"Momentum\"  //\n                   \"Instant-replacement-zero-migration\" //\n                   \"Constant-mortality\" \"No-change\" {\n  forvalues t = `minyear'/`maxyear' {  \n        /* Population growth */\n        qui sum pop if year==`t' & Variant==\"`variant'\"\n        local pop_t = r(sum) \n        qui sum pop  if year==`minyear' & Variant==\"`variant'\"\n        local pop_base = r(sum) \n        global pop_growth_t`t'_v`v' = `pop_t'/`pop_base'\n    }\n    local v = `v'+1\n}\nLastly, the code imports an Excel file specified by the macro scenario_file from a sheet named elas_rep, clearing the existing data in memory. These are three cells with the elasticities for Agriculture, Manufacturing (Industry), and Services. We put these in a matrix E from the dataset, variable A (first column).\nimport excel \"${scenario_file}\", sheet(elas_rep) clear \nmkmat A  , mat(E)\nIn summary, this chunk of code:\n\nImports a dataset and reshapes it to long format based on population variables.\nAggregates the data to get total populations by year and variant.\nComputes population growth rates for different scenarios across years.\nImports another dataset from Excel related to some scenarios.\nTransforms part of the dataset into a matrix for further analysis.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#import-data-from-the-excel-file-received-from-macroeconomic-modelers",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#import-data-from-the-excel-file-received-from-macroeconomic-modelers",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "3.2 Import data from the excel file received from macroeconomic modelers",
    "text": "3.2 Import data from the excel file received from macroeconomic modelers\nA local macro i is initialized to 0. A loop is then started, iterating over a global macro called scenarios, which presumably contains a list of sheet names from the Excel file to import. For each sheet name in scenarios, the code imports data from the Excel file specified by the scenario_file macro. The data is imported from the cell range A3:N63. This command renames the variables in the dataset using the variable names stored in the global macro $vars. The counter i is incremented by 1, and a new variable scenid is created in the dataset, which is given the current value of i. This acts as an identifier for each scenario. The dataset is saved into a temporary file named based on the current value of i (like scen1, scen2, etc.). The loop then moves on to the next sheet name in scenarios.\nforeach x of global scenarios {\n    qui import excel \"${scenario_file}\", sheet(\"`x'\") cellrange(A3:N63) clear\n    rename (*) ($vars)\n    local i = `i'+1\n    g scenid = `i'\n    tempfile scen`i'\n    qui save `scen`i''\n}\nThe dataset from the first scenario (scen1) is loaded into memory. A new local macro num is defined, which calculates the number of items in the scenarios global macro. Then, a loop starts from 2 up to the value of num. For each iteration, the dataset for the scenario corresponding to the current value of i is appended to the dataset in memory.\nuse `scen1', clear\nlocal num : list sizeof global(scenarios)\nforvalues i = 2/`num' {\n    append using `scen`i''\n}\nAny observations with a missing value for the year variable are dropped. A new variable rwage is created, which represents the real wage by dividing the wage variable by the cpi (Consumer Price Index) variable. This adjusts the wage for inflation.\ncap drop if year==.\nqui g rwage = wage/cpi\nThe variable Variant is initialized with empty strings. Then, a loop iterates over another global macro named variants. For each iteration, the value of Variant is replaced with the current item from variants where the scenid matches the current value of i. This assigns the appropriate variant name to each observation based on its scenid.\ng Variant = \"\"\nlocal i = 1\n    foreach variant of global variants {\n        replace Variant = \"`variant'\" if scenid==`i'\n        local i = `i' + 1\n    }\nThe dataset is then merged with the one saved in the temporary file pop based on the year and Variant variables. Observations that didn’t find a match in the pop dataset are dropped, and the _merge variable (created by the merge command) is also dropped. The dataset is sorted by scenid and then year.\nmerge m:1 year Variant using `pop'\ndrop if _merge==2\ndrop _merge\nsort scenid year\nThen a new variable consumption_pc is created, which calculates the per capita consumption. This is done by dividing the consumption variable by 100 times the pop variable.\ng consumption_pc = consumption/(pop*10e2)  \n}\nIn summary:\n\nWe import various scenarios from an Excel file and save each as a temporary Stata dataset.\nCombines all the scenarios into one dataset.\nProcesses the dataset by calculating real wages, assigning scenario names, merging with population data, and calculating per capita consumption values.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#creating-globals-by-yearscenario-to-be-used-later-in-the-microsimulation",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#creating-globals-by-yearscenario-to-be-used-later-in-the-microsimulation",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "3.3 Creating globals by year/scenario to be used later in the microsimulation",
    "text": "3.3 Creating globals by year/scenario to be used later in the microsimulation\nThese lines determine the range of years in the dataset. The minimum year is set to a predefined global macro ($surveyyear), and the maximum year is the maximum year observed in the dataset.\nqui sum year\nlocal minyear = $surveyyear\nlocal maxyear = r(max)\nThis line identifies all the unique values of scenid in the dataset and stores them in a local macro called scenarios.\nlevelsof scenid, loc(scenarios)\nThe code then starts a loop, iterating over each unique scenario in the dataset. Inside the loop for each scenario, another loop starts which iterates over the years from the minimum to the maximum year. Within these nested loops, a series of commands calculate global growth rates and other indicators for various economic variables (GDP, consumption, employment, value added in different sectors, wages, etc.). The calculations are typically in the form:\nqui sum [variable] if year==`t' & scenid==`sc'\nlocal [variable]_t = r(sum)\nqui sum [variable] if year==`minyear' & scenid==`sc'\nlocal [variable]_base = r(sum)\nglobal [variable]_growth_t`t'_sc`sc' = `variable_t'/`variable_base'\nFor each combination of year and scenario, these commands:\n\nSum up the variable’s value for the current year (t) and scenario (sc).\nSave this sum in a local macro.\nSum up the variable’s value for the base year and the current scenario.\nSave this sum in another local macro.\nCalculate the growth rate by dividing the current year’s sum by the base year’s sum.\nSave the growth rate in a global macro.\n\nThese steps are repeated for several economic indicators. At the end of the nested loops, the Stata dataset will contain a series of global macros capturing the growth rates and other economic indicators for each year and scenario.\nforeach sc of numlist `scenarios' {  \n    forvalues t = `minyear'/`maxyear' {  \n        \n        /* GDP */\n        \n        qui sum gdp if year==`t' & scenid==`sc'\n        local gdp_t = r(sum) \n        qui sum gdp  if year==`minyear' & scenid==`sc'\n        local gdp_base = r(sum) \n        global gdp_growth_t`t'_sc`sc' = `gdp_t'/`gdp_base'\n        \n        /* Consumption */\n        \n        qui sum consumption if year==`t' & scenid==`sc'\n        local consumption_t = r(sum) \n        qui sum consumption  if year==`minyear' & scenid==`sc'\n        local consumption_base = r(sum) \n        global c_growth_t`t'_sc`sc' = `consumption_t'/`consumption_base' \n        \n        /* Consumption per capita */\n\n        qui sum consumption_pc if year==`t' & scenid==`sc'\n        local consumption_t = r(sum) \n        qui sum consumption_pc   if year==`minyear' & scenid==`sc'\n        local consumption_base = r(sum) \n        global pcc_growth_t`t'_sc`sc' = `consumption_t'/`consumption_base'\n\n        /* Remittances */\n        \n        qui sum remittances if year==`t' & scenid==`sc'\n        local remittances_t = r(sum) \n        qui sum remittances  if year==`minyear' & scenid==`sc'\n        local remittances_base = r(sum) \n        global remitt_growth_t`t'_sc`sc' = `remittances_t'/`remittances_base'       \n        \n        /* Employment */\n        \n        qui sum employment if year==`t' & scenid==`sc'\n        local employment_t = r(sum) \n        qui sum employment   if year==`minyear' & scenid==`sc'\n        local employment_base = r(sum) \n        global emp_growth_t`t'_sc`sc' = `employment_t'/`employment_base'        \n        \n        /* Employment rate */\n        \n        qui sum employment    if year==`t' & scenid==`sc'\n        local employment_t_n = r(sum) \n        qui sum wa_population if year==`t' & scenid==`sc'\n        local employment_t_d = r(sum)   \n        global emp_rate_t`t'_sc`sc' = `employment_t_n'/`employment_t_d' \n        \n        /* Working age population */\n        \n        qui sum wa_population if year==`t' & scenid==`sc'\n        local employment_t = r(sum) \n        qui sum wa_population    if year==`minyear' & scenid==`sc'\n        local employment_base = r(sum) \n        global wapop_growth_t`t'_sc`sc' = `employment_t'/`employment_base'\n        \n        /* Value added */\n        \n        qui sum agriculture_va if year==`t' & scenid==`sc'\n        local N_i = r(sum) \n        qui sum agriculture_va if year==`minyear' & scenid==`sc'\n        local N_base = r(sum) \n        global growth_agriculture_t`t'_sc`sc' = `N_i'/`N_base'\n        \n        qui sum industry_va if year==`t' & scenid==`sc'\n        local N_i = r(sum) \n        qui sum industry_va if year==`minyear' & scenid==`sc'\n        local N_base = r(sum) \n        global growth_industry_t`t'_sc`sc' = `N_i'/`N_base'\n\n        qui sum services_va if year==`t' & scenid==`sc'\n        local N_i = r(sum) \n        qui sum services_va if year==`minyear' & scenid==`sc'\n        local N_base = r(sum) \n        global growth_services_t`t'_sc`sc' = `N_i'/`N_base'\n            \n        /* Nominal Wages */\n        \n        qui sum wage        if year==`t' & scenid==`sc'\n        local N_i = r(sum) \n        qui sum wage        if year==`minyear' & scenid==`sc'\n        local N_base = r(sum) \n        global growth_wage_t`t'_sc`sc' = `N_i'/`N_base'\n        \n        /* Real Wages */\n        \n        qui sum rwage       if year==`t' & scenid==`sc'\n        local N_i = r(sum) \n        qui sum rwage       if year==`minyear' & scenid==`sc'\n        local N_base = r(sum) \n        global growth_rwage_t`t'_sc`sc' = `N_i'/`N_base'\n        \n    }\n}\n}\nAfter finishing the calculations for all scenarios and years, the code then lists all global macros, giving you an overview of the generated variables. The block of Stata commands then ends.\nIn summary, this code processes the dataset to generate a comprehensive set of global macros containing values for various economic indicators, broken down by year and scenario. These global macros are then used in subsequent analyses or microsimulations.\nglobal c:all globals\nmacro list c",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#define-key-variables-and-globalsrates",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#define-key-variables-and-globalsrates",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "4.1 Define key variables and globals/rates",
    "text": "4.1 Define key variables and globals/rates\nThis command recodes the educy variable, which represents years of education. It bins the years into three categories: “0-3”, “3-7”, and “8+”. The newly created categorical variable is named calif.\nrecode educy (0/3 = 1 \"0-3\") (3/7 = 2 \"3-7\") (7/11 = 3 \"8+\"), g(calif)\nA matrix industry_growth is created, which is based on a combination of previously defined global variables and the matrix E, which you can recall we created before with the elasticities. The industry_growth matrix represents growth in different industry sectors.\nmat industry_growth = /// \n    1+(${growth_agriculture_t`t'_sc`i'}-1)*E[1,1] \\ ///\n    1+(   ${growth_industry_t`t'_sc`i'}-1)*E[2,1] \\ ///\n    1+(   ${growth_services_t`t'_sc`i'}-1)*E[3,1]\nmatlist industry_growth\nA global variable employment is created based on employment rates for a particular year and scenario. This variable captures the growth in employment rate from the survey year to the target year.\nglobal employment = (${emp_rate_t`t'_sc`i'})  / (${emp_rate_t${surveyyear}_sc`i'})",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#main-reweighting-command",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#main-reweighting-command",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "4.2 Main reweighting command",
    "text": "4.2 Main reweighting command\nThis is the most important part of the code. The reweighting of the dataset.\nThe command mfmodms_reweight appears to be a custom command (possibly from a user-written package or an in-house module) that performs the reweighting based on several constraints. The variables and parameters to be considered in the reweighting process are specified.\nmfmodms_reweight, age(age) edu(calif) gender(gender) hhsize(hhsize)       // \n                  id(hhid) iw(wgt) country(\"$country\") iyear($surveyyear) //\n                  tyear(`t') generate(wgtsim) industry(industry)          //\n                  growth(industry_growth) match(HH) popdata(\"$popdata\")   //\n                  employment($employment) variant(`variant')",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#wage-bill-at-baseline",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#wage-bill-at-baseline",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "4.3 Wage bill at baseline",
    "text": "4.3 Wage bill at baseline\nThe command quietly calculates the weighted sum of the yflab variable, which represents the family labor income. The result is stored as a scalar named Y0.\nqui sum yflab [aw=wgt]\nscalar Y0 = r(mean)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#wage-bill-at-simulated-yearscenario",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#wage-bill-at-simulated-yearscenario",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "4.4 Wage bill at simulated year/scenario",
    "text": "4.4 Wage bill at simulated year/scenario\nThis portion of the code takes the user through calculating the simulated wage bill for different scenarios and years and then modifies the distribution of labor income accordingly.\nThe comments suggest adjusting the yflab (probably representing labor income or wage) in such a way that it grows consistently with Value Added (VA), ensuring the share of the wage bill on VA remains constant. This is done for three sectors: agriculture, industry, and services.\nHere, the wage bill for the simulated year and scenario is computed and stored in a scalar Y1.\n/* \"wage\" by sector grow in a way consistent with VA, \n    such that the share of the wage bill on VA is constant */\nqui replace yflab = yflab*(${growth_agriculture_t`t'_sc`i'} /    //\n                    industry_growth[1,1]) if industry==1\nqui replace yflab = yflab*(${growth_industry_t`t'_sc`i'}    /    //\n                    industry_growth[2,1]) if industry==2\nqui replace yflab = yflab*(${growth_services_t`t'_sc`i'}    /    //\n                    industry_growth[3,1]) if industry==3\n\n// Labor income (wage bill) at simulated year and scenario      \n    qui sum yflab [aw=wgtsim`t']\n    scalar Y1 = r(mean)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#re-center-and-simulated-welfare-aggregate",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#re-center-and-simulated-welfare-aggregate",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "4.5 Re-center and simulated welfare aggregate",
    "text": "4.5 Re-center and simulated welfare aggregate\nThis section aims to adjust the labor income, aggregate it to the household level, then adjust it further with non-labor income and consumption projections. The comment suggests re-centering the labor income distribution, ensuring that only the distribution of labor income is modified. Labor income is aggregated at the household level, producing a new variable named ysim_t’_sci', which seems to represent simulated labor income for a specific year (t) and scenario (i). The simulated labor income is adjusted to become per capita values. To the simulated labor income per capita, non-labor income (denoted by pcnli) is added.\n/* Re-center, so we only modify the distribution of \"labor income\" */   \nqui replace yflab = yflab * (Y0/Y1) \n    \n/* Aggregate to household again */\nbys hhid: egen ysim_`t'_sc`i' = sum(yflab) \n\n/* Divide by hhsize to make per capita again */\nqui replace ysim_`t'_sc`i'=(ysim_`t'_sc`i')/hhsize  \n    \n/* Adding back \"non-labor\" income */\nqui replace ysim_`t'_sc`i'=ysim_`t'_sc`i' + pcnli",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#adjusting-the-consumption-according-to-the-projection",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#adjusting-the-consumption-according-to-the-projection",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "4.6 Adjusting the consumption according to the projection",
    "text": "4.6 Adjusting the consumption according to the projection\nThis portion adjusts the simulated labor income based on the growth in per capita consumption from projections. The conditional statement checks if it’s the base year (2021) and the first scenario. If it is, the dataset is saved anew. If not, the dataset is appended with new simulated values for the other years and scenarios.\nqui sum pcc [aw=wgt]\nscalar pccY0 = r(mean)\nqui sum ysim_`t'_sc`i' [aw=wgtsim`t']\nscalar pccrwY1 = r(mean)\n    \nqui replace ysim_`t'_sc`i' = ysim_`t'_sc`i' *   //\n                             (pccY0*${pcc_growth_t`t'_sc`i'}) / pccrwY1\nlabel var ysim_`t'_sc`i'  //\n   \"Simulated pcc - After reweighting and hh consumption growth, Year: `t'\"\n\nren wgtsim`t' wgtsim`t'_sc`i' \n\nif (`i'==1 & `t'==2021) save \"$path/data/MAG_simulated.dta\",replace \nelse {\n    qui merge 1:1 hhid pid using  //\n              \"$path/data/MAG_simulated.dta\", keepusing(ysim_*_sc* wgtsim*_sc* )\n    drop _merge\n    qui save \"$path/data/MAG_simulated.dta\", replace \n} // This closes the loop.\nAfter processing each scenario and year, a message is displayed in red, indicating the completion of the scenario-year pair.\ndis in red \"DONE WITH SCENARIO `i' AND YEAR `t'\"\nThese closing brackets represent the end of loops and conditions. The code runs through various scenarios and years, updating the variable i (scenario counter) for each iteration.\n} /* Conditional to skip scenarios for 2021 */\n} /* Loop over years */\nlocal i = `i'+1\n} /* Loop over scenarios */\nFinally, the timer that was started at the beginning of the code is turned off, and the time taken is displayed.\ntimer off 1\ntimer list 1\nIn summary: Overall, this code simulates labor income under different scenarios and years, adjusts it based on various factors, and then saves or appends the results to the file named MAG_simulated.dta.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#poverty-statistics-by-regions-urbanrural-and-gender",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#poverty-statistics-by-regions-urbanrural-and-gender",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "5.1 Poverty statistics by regions, urban/rural, and gender",
    "text": "5.1 Poverty statistics by regions, urban/rural, and gender\nThis code is primarily involved in generating poverty and inequality indicators for different scenarios and years. Load the simulated data created before for further processing. Merge the data with another dataset that likely contains poverty lines or thresholds (based on variable names).\nuse \"$path/data/MAG_simulated\",clear    \nmerge 1:1 hhid pid using \"$path/data/MAG_assigned\", keepusing(pline* lbpl ubpl)\nDefine global macros for scenarios and years. Note that we only analyze every ten years.\nglobal scenssim 1 2 3 4 5 6\nglobal nscsteps 2030(10)2050\nCreate a binary indicator for urban areas based on binary “rural”. If not present.\n*gen urban = rural!=1\nKeep only the specified variables in the dataset.\nkeep hhid pid wgt wgtsim* ysim* pcc region gender zone pline* lbpl ubpl\nDefine different poverty thresholds.\ngen pov19 = 1.9\ngen pov32 = 3.2\ngen pov55 = 5.5\ngen pov10 = 10\nCreate a variable called ‘country’ with value 1 for all observations. Also, define a new variable Ysim_baseyear equal to the pcc variable, which seems to represent per capita consumption.\ng country=1\ng Ysim_baseyear = pcc\nThe next set of commands uses the sp_groupfunction command multiple times. This command seems to be a user-defined or package-specific function that calculates some group-specific statistics, likely poverty rates, and Gini coefficients. For example, This block calculates statistics for the base year at the country level:\npreserve\n    sp_groupfunction [aw=wgt], poverty(Ysim_baseyear)  //\n    povertyline(pline215 pline365 pline685 lbpl ubpl)  //\n                gini(Ysim_baseyear) mean(Ysim_baseyear) by(country) \n    g year=$surveyyear\n    tempfile resultsbase\n    qui save `resultsbase'\nrestore \nSimilar blocks are provided for calculating statistics at different levels: region, urban vs. rural (zone), and gender.\npreserve\n    sp_groupfunction [aw=wgt], poverty(Ysim_baseyear) //\n    povertyline(pline215 pline365 pline685 lbpl ubpl) //\n                mean(Ysim_baseyear) by(country region) \n    g year=$surveyyear\n    tempfile resultsbase_reg\n    qui save `resultsbase_reg'\nrestore \n\npreserve\n    sp_groupfunction [aw=wgt], poverty(Ysim_baseyear)  //\n    povertyline(pline215 pline365 pline685 lbpl ubpl)  //\n                mean(Ysim_baseyear) by(country zone) \n    g year=$surveyyear\n    tempfile resultsbase_urb\n    qui save `resultsbase_urb'\nrestore \n\npreserve\n    sp_groupfunction [aw=wgt], poverty(Ysim_baseyear)  //\n    povertyline(pline215 pline365 pline685 lbpl ubpl)  //\n                mean(Ysim_baseyear) by(country gender) \n    g year=$surveyyear\n    tempfile resultsbase_gender\n    qui save `resultsbase_gender'\nrestore \nAnd then we drop the previously created variable Ysim_baseyear.\ndrop Ysim_baseyear \nThe following loop iterates over scenarios and years, calculating the same set of statistics for each combination. For each scenario-year combination, the results are saved in a temporary file.\nforeach sc in $scenssim {  \n    forvalues i=$nscsteps { \n      preserve\n      noisily sp_groupfunction [aw=wgtsim`i'_sc`sc'], poverty(ysim_`i'_sc`sc')..\n      g year=`i'\n      tempfile results`i'_`sc'\n      qui save `results`i'_`sc''\n      restore\n    }\n}\nThe following nested loops iterating over various scenarios ($scenssim) and years ($nscsteps) do the same. Within each loop, a function named sp_groupfunction is applied to the data, which likely computes poverty-related statistics. The results are then saved to separate temporary files for different combinations of scenarios, years, and groupings (region, urban/rural zone, and gender). The results are saved in temporary files named with the pattern results[year]_[grouping]_[scenario]. In summary, the code generates poverty statistics based on simulated data, breaking down the results by different groupings (regions, urban/rural zones, and gender) for various scenarios and years.\nThen the code focuses on aggregating results from various files, preparing data for output, and then performing additional calculations on income percentiles. Here’s the step-by-step breakdown:\nThe script first loads the results from the base file (resultsbase) and then appends (or stacks) results from the different scenarios, regions, zones (urban/rural), and gender groupings created before.\nuse `resultsbase',clear\nappend using `resultsbase_reg'\nappend using `resultsbase_urb'\nappend using `resultsbase_gender'\nforeach sc in $scenssim {\n    forvalues i=$nscsteps {\n        append using `results`i'_`sc''\n        append using `results`i'_reg_`sc''\n        append using `results`i'_urb_`sc''\n        append using `results`i'_gender_`sc''\n    }\n}\nWe then create a Unique Identifier (concat) and Reorder.\ngen concat = measure +\"_\"+ variable+\"_\" +reference+\"_\"+string(region)+ //\n                      \"_\"+string(zone)+\"_\"+string(gender)\norder concat, first\ngen regionref = region\nThe aggregated data is then exported to an Excel file and then saved in a Stata format.\nexport excel using \"$scenario_file\", sheet(\"Indicators\",modify) firstrow(varlabels)\ndrop concat \nsave \"$path/outputs\\MAG_indicators\",replace\nThe script switches to another dataset (MAG_simulated) and prepares to compute income percentiles.\nuse \"$path\\data\\MAG_simulated\",clear\nmerge 1:1 hhid pid using \"$path/data/MAG_assigned\", keepusing(pline* lbpl ubpl)\nkeep hhid pid wgt wgtsim* ysim* pcc pline* lbpl ubpl\ng Ysim_baseyear = pcc\ng country = 1\ndrop pcc\nIt first calculates the percentiles for the base year income.\ngquantiles Ysim_baseyear [aw=wgt], _pctile nq(100)\nmat quantiles = r(quantiles_used)\nmat colnames quantiles = Ysim_baseyear\nIn essence, this code is primarily focused on organizing and summarizing the simulated results from different scenarios, then performing statistical analyses on the income distribution by quantiles.\nforeach sc in $scenssim {\n    forval simyear = $nscsteps {    \n        gquantiles ysim_`simyear'_sc`sc' [aw=wgtsim`simyear'_sc`sc'], _pctile nq(100)\n        mat mat0 = r(quantiles_used)\n        mat colnames mat0 = ysim_`simyear'_sc`sc'\n        mat quantiles = quantiles,mat0\n    }\n}\nWe export income by percentiles to our Excel file, modifying it (not replace). First, the data is cleared out of the current memory. The quantiles matrix is converted to a dataset format using svmat. Each column from the matrix becomes a variable in the dataset. A new variable, percentil, is created to indicate the row number (or the percentile). The dataset is exported to an Excel file under the sheet “Income_by_percentile”.\nclear\nsvmat quantiles, names(col)\ng percentil = _n\nexport excel using \"$scenario_file\", sheet(\"Income_by_percentile\",modify) //\n                   firstrow(varlabels)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#compute-deviations",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#compute-deviations",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "5.2 Compute deviations",
    "text": "5.2 Compute deviations\nThe dataset MAG_indicators is loaded into memory. Several variables are modified to replace missing or specific values:\nuse \"$path/outputs\\MAG_indicators\", clear\ndrop country\nreplace region = 99 if region==.\nreplace zone = 99 if zone==.\nreplace gender = 99 if gender==.\nreplace reference = \"NA\" if reference==\"\"\nreplace _population=_population*10e-7\npreserve\nThe dataset is then subsetted to keep observations where measure is “fgt0” (Foster-Greer-Thorbecke poverty measure with parameter 0). Some transformations are applied to the value variable based on the measure variable. A temporary file (number_poor) is saved. The original data is then restored and appended with this modified subset.\nkeep if inlist(measure,\"fgt0\")\nreplace value=value*_population\nreplace measure=\"np_fgt0\" if measure==\"fgt0\"\ntempfile number_poor \nsave `number_poor'\nrestore\nappend using `number_poor'\n        ```\n\nFurther transformations are performed:\n\n```stata\nreplace value=100*value if inlist(measure,\"fgt0\",\"fgt1\",\"fgt2\",\"gini\")\nreplace variable = \"ysim_base_sc0\" if variable==\"Ysim_baseyear\"\nThe code then proceeds to extract scenid (scenario ID) and creates labels for it. It also creates a variable, Ysim, by extracting a part of the variable column. Some cleanup operations are also performed.\ng scenid = real(substr(variable,13,2))\nlabel define scenid 0 \"base year\" $scenid ,replace\nlabel values scenid scenid\ng Ysim = substr(variable,1,ustrpos(variable,\"_sc\")-5)\nreplace Ysim = \"base\" if year==$surveyyear\ndrop variable \nThe final version of the dataset is exported to an Excel file under the sheet “Results_long”.\nexport excel using \"$scenario_file\", sheet(\"Results_long\",modify) firstrow(varlabels)\nOverall, this code focuses on data manipulation tasks, including reshaping the data, generating new variables, making adjustments to existing variables, and exporting the processed data to Excel for further use.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  },
  {
    "objectID": "supporting-materials/CCDR-poverty-code-explanation.html#generating-deviations-from-baseline",
    "href": "supporting-materials/CCDR-poverty-code-explanation.html#generating-deviations-from-baseline",
    "title": "A guide to CCDR Poverty Analysis code",
    "section": "5.3 Generating Deviations from Baseline:",
    "text": "5.3 Generating Deviations from Baseline:\nRemove observations where the variable Ysim is equal to “base”. Keep only those observations where the gender is coded as 99. Drop the variable _population as it is not needed. Reshape the dataset from long format to wide format using the value variable, with new columns created for each scenid. This will generate variables like value1, value2, etc., for each scenario.\ndrop if Ysim==\"base\"\nkeep if gender==99\ndrop _population\nreshape wide value, i(measure reference region zone year) j(scenid)\nFor each scenario, calculate the deviation as a percentage from the baseline (value1). This deviation indicates how much a value in a given scenario has changed relative to the baseline scenario. Similarly, compute the deviation in levels (absolute difference from the baseline).\nlocal num : list sizeof global(scenarios)\nforvalues i=2(1)`num' {\n  g des_percent_`i' = 100*(value`i'-value1)/value1\n}\nforvalues i=2(1)`num' {\n  g des_level_`i' = value`i'-value1\n}\nDrop all the value* columns. Reshape the dataset back to long format based on the deviation columns. Rename the columns for better clarity.\ndrop value*\nreshape long des_percent_ des_level_, i(Ysim measure reference region zone year) j(scenid)\nrename des_*_ des_*\nCreate a new variable, concat, that combines several variables into a single string. This is for uniquely identifying or categorizing each observation. Reorder the dataset so that concat appears first.\ngen concat = measure +\"_\"+ Ysim+string(year)+\"_\" //\n             +string(scenid)+\"_\"+reference+\"_\"+  //\n             string(region)+\"_\"+string(zone)+\"_\"+ //\n             string(gender) \norder concat, first\nFinally, export the current dataset to an Excel file under the sheet “Deviations_long”.\nexport excel using \"$scenario_file\", sheet(\"Deviations_long\",modify) //\n                   firstrow(varlabels)\nThis code is mainly concerned with deriving deviations from a baseline across different scenarios and organizing the resulting dataset for further analysis and presentation. The computed deviations provide insights into how different scenarios compare to a reference or baseline scenario in the given dataset.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "A guide to CCDR Poverty Analysis code"
    ]
  }
]